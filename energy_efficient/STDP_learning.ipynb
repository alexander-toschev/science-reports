{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f620028-87ed-4c99-a115-950ce07e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LatencyEncoder:\n",
    "    def __init__(self, time: int = 100):\n",
    "        self.time = time  # Общее число временных шагов\n",
    "\n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        image: Tensor [1, 28, 28] или [28, 28], значения от 0 до 1 или до 255\n",
    "        return: spike_tensor [time, 1, 784]\n",
    "        \"\"\"\n",
    "        if image.ndim == 3:\n",
    "            image = image.squeeze()\n",
    "\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "\n",
    "        spike_tensor = torch.zeros((self.time, 1, 784))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                pixel = image[i, j].item()\n",
    "                if pixel > 0:\n",
    "                    spike_time = int((1.0 - pixel) * (self.time - 1))\n",
    "                    spike_tensor[spike_time, 0, i * 28 + j] = 1.0\n",
    "\n",
    "        return spike_tensor.view(self.time, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52ed814-94e5-4deb-835c-2ebbcd9483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_input_health(in_s_full, T, name=\"INPUT\", expected_total=None):\n",
    "    # in_s_full: [T,B,784] или [T,784]\n",
    "    s = in_s_full[:,0,:] if in_s_full.dim()==3 else in_s_full  # [T,784]\n",
    "    T_, N = s.shape\n",
    "    assert T_ == T, f\"T mismatch: {T_}!={T}\"\n",
    "    per_pix = s.sum(0)         # [N] спайков на пиксель за окно\n",
    "    per_t   = s.sum(1)         # [T] спайков на такт\n",
    "\n",
    "    total  = int(per_pix.sum().item())\n",
    "    mean_t = float(per_t.mean().item())\n",
    "    max_t  = int(per_t.max().item())\n",
    "    frac_silent_pixels = float((per_pix == 0).float().mean().item())\n",
    "    frac_empty_timesteps = float((per_t == 0).float().mean().item())\n",
    "    frac_dense_timesteps = float((per_t > 0.1*N).float().mean().item())  # >10% нейронов стреляют\n",
    "\n",
    "    # Нормированная энтропия распределения активности по пикселям\n",
    "    if total > 0:\n",
    "        p = (per_pix / total).clamp_min(1e-12)\n",
    "        import math\n",
    "        H = float((-(p * p.log()).sum().item()))           # nats\n",
    "        H_norm = H / math.log(N)                           # 0..1\n",
    "    else:\n",
    "        H_norm = 0.0\n",
    "\n",
    "    # Топ-8 «самых активных» пикселей (для грубой диагностики)\n",
    "    topk = torch.topk(per_pix, k=min(8, N))\n",
    "    topk_vals = [int(v) for v in topk.values.tolist()]\n",
    "\n",
    "    # Печать\n",
    "    print(f\"{name} window total: {total}\"\n",
    "          + (f\" | expected≈{int(expected_total)}\" if expected_total is not None else \"\"))\n",
    "    print(f\"{name} per-timestep: mean={mean_t:.1f}, max={max_t}\")\n",
    "    print(f\"{name} pixels: silent_frac={frac_silent_pixels:.3f}, H_norm={H_norm:.3f}\")\n",
    "    print(f\"{name} timesteps: empty_frac={frac_empty_timesteps:.3f}, dense>10%={frac_dense_timesteps:.3f}\")\n",
    "    print(f\"{name} top-8 pixel counts: {topk_vals}\")\n",
    "\n",
    "    # Возврат на всякий случай (если захочешь логировать в файл)\n",
    "    return dict(\n",
    "        total=total, mean_per_timestep=mean_t, max_per_timestep=max_t,\n",
    "        frac_silent_pixels=frac_silent_pixels, frac_empty_timesteps=frac_empty_timesteps,\n",
    "        frac_dense_timesteps=frac_dense_timesteps, H_norm=H_norm, top8=topk_vals\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297294ce-41ea-4446-bfed-081c022d6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stdp_nu(conn, nu_plus, nu_minus):\n",
    "    dev = conn.w.device\n",
    "    conn.update_rule.nu = (torch.tensor(nu_plus, device=dev),\n",
    "                           torch.tensor(nu_minus, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04cd6b1-9541-4bf7-bfec-daba59b3f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перед run_experiment\n",
    "class ThreshEMA:\n",
    "    def __init__(self): self.rate_ema = None\n",
    "    def step(self, layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "        with torch.no_grad():\n",
    "            rate = spike_counts / max(1, T)\n",
    "            if self.rate_ema is None:\n",
    "                self.rate_ema = rate.clone()\n",
    "            self.rate_ema = alpha * self.rate_ema + (1 - alpha) * rate\n",
    "            vt = layer.v_thresh if hasattr(layer,'v_thresh') else layer.thresh\n",
    "            vt += k * (self.rate_ema - target)\n",
    "            vt.clamp_(0.15, 1.2)\n",
    "            if hasattr(layer,'v_thresh'): layer.v_thresh = vt\n",
    "            else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd656371-a693-4252-9532-7e8105b90ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rate_ema = None\n",
    "def adapt_thresholds_ema(layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "    global _rate_ema\n",
    "    with torch.no_grad():\n",
    "        rate = spike_counts / max(1, T)\n",
    "        if _rate_ema is None: _rate_ema = rate.clone()\n",
    "        _rate_ema = alpha * _rate_ema + (1 - alpha) * rate\n",
    "        vt = layer.v_thresh if hasattr(layer,\"v_thresh\") else layer.thresh\n",
    "        vt += k * (_rate_ema - target)\n",
    "        vt.clamp_(vt_min, vt_max)  \n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6059930-22e3-4bdf-af94-50037eb25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_param(module, name, value, prefer_scalar=False, fallback_scalar=None):\n",
    "    \"\"\"\n",
    "    Безопасно проставляет module.<name>.\n",
    "    - Если буфер Tensor скалярный (numel()==1) и value вектор -> кладём 0-D тензор (ср. значение или fallback_scalar).\n",
    "    - Если буфер Tensor векторный -> копируем по форме.\n",
    "    - prefer_scalar=True принудительно делает 0-D (для refrac/reset).\n",
    "    \"\"\"\n",
    "    if not hasattr(module, name):\n",
    "        return False\n",
    "\n",
    "    cur = getattr(module, name)\n",
    "\n",
    "    # если это Tensor-буфер\n",
    "    if isinstance(cur, torch.Tensor):\n",
    "        dev, dt = cur.device, cur.dtype\n",
    "\n",
    "        if prefer_scalar:\n",
    "            # всегда 0-D тензор\n",
    "            val = float(value.mean().item() if torch.is_tensor(value) else value)\n",
    "            setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            return True\n",
    "\n",
    "        if torch.is_tensor(value):\n",
    "            if cur.numel() == 1 and value.numel() > 1:\n",
    "                # буфер скалярный, value вектор -> берём среднее/фолбэк\n",
    "                val = float(value.mean().item())\n",
    "                if fallback_scalar is not None:\n",
    "                    val = float(fallback_scalar)\n",
    "                setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            else:\n",
    "                if value.shape != cur.shape:\n",
    "                    value = value.view_as(cur)\n",
    "                cur.data.copy_(value.to(dev, dtype=dt))\n",
    "        else:\n",
    "            # value скаляр Python -> просто заливаем\n",
    "            if cur.numel() == 1:\n",
    "                setattr(module, name, torch.tensor(float(value), device=dev, dtype=dt))\n",
    "            else:\n",
    "                cur.data.fill_(float(value))\n",
    "        return True\n",
    "\n",
    "    # не Tensor-буфер – обычный атрибут\n",
    "    setattr(module, name, float(value) if prefer_scalar else value)\n",
    "    return True\n",
    "\n",
    "def debug_all_params(lif_layer):\n",
    "    print(\"=== attributes ===\")\n",
    "    for k in dir(lif_layer):\n",
    "        if not k.startswith(\"_\"):\n",
    "            try:\n",
    "                v = getattr(lif_layer, k)\n",
    "                if torch.is_tensor(v):\n",
    "                    print(f\"{k}: tensor shape={tuple(v.shape)}, first={v.flatten()[0].item():.6g}\")\n",
    "                else:\n",
    "                    print(f\"{k}: {type(v)}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    print(\"\\n=== named_parameters ===\")\n",
    "    for name, p in lif_layer.named_parameters():\n",
    "        print(f\"{name}: shape={tuple(p.shape)}, requires_grad={p.requires_grad}\")\n",
    "\n",
    "    print(\"\\n=== named_buffers ===\")\n",
    "    for name, b in lif_layer.named_buffers():\n",
    "        print(f\"{name}: shape={tuple(b.shape)}\")\n",
    "\n",
    "def tune_lif_params(lif_layer, n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0):\n",
    "    with torch.no_grad():\n",
    "        # порог: попытаемся поставить вектор; если буфер скалярный — авто-даунмикс в скаляр\n",
    "        vt_vec = (vt_mean + vt_jitter * torch.randn(n_hidden)).clamp(0.05, 2.0)\n",
    "        if not _set_param(lif_layer, \"v_thresh\", vt_vec, fallback_scalar=vt_mean):\n",
    "            _set_param(lif_layer, \"thresh\", vt_vec, fallback_scalar=vt_mean)\n",
    "\n",
    "        # tau: аналогично (может быть vектор/скаляр в разных версиях)\n",
    "        if not _set_param(lif_layer, \"tc_decay\", torch.full((n_hidden,), tau_val), fallback_scalar=tau_val):\n",
    "            _set_param(lif_layer, \"tc_decay\",   torch.full((n_hidden,), tau_val),   fallback_scalar=tau_val)\n",
    "\n",
    "        # refrac — строго скаляр (0-D)\n",
    "        _set_param(lif_layer, \"refrac\", refrac_val, prefer_scalar=True)\n",
    "\n",
    "        # reset — скаляр\n",
    "        if not _set_param(lif_layer, \"v_reset\", 0.0, prefer_scalar=True):\n",
    "            _set_param(lif_layer, \"reset\",  0.0, prefer_scalar=True)\n",
    "\n",
    "def print_lif_params(lif_layer):\n",
    "    with torch.no_grad():\n",
    "        #debug_all_params(lif_layer)\n",
    "        # Порог\n",
    "        for key in [\"v_thresh\", \"thresh\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                if torch.is_tensor(val):\n",
    "                    if val.ndim == 0:\n",
    "                        print(f\"[lif] {key} = scalar {val.item():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"[lif] {key} = vector shape={tuple(val.shape)}, \"\n",
    "                              f\"mean={val.mean():.3f}, min={val.min():.3f}, max={val.max():.3f}\")\n",
    "                else:\n",
    "                    print(f\"[lif] {key} = {val}\")\n",
    "        \n",
    "        # Tau\n",
    "        for key in [\"tc_decay\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                if torch.is_tensor(val):\n",
    "                    if val.ndim == 0:\n",
    "                        print(f\"[lif] {key} = scalar {val.item():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"[lif] {key} = vector shape={tuple(val.shape)}, \"\n",
    "                              f\"value≈{val[0].item():.3f} (all equal?)\")\n",
    "                else:\n",
    "                    print(f\"[lif] {key} = {val}\")\n",
    "        \n",
    "        # Refrac\n",
    "        if hasattr(lif_layer, \"refrac\"):\n",
    "            val = getattr(lif_layer, \"refrac\")\n",
    "            print(f\"[lif] refrac = {val if not torch.is_tensor(val) else val.item()}\")\n",
    "\n",
    "        # Reset\n",
    "        for key in [\"v_reset\", \"reset\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                print(f\"[lif] {key} = {val if not torch.is_tensor(val) else val.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738905c1-a267-41b6-a110-1df68fe5eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "# ====== Config ======\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    # core\n",
    "    time:   int = 200\n",
    "    n_hidden: int = 100\n",
    "    nu_plus:  float = 0.02\n",
    "    nu_minus: float = -0.02\n",
    "\n",
    "    # inhibition / WTA\n",
    "    inhib_strength: float = 0.3\n",
    "    inh_decay: float = 0.9\n",
    "    top_k: int = 0                    # 0 = WTA off for diagnostics\n",
    "    enable_inhibition_at_start: bool = False\n",
    "\n",
    "    # encoder\n",
    "    encoder: str = \"latency\"         # start with Poisson to \"ignite\" spikes\n",
    "\n",
    "    # homeostasis\n",
    "    target_spikes: float = 2.0\n",
    "    eta_up: float = 1.0\n",
    "    eta_down: float = 0.5\n",
    "    thresh_min: float = 0.2\n",
    "    thresh_max: float = 2.0\n",
    "    thresh_init: float = 0.5          # v_thresh initial (BindsNET positive scale)\n",
    "\n",
    "    # weights\n",
    "    w_clip_min: float = 0.0\n",
    "    w_clip_max: float = 1.5\n",
    "    w_col_target_norm: float = 20.0\n",
    "    w_init_lo: float = 0.8\n",
    "    w_init_hi: float = 1.2\n",
    "    wmin:float = 0.0\n",
    "    wmax:float = 2.0\n",
    "    warmup_N: int = 50\n",
    "    # loop\n",
    "    N: int = 200\n",
    "    log_every: int = 50\n",
    "    seed: int = 42\n",
    "    poisson_rate_scale: float = 0.7 \n",
    "    device: str = \"cpu\"\n",
    "    vt_mean:float = 0.35\n",
    "    vt_jitter:float = 0.02\n",
    "    tau_val:float = 50.0\n",
    "    refrac_val:float = 2.0\n",
    "    debug:bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62625648-17a4-47af-9950-dfa00b772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SETUP (Colab/Local) ======\n",
    "# !pip -q install bindsnet==0.2.8 torchvision==0.18.1 torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import os, itertools, random, csv, time as _ptime\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Utils ======\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def to_2d(s):  # [T,N] or [T,1,N] -> [T,N]\n",
    "    return s[:,0,:] if (s.dim()==3 and s.size(1)==1) else s\n",
    "\n",
    "\n",
    "\n",
    "# ====== Helpers: WTA, norm, thresholds, plots, metrics ======\n",
    "def apply_wta(s, top_k=1):\n",
    "    s2 = to_2d(s)\n",
    "    sb = s2.sum(0).float().squeeze()\n",
    "    if sb.sum() == 0:\n",
    "        return False, None\n",
    "    vals, idxs = torch.topk(sb, k=min(top_k, sb.numel()))\n",
    "    s.zero_()\n",
    "    for j in idxs.tolist():\n",
    "        if s.dim()==3:\n",
    "            s[:,0,j] = True\n",
    "        else:\n",
    "            s[:,j] = True\n",
    "    return True, idxs.tolist()\n",
    "\n",
    "def weight_soft_bound_and_colnorm(conn_w, w_clip_min, w_clip_max, target_norm):\n",
    "    with torch.no_grad():\n",
    "        w = conn_w.data\n",
    "        w.clamp_(w_clip_min, w_clip_max)\n",
    "        col_norm = w.norm(p=1, dim=0, keepdim=True) + 1e-6\n",
    "        w.mul_(target_norm / col_norm)\n",
    "\n",
    "def adapt_thresholds(layer, spike_counts, cfg: Cfg):\n",
    "    with torch.no_grad():\n",
    "        vt = layer.v_thresh if hasattr(layer, \"v_thresh\") else layer.thresh\n",
    "        vt -= 0.05 * (spike_counts < 1.0).float()        # if silent -> lower threshold\n",
    "        vt += 0.02 * (spike_counts > 3.0).float()        # if too active -> raise\n",
    "        vt.clamp_(cfg.thresh_min, cfg.thresh_max)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt\n",
    "\n",
    "def spiking_metrics_window(lif_s, winners=None):\n",
    "    s = to_2d(lif_s).to(torch.bool)\n",
    "    T, N = s.shape\n",
    "    per_n = s.sum(0)\n",
    "    tot = int(per_n.sum())\n",
    "    active = int((per_n > 0).sum())\n",
    "    if tot > 0:\n",
    "        p = (per_n / tot).float().cpu().numpy()\n",
    "        HHI = float((p**2).sum())\n",
    "        ps = np.sort(p)\n",
    "        Gini = float((np.cumsum(ps).sum()/ps.sum() - (len(ps)+1)/2)/len(ps))\n",
    "    else:\n",
    "        HHI, Gini = 1.0, 1.0\n",
    "    uniq_winners = len(set(winners)) if winners else 0\n",
    "    return dict(T=T, N=N, total_spikes=tot, active=active, HHI=HHI, Gini=Gini, uniq_winners=uniq_winners)\n",
    "\n",
    "class SNNMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.samples=0; self.S_out=0; self.S_in=0; self.SynOps=0; self.V_updates=0\n",
    "        self.usage_counts = {}\n",
    "    def log_sample(self, lif_s, in_s, n_hidden, T, winners=None):\n",
    "        lif2 = to_2d(lif_s);  in2 = to_2d(in_s)\n",
    "        s_out = int(lif2.sum().item())\n",
    "        s_in  = int(in2.sum().item())\n",
    "        self.S_out += s_out; self.S_in += s_in\n",
    "        self.SynOps += s_in * n_hidden\n",
    "        self.V_updates += n_hidden * T\n",
    "        self.samples += 1\n",
    "        if winners:\n",
    "            for j in winners:\n",
    "                self.usage_counts[j] = self.usage_counts.get(j,0)+1\n",
    "    def report(self, a=1.0, b=0.05, c=0.005):\n",
    "        s = max(1, self.samples)\n",
    "        HHI_win = 0.0\n",
    "        if self.usage_counts:\n",
    "            tot = sum(self.usage_counts.values())\n",
    "            ps = np.array([v/tot for v in self.usage_counts.values()], dtype=float)\n",
    "            HHI_win = float((ps**2).sum())\n",
    "        return {\n",
    "            \"spikes_per_sample\": self.S_out/s,\n",
    "            \"synops_per_sample\": self.SynOps/s,\n",
    "            \"v_updates_per_sample\": self.V_updates/s,\n",
    "            \"energy_proxy_per_sample\": (a*self.S_out + b*self.SynOps + c*self.V_updates)/s,\n",
    "            \"winners_unique\": len(self.usage_counts),\n",
    "            \"winner_HHI\": HHI_win,\n",
    "        }\n",
    "\n",
    "# ====== Build Net & Encoder ======\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "def build_net(cfg: Cfg):\n",
    "    net = Network()\n",
    "\n",
    "    input_layer = Input(n=784, traces=True)\n",
    "    lif_layer   = LIFNodes(n=cfg.n_hidden, traces=True)\n",
    "    tune_lif_params(lif_layer, cfg.n_hidden, cfg.vt_mean, cfg.vt_jitter, cfg.tau_val, cfg.refrac_val)\n",
    "            \n",
    "    net.add_layer(input_layer, name='Input')\n",
    "    net.add_layer(lif_layer,   name='LIF')\n",
    "    print_lif_params(lif_layer)\n",
    "\n",
    "    connection = Connection(source=input_layer, target=lif_layer)\n",
    "    connection.update_rule = PostPre(connection=connection,\n",
    "                                 nu=(torch.tensor(cfg.nu_plus),\n",
    "                                     torch.tensor(cfg.nu_minus)))\n",
    "    net.add_connection(connection, source='Input', target='LIF')\n",
    "\n",
    "    # Lateral inhibition (created, but optionally disabled at start)\n",
    "    W_inh = torch.full((cfg.n_hidden, cfg.n_hidden), -cfg.inhib_strength)\n",
    "    W_inh.fill_diagonal_(0.0)\n",
    "    recurrent_inh = Connection(source=lif_layer, target=lif_layer, w=W_inh.clone())\n",
    "    net.add_connection(recurrent_inh, source='LIF', target='LIF')\n",
    "\n",
    "    # Weights init (stronger to ignite)\n",
    "    with torch.no_grad():\n",
    "        connection.w.data.uniform_(cfg.w_init_lo, cfg.w_init_hi)\n",
    "\n",
    "    # Thresholds: use v_thresh if available\n",
    "    th0 = torch.full((cfg.n_hidden,), cfg.thresh_init)\n",
    "    if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh = th0.clone()\n",
    "    else: lif_layer.thresh = th0.clone()\n",
    "\n",
    "    # Optionally disable inhibition at start (for diagnostics)\n",
    "    if not cfg.enable_inhibition_at_start:\n",
    "        with torch.no_grad():\n",
    "            recurrent_inh.w.zero_()\n",
    "\n",
    "    return net, input_layer, lif_layer, connection, recurrent_inh, W_inh\n",
    "\n",
    "# Пре-процесс для произвольных изображений (PIL / np / tensor)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28), antialias=True),\n",
    "    transforms.ToTensor(),                 # -> [1,28,28] float in [0,1]\n",
    "    # Никаких Normalize(mean,std) здесь — нам нужны «сырые» 0..1!\n",
    "])\n",
    "\n",
    "def make_encoder(encoder_type: str, T: int, rate_floor: float = 0.0,poisson_rate_scale: float = 0.7 ):  # floor по умолчанию 0\n",
    "    encoder_type = encoder_type.lower()\n",
    "    assert encoder_type in (\"poisson\", \"latency\")\n",
    "\n",
    "    def encode_poisson(img_tensor):\n",
    "        x = img_tensor.view(-1).clamp(0, 1)\n",
    "        rates = x * poisson_rate_scale\n",
    "        rand = torch.rand((T, rates.numel()), device=rates.device if x.is_cuda else None)\n",
    "        spikes = (rand < rates).float()\n",
    "        return spikes.view(T, 1, 784)\n",
    "\n",
    "    def encode_latency(img_tensor):\n",
    "        x = img_tensor.squeeze(0).clamp(0, 1)\n",
    "        spikes = torch.zeros((T, 1, 784), dtype=torch.float32)\n",
    "        nz = (x > 0).nonzero(as_tuple=False)\n",
    "        if nz.numel() == 0:\n",
    "            return spikes\n",
    "        for idx in nz:\n",
    "            i, j = int(idx[0]), int(idx[1])\n",
    "            p = float(x[i, j])\n",
    "            t = int(round((1.0 - p) * (T - 1)))\n",
    "            # маленький джиттер ±1 тик (в пределах окна)\n",
    "            if T >= 3:\n",
    "                t += int(torch.randint(-1, 2, (1,)).item())\n",
    "                t = max(0, min(T-1, t))\n",
    "            spikes[t, 0, i*28 + j] = 1.0\n",
    "        return spikes\n",
    "\n",
    "    return (encode_poisson if encoder_type == \"poisson\" else encode_latency), preprocess\n",
    "        \n",
    "def _to_2d(s):  # [T, B, N] -> [T, N]\n",
    "    return s[:, 0, :] if s.dim()==3 else s\n",
    "    \n",
    "# ====== One Experiment ======\n",
    "def run_experiment(cfg: Cfg, verbose=True):\n",
    "    set_seed(cfg.seed)\n",
    "    device = cfg.device\n",
    "    print(\"Используем:\", device)\n",
    "    # Датасет (MNIST уже в [0,1] и [1,28,28])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # Сеть + мониторы\n",
    "    net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "    net = net.to(device)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # ↓ СРАЗУ ПОСЛЕ build_net(cfg)\n",
    "    with torch.no_grad():\n",
    "        # у разных версий BindsNET порог лежит в v_thresh ИЛИ в thresh\n",
    "        if hasattr(lif_layer, \"v_thresh\"):\n",
    "            vt = lif_layer.v_thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.v_thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)  # 0-D тензор!\n",
    "            else:\n",
    "                lif_layer.v_thresh.fill_(0.12)\n",
    "        else:\n",
    "            vt = lif_layer.thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)   # 0-D тензор!\n",
    "            else:\n",
    "                lif_layer.thresh.fill_(0.12)\n",
    "        if hasattr(lif_layer, \"refrac\"):\n",
    "            lif_layer.refrac = torch.tensor(2.0, device=vt.device)  # 2 тика\n",
    "            #print(f\"set refrac {lif_layer.refrac}\")\n",
    "            \n",
    "    \n",
    "    # для самопроверки — оставь print один раз\n",
    "    vt_chk = (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\">>> THRESH SET TO:\", float(vt_chk.mean().item()))\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    rf = lif_layer.refrac\n",
    "    #print(\"v_thresh mean±std refrac:\", float(vt.mean()), float(vt.std()),rf)\n",
    "    \n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    inp_mon = Monitor(input_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    net.add_monitor(lif_mon, name=\"lif_mon\")\n",
    "    net.add_monitor(inp_mon, name=\"inp_mon\")\n",
    "\n",
    "    # Энкодер\n",
    "    ENCODER_TYPE = cfg.encoder\n",
    "    T = cfg.time\n",
    "    encoder, _ = make_encoder(ENCODER_TYPE, T, poisson_rate_scale=cfg.poisson_rate_scale)\n",
    "\n",
    "    # --- DEBUG METRICS INIT --------------------------------------------\n",
    "    DEBUG = cfg.debug\n",
    "    pix_total = 28 * 28\n",
    "    # аккумулируем статистику по всему ранe\n",
    "    inp_empty_steps_total = 0     # сколько тайм-степов вообще пустые (нет входных спайков)\n",
    "    lif_empty_steps_total = 0\n",
    "    steps_total = 0\n",
    "    pix_fire_counts = torch.zeros(pix_total)  # суммарные спайки по каждому пикселю\n",
    "    run_pairs = []  # (sum_in_window, sum_lif_window)\n",
    "    # --------------------------------------------------------------------\n",
    "    \n",
    "    # --------- WARMUP (без STDP) ---------\n",
    "    WARMUP = getattr(cfg, \"warmup_N\", 50)\n",
    "    if WARMUP > 0:\n",
    "        # на прогрев STDP выкл.\n",
    "        set_stdp_nu(connection, 0.0, 0.0)\n",
    "        for wi in range(min(WARMUP, len(dataset))):\n",
    "            image = dataset[wi][\"image\"]\n",
    "             # === ВСТАВИТЬ В ЦИКЛ ПЕРЕД net.run(...) ===\n",
    "            # Оценка ожидаемого числа входных спайков (для Poisson)\n",
    "            if cfg.encoder.lower() == \"poisson\":\n",
    "                # Если в Poisson ты делаешь: spikes[t] ~ Bernoulli(rate_scale * pixel)\n",
    "                img_mean = float(image.mean().item())  # [0..1]\n",
    "                expected_total = cfg.time * 784 * cfg.poisson_rate_scale * img_mean\n",
    "            else:\n",
    "                expected_total = None\n",
    "            spike_input = encoder(image).to(device)\n",
    "            net.run(inputs={\"Input\": spike_input}, time=cfg.time)\n",
    "\n",
    "            # адаптация порогов на прогреве (по желанию — полезно)\n",
    "            lif_s_full = lif_mon.get(\"s\")\n",
    "            spike_counts = to_2d(lif_s_full).sum(0).float().squeeze()\n",
    "            # adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "            \n",
    "\n",
    "            # очистка состояний между примерами\n",
    "            net.reset_state_variables()\n",
    "            lif_mon.reset_state_variables()\n",
    "            inp_mon.reset_state_variables()\n",
    "\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\"v_thresh mean±std:\", float(vt.mean()), float(vt.std()))\n",
    "    # --------- ОСНОВНОЙ ЦИКЛ ---------\n",
    "    with torch.no_grad():\n",
    "        I = torch.eye(cfg.n_hidden, device=recurrent_inh.w.device, dtype=recurrent_inh.w.dtype)\n",
    "        recurrent_inh.w.copy_(-0.55 * (1 - I)) \n",
    "    ema = ThreshEMA()\n",
    "    meter = SNNMeter()\n",
    "    # мягкий STDP после прогрева\n",
    "    set_stdp_nu(connection, cfg.nu_plus, cfg.nu_minus) # было 1e-3 / -5e-4\n",
    "    \n",
    "\n",
    "    for i in range(cfg.N):\n",
    "        sample = dataset[i]\n",
    "        image  = sample[\"image\"]\n",
    "        spike_input = encoder(image).to(device)\n",
    "        inputs = {\"Input\": spike_input}\n",
    "        \n",
    "\n",
    "        net.run(inputs=inputs, time=cfg.time)\n",
    "\n",
    "        # Полный растр за окно\n",
    "        lif_s_full = lif_mon.get(\"s\")   # [T,B,N]\n",
    "        in_s_full  = inp_mon.get(\"s\")   # [T,B,784]\n",
    "        lif2 = _to_2d(lif_s_full); in2 = _to_2d(in_s_full)\n",
    "\n",
    "        # --- DEBUG METRICS PER-WINDOW ---------------------------------\n",
    "        # по-времени: сколько событий на каждом t\n",
    "        inp_t = in2.sum(dim=1).cpu().numpy()   # [T]\n",
    "        lif_t = lif2.sum(dim=1).cpu().numpy()  # [T]\n",
    "        steps_total += T\n",
    "        inp_empty_steps_total += int((inp_t == 0).sum())\n",
    "        lif_empty_steps_total += int((lif_t == 0).sum())\n",
    "        # по-пикселям: сколько раз пиксель стрелял за окно\n",
    "        pix_fire_counts += in2.sum(dim=0).cpu()  # [784]\n",
    "        # окно-суммы для быстрой корреляции «окно входа» → «окно выхода»\n",
    "        run_pairs.append((float(inp_t.sum()), float(lif_t.sum())))\n",
    "        # --------------------------------------------------------------\n",
    "\n",
    "        # чекпоинт-лог (минимальный)\n",
    "        if i in (0, 50, 100, 150, 199) or ((i+1) % cfg.log_every == 0):\n",
    "            print(f\"INPUT window sum: {int(inp_t.sum())}\")\n",
    "            print(f\"LIF   window sum: {int(lif_t.sum())}\")\n",
    "\n",
    "            if DEBUG:\n",
    "                # доля пустых таймстепов в текущем окне\n",
    "                empty_frac_in  = float((inp_t == 0).mean())\n",
    "                empty_frac_lif = float((lif_t == 0).mean())\n",
    "                mean_in_t  = float(inp_t.mean());  max_in_t  = float(inp_t.max(initial=0))\n",
    "                mean_lif_t = float(lif_t.mean());  max_lif_t = float(lif_t.max(initial=0))\n",
    "\n",
    "                # корреляция по тайм-ось: сколько входных событий ↔ сколько выходных\n",
    "                if (inp_t.std() > 1e-8) and (lif_t.std() > 1e-8):\n",
    "                    corr = float(np.corrcoef(inp_t, lif_t)[0,1])\n",
    "                else:\n",
    "                    corr = float('nan')\n",
    "\n",
    "                print(f\"[dbg] per-timestep INPUT mean={mean_in_t:.2f} max={max_in_t} empty_frac={empty_frac_in:.2f}\")\n",
    "                print(f\"[dbg] per-timestep LIF   mean={mean_lif_t:.2f} max={max_lif_t} empty_frac={empty_frac_lif:.2f}\")\n",
    "                print(f\"[dbg] corr(input_t, lif_t)={corr:.3f}\")\n",
    "\n",
    "                # топ-8 активных пикселей (индикатор, что вход не совсем «немой»)\n",
    "                topk = torch.topk(pix_fire_counts, k=8)\n",
    "                print(f\"[dbg] top8 pixels counts: {topk.values.int().tolist()}  idx: {topk.indices.tolist()[:8]}\")\n",
    "\n",
    "\n",
    "        # WTA (если включён)\n",
    "        winners = []\n",
    "        if cfg.top_k and cfg.top_k > 0:\n",
    "            ok, idxs = apply_wta(lif_layer.s, top_k=cfg.top_k)\n",
    "            winners = idxs if ok and idxs is not None else []\n",
    "\n",
    "        # Метрики окна\n",
    "        m = spiking_metrics_window(lif_s_full, winners)\n",
    "        if verbose and ((i+1) % cfg.log_every == 0 or i == 0):\n",
    "            print(f\"[{i+1}] total={m['total_spikes']} active={m['active']}/{m['N']} HHI={m['HHI']:.3f}\")\n",
    "\n",
    "        # Homeostasis по «сырым» спайкам (до WTA)\n",
    "        spike_counts = to_2d(lif_s_full).sum(0).float().to(device)\n",
    "        ema.step(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "\n",
    "        # Кламп весов (без агрессивной колоночной нормировки каждый шаг)\n",
    "        with torch.no_grad():\n",
    "            connection.w.clamp_(0.0, 1.0)\n",
    "\n",
    "        # Энергетика / учёт\n",
    "        meter.log_sample(lif_s_full, in_s_full, cfg.n_hidden, cfg.time, winners=winners)\n",
    "\n",
    "        # Сброс состояний и мониторов\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "        inp_mon.reset_state_variables()\n",
    "\n",
    "        \n",
    "    # --- DEBUG METRICS FINAL SUMMARY -----------------------------------\n",
    "    if DEBUG and steps_total > 0:\n",
    "        inp_empty_frac_all = inp_empty_steps_total / steps_total\n",
    "        lif_empty_frac_all = lif_empty_steps_total / steps_total\n",
    "        silent_pixels_frac = float((pix_fire_counts == 0).float().mean())\n",
    "\n",
    "        # корреляция «сумма входа по окну → сумма выхода по окну»\n",
    "        if len(run_pairs) > 1:\n",
    "            inp_sums = np.array([p[0] for p in run_pairs], dtype=float)\n",
    "            lif_sums = np.array([p[1] for p in run_pairs], dtype=float)\n",
    "            if inp_sums.std() > 1e-8 and lif_sums.std() > 1e-8:\n",
    "                corr_win = float(np.corrcoef(inp_sums, lif_sums)[0,1])\n",
    "            else:\n",
    "                corr_win = float('nan')\n",
    "        else:\n",
    "            corr_win = float('nan')\n",
    "\n",
    "        q = torch.quantile(pix_fire_counts, torch.tensor([0.0, 0.5, 0.9, 0.99]))\n",
    "        print(\"\\n=== INPUT DENSITY SUMMARY ===\")\n",
    "        print(f\"empty_frac_all (per-timestep): INPUT={inp_empty_frac_all:.2f} | LIF={lif_empty_frac_all:.2f}\")\n",
    "        print(f\"silent_pixels_frac: {silent_pixels_frac:.2f}\")\n",
    "        print(f\"pix_fire_counts quantiles [min,median,p90,p99]: {q.tolist()}\")\n",
    "        print(f\"corr(window_sum_in, window_sum_lif): {corr_win:.3f}\")\n",
    "    # --------------------------------------------------------------------\n",
    "   \n",
    "    rpt = meter.report()\n",
    "    if getattr(meter, \"samples\", 0) == 0:\n",
    "        print(\"!! meter: no samples logged — проверь порядок log_sample()/reset() и continue в цикле\")\n",
    "    out = {**asdict(cfg), **rpt}\n",
    "    return out, connection, lif_layer\n",
    "\n",
    "# ====== Grid Runner (compact) ======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8eb2b6-28b4-499d-9679-d66f8b0c23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Cfg(\n",
    "    time=200,\n",
    "    n_hidden=100,\n",
    "    encoder=\"poisson\",                 # сначала Poisson\n",
    "    top_k=3,                           # WTA выкл. для диагностики\n",
    "    enable_inhibition_at_start=False,  # ингибицию включим позже\n",
    "   \n",
    "    poisson_rate_scale = 0.006\n",
    ")\n",
    "res = run_experiment(cfg, verbose=True)\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314ca5-f60c-435e-945a-7594a098bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "# Сетка значений для сканирования\n",
    "scales = [0.002, 0.004, 0.006, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "results = []\n",
    "print(\"scan poisson_rate_scale → [spikes/sample, winners_unique, HHI, energy_proxy]\\n\")\n",
    "for s in scales:\n",
    "    cfg_s = Cfg(**{**asdict(cfg), \"poisson_rate_scale\": s})\n",
    "    res = run_experiment(cfg_s, verbose=False)\n",
    "    results.append(res)\n",
    "    print(f\"{s:>6}: {res['spikes_per_sample']:.2f}, \"\n",
    "          f\"{res['winners_unique']}, \"\n",
    "          f\"{res['winner_HHI']:.3f}, \"\n",
    "          f\"{res['energy_proxy_per_sample']:.1f}\")\n",
    "\n",
    "# Простейший отбор «разумных» настроек:\n",
    "#   - хотим winners_unique > 0 (есть специализация)\n",
    "#   - хотим умеренную активность (не лавина): spikes_per_sample в [20, 400] (подправь под свою цель)\n",
    "#   - минимизируем energy_proxy_per_sample\n",
    "candidates = [\n",
    "    r for r in results\n",
    "    if r[\"winners_unique\"] > 0 and 20 <= r[\"spikes_per_sample\"] <= 400\n",
    "]\n",
    "if candidates:\n",
    "    best = min(candidates, key=lambda r: r[\"energy_proxy_per_sample\"])\n",
    "    print(\"\\nBEST (by lowest energy among reasonable activity):\")\n",
    "    print({k: best[k] for k in [\"poisson_rate_scale\",\"spikes_per_sample\",\n",
    "                                \"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "else:\n",
    "    print(\"\\nNo reasonable candidates found — relax constraints or widen scales.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f981614-7982-4266-86e8-e76f58315789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools, csv, math, traceback\n",
    "\n",
    "# ---- настрой сетку здесь ----\n",
    "param_grid = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # ОТРИЦАТЕЛЬНЫЕ\n",
    "    \"top_k\":              [0, 1, 3, 4, 5],\n",
    "    # если захочешь — добавь сюда \"time\", \"n_hidden\", но тогда меняй сборку cfg ниже\n",
    "}\n",
    "\n",
    "def grid_search(param_grid, out_csv=\"grid_results.csv\", seed=42, verbose_every=0):\n",
    "    keys = list(param_grid.keys())\n",
    "    vals = [param_grid[k] for k in keys]\n",
    "    total = 1\n",
    "    for v in vals: total *= len(v)\n",
    "    print(f\"Комбинаций: {total}\")\n",
    "\n",
    "    # CSV\n",
    "    header = keys + [\n",
    "        \"spikes_per_sample\",\n",
    "        \"winners_unique\",\n",
    "        \"winner_HHI\",\n",
    "        \"energy_proxy_per_sample\",\n",
    "    ]\n",
    "    f = open(out_csv, \"w\", newline=\"\")\n",
    "    writer = csv.writer(f); writer.writerow(header)\n",
    "\n",
    "    best = []  # будем хранить топ-5\n",
    "    def score(res):\n",
    "        # цель: больше специализации, меньше энергии и лишних спайков\n",
    "        # комбинированный ключ: (-winners_unique, winner_HHI возм., energy, spikes)\n",
    "        # но для сортировки возьмём tuple (энергия, -winners_unique, winner_HHI)\n",
    "        return (res[\"energy_proxy_per_sample\"], -res[\"winners_unique\"], res[\"winner_HHI\"])\n",
    "\n",
    "    with tqdm(total=total, desc=\"Grid search\") as pbar:\n",
    "        for combo in itertools.product(*vals):\n",
    "            cfg_dict = dict(zip(keys, combo))\n",
    "            try:\n",
    "                cfg = Cfg(\n",
    "                    time=200,\n",
    "                    n_hidden=100,\n",
    "                    encoder=\"poisson\",\n",
    "                    top_k=int(cfg_dict[\"top_k\"]),\n",
    "                    enable_inhibition_at_start=False,\n",
    "                    nu_plus=float(cfg_dict[\"nu_plus\"]),\n",
    "                    nu_minus=float(cfg_dict[\"nu_minus\"]),           # отрицательные допустимы\n",
    "                    poisson_rate_scale=float(cfg_dict[\"poisson_rate_scale\"]),\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                res = run_experiment(cfg, verbose=False)\n",
    "                row = [cfg_dict[k] for k in keys] + [\n",
    "                    res[\"spikes_per_sample\"],\n",
    "                    res[\"winners_unique\"],\n",
    "                    res[\"winner_HHI\"],\n",
    "                    res[\"energy_proxy_per_sample\"],\n",
    "                ]\n",
    "                writer.writerow(row); f.flush()\n",
    "\n",
    "                # обновить топ-5\n",
    "                best.append(res)\n",
    "                best.sort(key=score)\n",
    "                if len(best) > 5: best = best[:5]\n",
    "\n",
    "            except Exception as e:\n",
    "                # логируем «плохую» точку\n",
    "                row = [cfg_dict[k] for k in keys] + [\"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"]\n",
    "                writer.writerow(row); f.flush()\n",
    "                print(\"\\n[WARN] Ошибка на комбе:\", cfg_dict)\n",
    "                traceback.print_exc()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(\"\\nTop-5 (по энерго-метрике с приоритетом специализации):\")\n",
    "    for i, r in enumerate(best, 1):\n",
    "        short = {\n",
    "            \"poisson_rate_scale\": r.get(\"poisson_rate_scale\", None) if isinstance(r.get(\"poisson_rate_scale\", None), (int,float)) else None,\n",
    "            \"nu_plus\": r.get(\"nu_plus\", None) if isinstance(r.get(\"nu_plus\", None), (int,float)) else None,\n",
    "            \"nu_minus\": r.get(\"nu_minus\", None) if isinstance(r.get(\"nu_minus\", None), (int,float)) else None,\n",
    "            \"top_k\": r.get(\"top_k\", None) if isinstance(r.get(\"top_k\", None), (int,float)) else None,\n",
    "            \"spikes_per_sample\": r[\"spikes_per_sample\"],\n",
    "            \"winners_unique\": r[\"winners_unique\"],\n",
    "            \"winner_HHI\": r[\"winner_HHI\"],\n",
    "            \"energy_proxy_per_sample\": r[\"energy_proxy_per_sample\"],\n",
    "        }\n",
    "        print(f\"{i}.\", short)\n",
    "\n",
    "    print(f\"\\nСохранено: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b10dc-1cd8-4c72-8fd6-a449cb7a4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- настрой сетку здесь ----\n",
    "param_grid_set2 = {\n",
    "    \"poisson_rate_scale\": [0.004, 0.006, 0.008],\n",
    "    \"nu_plus\": [0.001, 0.002, 0.003],\n",
    "    \"nu_minus\": [-0.0005, -0.001, -0.002],\n",
    "    \"top_k\": [0, 3, 5]\n",
    "}\n",
    "param_grid_set1 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # ОТРИЦАТЕЛЬНЫЕ\n",
    "    \"top_k\":              [0,  3,  5,6],\n",
    "    # если захочешь — добавь сюда \"time\", \"n_hidden\", но тогда меняй сборку cfg ниже\n",
    "}\n",
    "param_grid_set3 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.065,],\n",
    "    \"nu_plus\":            [0.0001],\n",
    "    \"nu_minus\":           [-0.001],  # ОТРИЦАТЕЛЬНЫЕ\n",
    "    \"top_k\":              [ 5,6,7,8],\n",
    "    # если захочешь — добавь сюда \"time\", \"n_hidden\", но тогда меняй сборку cfg ниже\n",
    "}\n",
    "\n",
    "grid_search(param_grid_set3, out_csv=\"grid_results_set3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ee5c9-dd5c-472f-ae14-e1691c18b023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5608d0cb-e714-4826-9ac0-0e7422dce145",
   "metadata": {},
   "source": [
    "Top-5 (по энерго-метрике с приоритетом специализации):\n",
    "1. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 0, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "2. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 3, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "3. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 5, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "4. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 0, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}\n",
    "5. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 3, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6385223-e6d4-45d9-a080-e30a2b9c8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, torch\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "# ====== 1) SAVE / LOAD ======\n",
    "def save_snn(path, cfg, connection, lif_layer):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "    ckpt = {\n",
    "        \"cfg\": asdict(cfg),\n",
    "        \"W\": connection.w.detach().cpu(),\n",
    "        \"v_thresh\": vt.detach().cpu(),\n",
    "    }\n",
    "    torch.save(ckpt, path)\n",
    "    print(f\"Saved to {path} | W {tuple(ckpt['W'].shape)}\")\n",
    "\n",
    "def load_weights_into(net, connection, lif_layer, ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        connection.w.copy_(ckpt[\"W\"])\n",
    "        vt = ckpt[\"v_thresh\"]\n",
    "        if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh.copy_(vt)\n",
    "        else: lif_layer.thresh.copy_(vt)\n",
    "    print(f\"Loaded from {ckpt_path}\")\n",
    "\n",
    "# ====== 2) КАЛИБРОВКА (нейрон -> метка) ======\n",
    "@torch.no_grad()\n",
    "def build_label_map(net, input_layer, lif_layer, encoder, n_calib=2000, T=200, top_k=3, seed=123):\n",
    "    # выключаем обучение\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_eval_tmp\")\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_train = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_calib, len(ds_train))))\n",
    "    usage = torch.zeros((lif_layer.n,), dtype=torch.long)          # сколько раз нейрон выигрывал\n",
    "    wins  = torch.zeros((lif_layer.n, 10), dtype=torch.long)       # нейрон x класс\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)  # фиксируем стохастику Poisson per-sample\n",
    "        x = ds_train[i][\"image\"]\n",
    "        y = int(ds_train[i][\"label\"])\n",
    "        spikes_in = encoder(x)                       # [T,1,784]\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        # выбираем победителей по сумме спайков за окно\n",
    "        s = lif_mon.get(\"s\")                         # [T,1,N]\n",
    "        s2 = s[:,0,:]                                # [T,N]\n",
    "        counts = s2.sum(0)                           # [N]\n",
    "        if counts.sum() > 0:\n",
    "            k = min(top_k, lif_layer.n)\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            for j in topi.tolist():\n",
    "                usage[j] += 1\n",
    "                wins[j, y] += 1\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    net.monitors.pop(\"lif_eval_tmp\", None)\n",
    "\n",
    "    # нейронная метка = argmax по классам (если нейрон хоть раз выигрывал)\n",
    "    label_map = -torch.ones((lif_layer.n,), dtype=torch.long)\n",
    "    active = (usage > 0).nonzero().flatten().tolist()\n",
    "    for j in active:\n",
    "        label_map[j] = wins[j].argmax().item()\n",
    "\n",
    "    covered = int((label_map >= 0).sum())\n",
    "    print(f\"Label-map built: {covered}/{lif_layer.n} neurons assigned; active winners {int((usage>0).sum())}\")\n",
    "    return label_map\n",
    "\n",
    "# ====== 3) ОЦЕНКА НА TEST ======\n",
    "@torch.no_grad()\n",
    "def evaluate_on_mnist(net, input_layer, lif_layer, encoder, label_map, T=200, top_k=3, n_test=1000, seed=999):\n",
    "    # freeze learning\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_test_tmp\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_test = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_test, len(ds_test))))\n",
    "\n",
    "    correct = 0\n",
    "    meter = SNNMeter()\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)\n",
    "        x = ds_test[i][\"image\"]; y = int(ds_test[i][\"label\"])\n",
    "        spikes_in = encoder(x)\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        s_full = lif_mon.get(\"s\")              # [T,1,N]\n",
    "        s2 = s_full[:,0,:]                     # [T,N]\n",
    "        counts = s2.sum(0)                     # [N]\n",
    "\n",
    "        # WTA на оценке — берём top_k нейронов и голосуем их метками\n",
    "        k = min(top_k, lif_layer.n)\n",
    "        if counts.sum() == 0:\n",
    "            pred = -1\n",
    "        else:\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            votes = torch.zeros(10, dtype=torch.float32)\n",
    "            for j, v in zip(topi.tolist(), topv.tolist()):\n",
    "                lbl = int(label_map[j].item())\n",
    "                if lbl >= 0: votes[lbl] += float(v)\n",
    "            pred = int(votes.argmax().item()) if votes.sum() > 0 else -1\n",
    "\n",
    "        if pred == y: correct += 1\n",
    "\n",
    "        # энергетика (для контроля)\n",
    "        # создадим фиктивный “input monitor” из тех же спайков\n",
    "        meter.log_sample(s_full, spikes_in, lif_layer.n, T, winners=topi.tolist() if counts.sum()>0 else None)\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    acc = correct / len(idxs)\n",
    "    rpt = meter.report()\n",
    "    net.monitors.pop(\"lif_test_tmp\", None)\n",
    "    print(f\"TEST accuracy: {acc:.3f}  | spikes/sample={rpt['spikes_per_sample']:.2f}  energy≈{rpt['energy_proxy_per_sample']:.1f}\")\n",
    "    return {\"accuracy\": acc, **rpt}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c63233-0d2b-43c2-a3fa-8744a8a2523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем: cpu\n",
      "[lif] thresh = scalar 0.350\n",
      "[lif] tc_decay = scalar 150.000\n",
      "[lif] refrac = 2\n",
      "[lif] reset = 0.0\n",
      "INPUT window sum: 117\n",
      "LIF   window sum: 0\n",
      "[1] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 67\n",
      "[50] total=67 active=13/100 HHI=0.082\n",
      "INPUT window sum: 79\n",
      "LIF   window sum: 0\n",
      "INPUT window sum: 53\n",
      "LIF   window sum: 0\n",
      "[100] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 88\n",
      "LIF   window sum: 0\n",
      "INPUT window sum: 165\n",
      "LIF   window sum: 90\n",
      "[150] total=90 active=7/100 HHI=0.143\n",
      "INPUT window sum: 119\n",
      "LIF   window sum: 11\n",
      "INPUT window sum: 112\n",
      "LIF   window sum: 0\n",
      "[200] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 183\n",
      "LIF   window sum: 641\n",
      "[250] total=641 active=100/100 HHI=0.014\n",
      "INPUT window sum: 157\n",
      "LIF   window sum: 357\n",
      "[300] total=357 active=76/100 HHI=0.018\n",
      "INPUT window sum: 107\n",
      "LIF   window sum: 0\n",
      "[350] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 224\n",
      "LIF   window sum: 366\n",
      "[400] total=366 active=43/100 HHI=0.042\n",
      "INPUT window sum: 146\n",
      "LIF   window sum: 459\n",
      "[450] total=459 active=98/100 HHI=0.010\n",
      "INPUT window sum: 128\n",
      "LIF   window sum: 4\n",
      "[500] total=4 active=2/100 HHI=0.625\n",
      "INPUT window sum: 132\n",
      "LIF   window sum: 110\n",
      "[550] total=110 active=55/100 HHI=0.018\n",
      "INPUT window sum: 119\n",
      "LIF   window sum: 0\n",
      "[600] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 145\n",
      "LIF   window sum: 79\n",
      "[650] total=79 active=13/100 HHI=0.100\n",
      "INPUT window sum: 149\n",
      "LIF   window sum: 91\n",
      "[700] total=91 active=60/100 HHI=0.034\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 243\n",
      "[750] total=243 active=76/100 HHI=0.016\n",
      "INPUT window sum: 130\n",
      "LIF   window sum: 119\n",
      "[800] total=119 active=49/100 HHI=0.022\n",
      "INPUT window sum: 183\n",
      "LIF   window sum: 298\n",
      "[850] total=298 active=45/100 HHI=0.027\n",
      "INPUT window sum: 112\n",
      "LIF   window sum: 0\n",
      "[900] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 186\n",
      "LIF   window sum: 109\n",
      "[950] total=109 active=21/100 HHI=0.121\n",
      "INPUT window sum: 136\n",
      "LIF   window sum: 24\n",
      "[1000] total=24 active=6/100 HHI=0.167\n",
      "\n",
      "SUMMARY: {'spikes_per_sample': 81.135, 'winners_unique': 80, 'winner_HHI': 0.016851851851851854, 'energy_proxy_per_sample': 782.995}\n",
      "Saved to out/snn_mnist.pt | W (784, 100)\n",
      "[lif] thresh = scalar 0.350\n",
      "[lif] tc_decay = scalar 150.000\n",
      "[lif] refrac = 2\n",
      "[lif] reset = 0.0\n",
      "Loaded from out/snn_mnist.pt\n",
      "Label-map built: 64/100 neurons assigned; active winners 64\n",
      "TEST accuracy: 0.099  | spikes/sample=6640.19  energy≈73855.0\n",
      "{'accuracy': 0.099, 'spikes_per_sample': 6640.193, 'synops_per_sample': 1342296.9, 'v_updates_per_sample': 20000.0, 'energy_proxy_per_sample': 73855.038, 'winners_unique': 45, 'winner_HHI': 0.31625799999999993}\n"
     ]
    }
   ],
   "source": [
    "# ====== ПРИМЕР ИСПОЛЬЗОВАНИЯ ======\n",
    "# 1) тренируем как раньше:\n",
    "cfg = Cfg(\n",
    "    time = 200,                 # число тактов симуляции на образ\n",
    "    n_hidden = 100    ,         # количество скрытых нейронов\n",
    "    encoder = \"poisson\",        # кодировщик входа: пуассоновский\n",
    "    top_k = 3           ,       # количество победителей в WTA\n",
    "    enable_inhibition_at_start = False,  # включать ли торможение сразу\n",
    "    nu_plus = 0.0001,           # шаг LTP при STDP\n",
    "    nu_minus = -0.001 ,         # шаг LTD при STDP\n",
    "    poisson_rate_scale = 0.006, # масштаб интенсивности пуассоновских потоков\n",
    "    device = \"cpu\",             # устройство вычислений\n",
    "    log_every = 50 ,            # логирование каждые N шагов/образов\n",
    "    N = 1000   ,                # размер датасета\n",
    "    vt_mean = 0.35,             # средний порог возбуждения нейронов\n",
    "    vt_jitter = 0.02   ,        # разброс порогов по нейронам\n",
    "    tau_val = 150.0   ,          # константа времени утечки мембраны (aka tc_decay)\n",
    "    refrac_val = 2.0  ,         # рефрактерный период после спайка\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "res, connection, lif_layer = run_experiment(cfg, verbose=True)   # тут ты уже обучал\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "\n",
    "# 2) сохраняем после обучения:\n",
    "save_snn(\"out/snn_mnist.pt\", cfg, connection, lif_layer)\n",
    "\n",
    "# 3) для оценки — пересобираем сеть (или используем текущую), грузим веса:\n",
    "net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "\n",
    "load_weights_into(net, connection, lif_layer, \"out/snn_mnist.pt\")\n",
    "\n",
    "# 4) тот же энкодер, что и при обучении:\n",
    "encoder, _ = make_encoder(\"poisson\", T=cfg.time)\n",
    "\n",
    "# 5) калибруем нейрон→метка по train (без обучения!):\n",
    "label_map = build_label_map(net, input_layer, lif_layer, encoder,  n_calib=2000, T=cfg.time, top_k=cfg.top_k)\n",
    "\n",
    "# 6) считаем accuracy на test:\n",
    "test_report = evaluate_on_mnist(net, input_layer, lif_layer, encoder,label_map, T=cfg.time, top_k=cfg.top_k, n_test=1000)\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0968c3-e842-48ce-860b-9beff1f775a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
