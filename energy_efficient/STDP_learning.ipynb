{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f620028-87ed-4c99-a115-950ce07e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LatencyEncoder:\n",
    "    def __init__(self, time: int = 100):\n",
    "        self.time = time  # –û–±—â–µ–µ —á–∏—Å–ª–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤\n",
    "\n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        image: Tensor [1, 28, 28] –∏–ª–∏ [28, 28], –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1 –∏–ª–∏ –¥–æ 255\n",
    "        return: spike_tensor [time, 1, 784]\n",
    "        \"\"\"\n",
    "        if image.ndim == 3:\n",
    "            image = image.squeeze()\n",
    "\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "\n",
    "        spike_tensor = torch.zeros((self.time, 1, 784))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                pixel = image[i, j].item()\n",
    "                if pixel > 0:\n",
    "                    spike_time = int((1.0 - pixel) * (self.time - 1))\n",
    "                    spike_tensor[spike_time, 0, i * 28 + j] = 1.0\n",
    "\n",
    "        return spike_tensor.view(self.time, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d52ed814-94e5-4deb-835c-2ebbcd9483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_input_health(in_s_full, T, name=\"INPUT\", expected_total=None):\n",
    "    # in_s_full: [T,B,784] –∏–ª–∏ [T,784]\n",
    "    s = in_s_full[:,0,:] if in_s_full.dim()==3 else in_s_full  # [T,784]\n",
    "    T_, N = s.shape\n",
    "    assert T_ == T, f\"T mismatch: {T_}!={T}\"\n",
    "    per_pix = s.sum(0)         # [N] —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –ø–∏–∫—Å–µ–ª—å –∑–∞ –æ–∫–Ω–æ\n",
    "    per_t   = s.sum(1)         # [T] —Å–ø–∞–π–∫–æ–≤ –Ω–∞ —Ç–∞–∫—Ç\n",
    "\n",
    "    total  = int(per_pix.sum().item())\n",
    "    mean_t = float(per_t.mean().item())\n",
    "    max_t  = int(per_t.max().item())\n",
    "    frac_silent_pixels = float((per_pix == 0).float().mean().item())\n",
    "    frac_empty_timesteps = float((per_t == 0).float().mean().item())\n",
    "    frac_dense_timesteps = float((per_t > 0.1*N).float().mean().item())  # >10% –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å—Ç—Ä–µ–ª—è—é—Ç\n",
    "\n",
    "    # –ù–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –ø–∏–∫—Å–µ–ª—è–º\n",
    "    if total > 0:\n",
    "        p = (per_pix / total).clamp_min(1e-12)\n",
    "        import math\n",
    "        H = float((-(p * p.log()).sum().item()))           # nats\n",
    "        H_norm = H / math.log(N)                           # 0..1\n",
    "    else:\n",
    "        H_norm = 0.0\n",
    "\n",
    "    # –¢–æ–ø-8 ¬´—Å–∞–º—ã—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö¬ª –ø–∏–∫—Å–µ–ª–µ–π (–¥–ª—è –≥—Ä—É–±–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)\n",
    "    topk = torch.topk(per_pix, k=min(8, N))\n",
    "    topk_vals = [int(v) for v in topk.values.tolist()]\n",
    "\n",
    "    # –ü–µ—á–∞—Ç—å\n",
    "    print(f\"{name} window total: {total}\"\n",
    "          + (f\" | expected‚âà{int(expected_total)}\" if expected_total is not None else \"\"))\n",
    "    print(f\"{name} per-timestep: mean={mean_t:.1f}, max={max_t}\")\n",
    "    print(f\"{name} pixels: silent_frac={frac_silent_pixels:.3f}, H_norm={H_norm:.3f}\")\n",
    "    print(f\"{name} timesteps: empty_frac={frac_empty_timesteps:.3f}, dense>10%={frac_dense_timesteps:.3f}\")\n",
    "    print(f\"{name} top-8 pixel counts: {topk_vals}\")\n",
    "\n",
    "    # –í–æ–∑–≤—Ä–∞—Ç –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ —Ñ–∞–π–ª)\n",
    "    return dict(\n",
    "        total=total, mean_per_timestep=mean_t, max_per_timestep=max_t,\n",
    "        frac_silent_pixels=frac_silent_pixels, frac_empty_timesteps=frac_empty_timesteps,\n",
    "        frac_dense_timesteps=frac_dense_timesteps, H_norm=H_norm, top8=topk_vals\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297294ce-41ea-4446-bfed-081c022d6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stdp_nu(conn, nu_plus, nu_minus):\n",
    "    dev = conn.w.device\n",
    "    conn.update_rule.nu = (torch.tensor(nu_plus, device=dev),\n",
    "                           torch.tensor(nu_minus, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04cd6b1-9541-4bf7-bfec-daba59b3f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–¥ run_experiment\n",
    "class ThreshEMA:\n",
    "    def __init__(self): self.rate_ema = None\n",
    "    def step(self, layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "        with torch.no_grad():\n",
    "            rate = spike_counts / max(1, T)\n",
    "            if self.rate_ema is None:\n",
    "                self.rate_ema = rate.clone()\n",
    "            self.rate_ema = alpha * self.rate_ema + (1 - alpha) * rate\n",
    "            vt = layer.v_thresh if hasattr(layer,'v_thresh') else layer.thresh\n",
    "            vt += k * (self.rate_ema - target)\n",
    "            vt.clamp_(0.15, 1.2)\n",
    "            if hasattr(layer,'v_thresh'): layer.v_thresh = vt\n",
    "            else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd656371-a693-4252-9532-7e8105b90ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rate_ema = None\n",
    "def adapt_thresholds_ema(layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "    global _rate_ema\n",
    "    with torch.no_grad():\n",
    "        rate = spike_counts / max(1, T)\n",
    "        if _rate_ema is None: _rate_ema = rate.clone()\n",
    "        _rate_ema = alpha * _rate_ema + (1 - alpha) * rate\n",
    "        vt = layer.v_thresh if hasattr(layer,\"v_thresh\") else layer.thresh\n",
    "        vt += k * (_rate_ema - target)\n",
    "        vt.clamp_(vt_min, vt_max)  \n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d6059930-22e3-4bdf-af94-50037eb25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_param(module, name, value, prefer_scalar=False, fallback_scalar=None):\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ—Å—Ç–∞–≤–ª—è–µ—Ç module.<name>.\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor —Å–∫–∞–ª—è—Ä–Ω—ã–π (numel()==1) –∏ value –≤–µ–∫—Ç–æ—Ä -> –∫–ª–∞–¥—ë–º 0-D —Ç–µ–Ω–∑–æ—Ä (—Å—Ä. –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ fallback_scalar).\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor –≤–µ–∫—Ç–æ—Ä–Ω—ã–π -> –∫–æ–ø–∏—Ä—É–µ–º –ø–æ —Ñ–æ—Ä–º–µ.\n",
    "    - prefer_scalar=True –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –¥–µ–ª–∞–µ—Ç 0-D (–¥–ª—è refrac/reset).\n",
    "    \"\"\"\n",
    "    if not hasattr(module, name):\n",
    "        return False\n",
    "\n",
    "    cur = getattr(module, name)\n",
    "\n",
    "    # –µ—Å–ª–∏ —ç—Ç–æ Tensor-–±—É—Ñ–µ—Ä\n",
    "    if isinstance(cur, torch.Tensor):\n",
    "        dev, dt = cur.device, cur.dtype\n",
    "\n",
    "        if prefer_scalar:\n",
    "            # –≤—Å–µ–≥–¥–∞ 0-D —Ç–µ–Ω–∑–æ—Ä\n",
    "            val = float(value.mean().item() if torch.is_tensor(value) else value)\n",
    "            setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            return True\n",
    "\n",
    "        if torch.is_tensor(value):\n",
    "            if cur.numel() == 1 and value.numel() > 1:\n",
    "                # –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π, value –≤–µ–∫—Ç–æ—Ä -> –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ/—Ñ–æ–ª–±—ç–∫\n",
    "                val = float(value.mean().item())\n",
    "                if fallback_scalar is not None:\n",
    "                    val = float(fallback_scalar)\n",
    "                setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            else:\n",
    "                if value.shape != cur.shape:\n",
    "                    value = value.view_as(cur)\n",
    "                cur.data.copy_(value.to(dev, dtype=dt))\n",
    "        else:\n",
    "            # value —Å–∫–∞–ª—è—Ä Python -> –ø—Ä–æ—Å—Ç–æ –∑–∞–ª–∏–≤–∞–µ–º\n",
    "            if cur.numel() == 1:\n",
    "                setattr(module, name, torch.tensor(float(value), device=dev, dtype=dt))\n",
    "            else:\n",
    "                cur.data.fill_(float(value))\n",
    "        return True\n",
    "\n",
    "    # –Ω–µ Tensor-–±—É—Ñ–µ—Ä ‚Äì –æ–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç\n",
    "    setattr(module, name, float(value) if prefer_scalar else value)\n",
    "    return True\n",
    "\n",
    "def debug_all_params(lif_layer):\n",
    "    print(\"=== attributes ===\")\n",
    "    for k in dir(lif_layer):\n",
    "        if not k.startswith(\"_\"):\n",
    "            try:\n",
    "                v = getattr(lif_layer, k)\n",
    "                if torch.is_tensor(v):\n",
    "                    print(f\"{k}: tensor shape={tuple(v.shape)}, first={v.flatten()[0].item():.6g}\")\n",
    "                else:\n",
    "                    print(f\"{k}: {type(v)}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    print(\"\\n=== named_parameters ===\")\n",
    "    for name, p in lif_layer.named_parameters():\n",
    "        print(f\"{name}: shape={tuple(p.shape)}, requires_grad={p.requires_grad}\")\n",
    "\n",
    "    print(\"\\n=== named_buffers ===\")\n",
    "    for name, b in lif_layer.named_buffers():\n",
    "        print(f\"{name}: shape={tuple(b.shape)}\")\n",
    "\n",
    "def tune_lif_params(lif_layer, n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0):\n",
    "    with torch.no_grad():\n",
    "        # –ø–æ—Ä–æ–≥: –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä; –µ—Å–ª–∏ –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π ‚Äî –∞–≤—Ç–æ-–¥–∞—É–Ω–º–∏–∫—Å –≤ —Å–∫–∞–ª—è—Ä\n",
    "        vt_vec = (vt_mean + vt_jitter * torch.randn(n_hidden)).clamp(0.05, 2.0)\n",
    "        if not _set_param(lif_layer, \"v_thresh\", vt_vec, fallback_scalar=vt_mean):\n",
    "            _set_param(lif_layer, \"thresh\", vt_vec, fallback_scalar=vt_mean)\n",
    "\n",
    "        # tau: –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å v–µ–∫—Ç–æ—Ä/—Å–∫–∞–ª—è—Ä –≤ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö)\n",
    "        if not _set_param(lif_layer, \"tc_decay\", torch.full((n_hidden,), tau_val), fallback_scalar=tau_val):\n",
    "            _set_param(lif_layer, \"tc_decay\",   torch.full((n_hidden,), tau_val),   fallback_scalar=tau_val)\n",
    "\n",
    "        # refrac ‚Äî —Å—Ç—Ä–æ–≥–æ —Å–∫–∞–ª—è—Ä (0-D)\n",
    "        _set_param(lif_layer, \"refrac\", refrac_val, prefer_scalar=True)\n",
    "\n",
    "        # reset ‚Äî —Å–∫–∞–ª—è—Ä\n",
    "        if not _set_param(lif_layer, \"v_reset\", 0.0, prefer_scalar=True):\n",
    "            _set_param(lif_layer, \"reset\",  0.0, prefer_scalar=True)\n",
    "\n",
    "def print_lif_params(lif_layer):\n",
    "    with torch.no_grad():\n",
    "        #debug_all_params(lif_layer)\n",
    "        # –ü–æ—Ä–æ–≥\n",
    "        for key in [\"v_thresh\", \"thresh\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                if torch.is_tensor(val):\n",
    "                    if val.ndim == 0:\n",
    "                        print(f\"[lif] {key} = scalar {val.item():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"[lif] {key} = vector shape={tuple(val.shape)}, \"\n",
    "                              f\"mean={val.mean():.3f}, min={val.min():.3f}, max={val.max():.3f}\")\n",
    "                else:\n",
    "                    print(f\"[lif] {key} = {val}\")\n",
    "        \n",
    "        # Tau\n",
    "        for key in [\"tc_decay\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                if torch.is_tensor(val):\n",
    "                    if val.ndim == 0:\n",
    "                        print(f\"[lif] {key} = scalar {val.item():.3f}\")\n",
    "                    else:\n",
    "                        print(f\"[lif] {key} = vector shape={tuple(val.shape)}, \"\n",
    "                              f\"value‚âà{val[0].item():.3f} (all equal?)\")\n",
    "                else:\n",
    "                    print(f\"[lif] {key} = {val}\")\n",
    "        \n",
    "        # Refrac\n",
    "        if hasattr(lif_layer, \"refrac\"):\n",
    "            val = getattr(lif_layer, \"refrac\")\n",
    "            print(f\"[lif] refrac = {val if not torch.is_tensor(val) else val.item()}\")\n",
    "\n",
    "        # Reset\n",
    "        for key in [\"v_reset\", \"reset\"]:\n",
    "            if hasattr(lif_layer, key):\n",
    "                val = getattr(lif_layer, key)\n",
    "                print(f\"[lif] {key} = {val if not torch.is_tensor(val) else val.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "738905c1-a267-41b6-a110-1df68fe5eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Config ======\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    # core\n",
    "    time:   int = 200\n",
    "    n_hidden: int = 100\n",
    "    nu_plus:  float = 0.02\n",
    "    nu_minus: float = -0.02\n",
    "\n",
    "    # inhibition / WTA\n",
    "    inhib_strength: float = 0.3\n",
    "    inh_decay: float = 0.9\n",
    "    top_k: int = 0                    # 0 = WTA off for diagnostics\n",
    "    enable_inhibition_at_start: bool = False\n",
    "\n",
    "    # encoder\n",
    "    encoder: str = \"latency\"         # start with Poisson to \"ignite\" spikes\n",
    "\n",
    "    # homeostasis\n",
    "    target_spikes: float = 2.0\n",
    "    eta_up: float = 1.0\n",
    "    eta_down: float = 0.5\n",
    "    thresh_min: float = 0.2\n",
    "    thresh_max: float = 2.0\n",
    "    thresh_init: float = 0.5          # v_thresh initial (BindsNET positive scale)\n",
    "\n",
    "    # weights\n",
    "    w_clip_min: float = 0.0\n",
    "    w_clip_max: float = 1.5\n",
    "    w_col_target_norm: float = 20.0\n",
    "    w_init_lo: float = 0.8\n",
    "    w_init_hi: float = 1.2\n",
    "    wmin:float = 0.0\n",
    "    wmax:float = 2.0\n",
    "    warmup_N: int = 50\n",
    "    # loop\n",
    "    N: int = 200\n",
    "    log_every: int = 50\n",
    "    seed: int = 42\n",
    "    poisson_rate_scale: float = 0.7 \n",
    "    device: str = \"cpu\"\n",
    "    vt_mean:float = 0.35\n",
    "    vt_jitter:float = 0.02\n",
    "    tau_val:float = 50.0\n",
    "    refrac_val:float = 2.0\n",
    "    debug:bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080659-6ab0-4b4c-9dc8-1a070c04babe",
   "metadata": {},
   "source": [
    "# üß† Spiking Neural Network (SNN) –Ω–∞ –±–∞–∑–µ BindsNET —Å –æ–±—É—á–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ STDP\n",
    "\n",
    "–í —ç—Ç–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è —Å–ø–∞–π–∫–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å (SNN) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST.\n",
    "\n",
    "## üìå –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏:\n",
    "- **–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`Input`, 784 –Ω–µ–π—Ä–æ–Ω–∞)** ‚Äî –ø–æ –æ–¥–Ω–æ–º—É –Ω–µ–π—Ä–æ–Ω—É –Ω–∞ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 28√ó28.\n",
    "- **Poisson-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫** ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —è—Ä–∫–æ—Å—Ç—å –ø–∏–∫—Å–µ–ª–µ–π –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π (`Connection`)** ‚Äî —Å–æ–µ–¥–∏–Ω—è–µ—Ç –≤—Ö–æ–¥ —Å –≤—ã—Ö–æ–¥–æ–º (–º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ 784 √ó 100).\n",
    "- **–í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`LIF`, 100 –Ω–µ–π—Ä–æ–Ω–æ–≤)** ‚Äî Leaky Integrate-and-Fire –Ω–µ–π—Ä–æ–Ω—ã —Å —É—Ç–µ—á–∫–æ–π –∏ –ø–æ—Ä–æ–≥–æ–º.\n",
    "- **STDP (Spike-Timing Dependent Plasticity)** ‚Äî –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤; –≤–µ—Å–∞ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è, –µ—Å–ª–∏ –≤—Ö–æ–¥ –∞–∫—Ç–∏–≤–µ–Ω –¥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∞–π–∫–∞.\n",
    "\n",
    "## üî¨ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è:\n",
    "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ MNIST.\n",
    "2. –ö–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ Poisson-—Å–ø–∞–π–∫–æ–≤—ã–π –ø–æ—Ç–æ–∫.\n",
    "3. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–µ—Ç—å:\n",
    "   - `Input` –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏,\n",
    "   - `LIF` –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Å–æ–≤.\n",
    "4. –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:\n",
    "   - –°–ø–∞–π–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å `LIF`-–Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ –ø–æ–¥–∞—á–∏ –≤—Ö–æ–¥–∞.\n",
    "   - –°—É–º–º–∞ —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ (`Input`) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø–∏–∫—Å–µ–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã.\n",
    "   - –í–µ—Å–∞ –æ–¥–Ω–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ `LIF`-–Ω–µ–π—Ä–æ–Ω–∞ ‚Äî –¥–æ –∏ –ø–æ—Å–ª–µ STDP.\n",
    "\n",
    "## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:\n",
    "- –ì—Ä–∞—Ñ–∏–∫: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–∞–π–∫–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ/–ø–æ—Å–ª–µ + –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- –ì—Ä–∞—Ñ–∏–∫: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤, –≤–µ–¥—É—â–∏—Ö –∫ –Ω–µ–π—Ä–æ–Ω—É `LIF[42]` ‚Äî –≤–∏–¥–Ω–æ, –∫–∞–∫ STDP —É—Å–∏–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–≤—è–∑–∏.\n",
    "\n",
    "## üéØ –¶–µ–ª—å:\n",
    "–ü–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ SNN:\n",
    "- –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ—Ç–æ–∫ —Å–ø–∞–π–∫–æ–≤,\n",
    "- –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã,\n",
    "- –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ (STDP), –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62625648-17a4-47af-9950-dfa00b772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SETUP (Colab/Local) ======\n",
    "# !pip -q install bindsnet==0.2.8 torchvision==0.18.1 torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import os, itertools, random, csv, time as _ptime\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Utils ======\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def to_2d(s):  # [T,N] or [T,1,N] -> [T,N]\n",
    "    return s[:,0,:] if (s.dim()==3 and s.size(1)==1) else s\n",
    "\n",
    "\n",
    "\n",
    "# ====== Helpers: WTA, norm, thresholds, plots, metrics ======\n",
    "def apply_wta(s, top_k=1):\n",
    "    s2 = to_2d(s)\n",
    "    sb = s2.sum(0).float().squeeze()\n",
    "    if sb.sum() == 0:\n",
    "        return False, None\n",
    "    vals, idxs = torch.topk(sb, k=min(top_k, sb.numel()))\n",
    "    s.zero_()\n",
    "    for j in idxs.tolist():\n",
    "        if s.dim()==3:\n",
    "            s[:,0,j] = True\n",
    "        else:\n",
    "            s[:,j] = True\n",
    "    return True, idxs.tolist()\n",
    "\n",
    "def weight_soft_bound_and_colnorm(conn_w, w_clip_min, w_clip_max, target_norm):\n",
    "    with torch.no_grad():\n",
    "        w = conn_w.data\n",
    "        w.clamp_(w_clip_min, w_clip_max)\n",
    "        col_norm = w.norm(p=1, dim=0, keepdim=True) + 1e-6\n",
    "        w.mul_(target_norm / col_norm)\n",
    "\n",
    "def adapt_thresholds(layer, spike_counts, cfg: Cfg):\n",
    "    with torch.no_grad():\n",
    "        vt = layer.v_thresh if hasattr(layer, \"v_thresh\") else layer.thresh\n",
    "        vt -= 0.05 * (spike_counts < 1.0).float()        # if silent -> lower threshold\n",
    "        vt += 0.02 * (spike_counts > 3.0).float()        # if too active -> raise\n",
    "        vt.clamp_(cfg.thresh_min, cfg.thresh_max)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt\n",
    "\n",
    "def spiking_metrics_window(lif_s, winners=None):\n",
    "    s = to_2d(lif_s).to(torch.bool)\n",
    "    T, N = s.shape\n",
    "    per_n = s.sum(0)\n",
    "    tot = int(per_n.sum())\n",
    "    active = int((per_n > 0).sum())\n",
    "    if tot > 0:\n",
    "        p = (per_n / tot).float().cpu().numpy()\n",
    "        HHI = float((p**2).sum())\n",
    "        ps = np.sort(p)\n",
    "        Gini = float((np.cumsum(ps).sum()/ps.sum() - (len(ps)+1)/2)/len(ps))\n",
    "    else:\n",
    "        HHI, Gini = 1.0, 1.0\n",
    "    uniq_winners = len(set(winners)) if winners else 0\n",
    "    return dict(T=T, N=N, total_spikes=tot, active=active, HHI=HHI, Gini=Gini, uniq_winners=uniq_winners)\n",
    "\n",
    "class SNNMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.samples=0; self.S_out=0; self.S_in=0; self.SynOps=0; self.V_updates=0\n",
    "        self.usage_counts = {}\n",
    "    def log_sample(self, lif_s, in_s, n_hidden, T, winners=None):\n",
    "        lif2 = to_2d(lif_s);  in2 = to_2d(in_s)\n",
    "        s_out = int(lif2.sum().item())\n",
    "        s_in  = int(in2.sum().item())\n",
    "        self.S_out += s_out; self.S_in += s_in\n",
    "        self.SynOps += s_in * n_hidden\n",
    "        self.V_updates += n_hidden * T\n",
    "        self.samples += 1\n",
    "        if winners:\n",
    "            for j in winners:\n",
    "                self.usage_counts[j] = self.usage_counts.get(j,0)+1\n",
    "    def report(self, a=1.0, b=0.05, c=0.005):\n",
    "        s = max(1, self.samples)\n",
    "        HHI_win = 0.0\n",
    "        if self.usage_counts:\n",
    "            tot = sum(self.usage_counts.values())\n",
    "            ps = np.array([v/tot for v in self.usage_counts.values()], dtype=float)\n",
    "            HHI_win = float((ps**2).sum())\n",
    "        return {\n",
    "            \"spikes_per_sample\": self.S_out/s,\n",
    "            \"synops_per_sample\": self.SynOps/s,\n",
    "            \"v_updates_per_sample\": self.V_updates/s,\n",
    "            \"energy_proxy_per_sample\": (a*self.S_out + b*self.SynOps + c*self.V_updates)/s,\n",
    "            \"winners_unique\": len(self.usage_counts),\n",
    "            \"winner_HHI\": HHI_win,\n",
    "        }\n",
    "\n",
    "# ====== Build Net & Encoder ======\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "def build_net(cfg: Cfg):\n",
    "    net = Network()\n",
    "\n",
    "    input_layer = Input(n=784, traces=True)\n",
    "    lif_layer   = LIFNodes(n=cfg.n_hidden, traces=True)\n",
    "    tune_lif_params(lif_layer, cfg.n_hidden, cfg.vt_mean, cfg.vt_jitter, cfg.tau_val, cfg.refrac_val)\n",
    "            \n",
    "    net.add_layer(input_layer, name='Input')\n",
    "    net.add_layer(lif_layer,   name='LIF')\n",
    "    print_lif_params(lif_layer)\n",
    "\n",
    "    connection = Connection(source=input_layer, target=lif_layer)\n",
    "    connection.update_rule = PostPre(connection=connection,\n",
    "                                 nu=(torch.tensor(cfg.nu_plus),\n",
    "                                     torch.tensor(cfg.nu_minus)))\n",
    "    net.add_connection(connection, source='Input', target='LIF')\n",
    "\n",
    "    # Lateral inhibition (created, but optionally disabled at start)\n",
    "    W_inh = torch.full((cfg.n_hidden, cfg.n_hidden), -cfg.inhib_strength)\n",
    "    W_inh.fill_diagonal_(0.0)\n",
    "    recurrent_inh = Connection(source=lif_layer, target=lif_layer, w=W_inh.clone())\n",
    "    net.add_connection(recurrent_inh, source='LIF', target='LIF')\n",
    "\n",
    "    # Weights init (stronger to ignite)\n",
    "    with torch.no_grad():\n",
    "        connection.w.data.uniform_(cfg.w_init_lo, cfg.w_init_hi)\n",
    "\n",
    "    # Thresholds: use v_thresh if available\n",
    "    th0 = torch.full((cfg.n_hidden,), cfg.thresh_init)\n",
    "    if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh = th0.clone()\n",
    "    else: lif_layer.thresh = th0.clone()\n",
    "\n",
    "    # Optionally disable inhibition at start (for diagnostics)\n",
    "    if not cfg.enable_inhibition_at_start:\n",
    "        with torch.no_grad():\n",
    "            recurrent_inh.w.zero_()\n",
    "\n",
    "    return net, input_layer, lif_layer, connection, recurrent_inh, W_inh\n",
    "\n",
    "# –ü—Ä–µ-–ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL / np / tensor)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28), antialias=True),\n",
    "    transforms.ToTensor(),                 # -> [1,28,28] float in [0,1]\n",
    "    # –ù–∏–∫–∞–∫–∏—Ö Normalize(mean,std) –∑–¥–µ—Å—å ‚Äî –Ω–∞–º –Ω—É–∂–Ω—ã ¬´—Å—ã—Ä—ã–µ¬ª 0..1!\n",
    "])\n",
    "\n",
    "def make_encoder(encoder_type: str, T: int, rate_floor: float = 0.0,poisson_rate_scale: float = 0.7 ):  # floor –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0\n",
    "    encoder_type = encoder_type.lower()\n",
    "    assert encoder_type in (\"poisson\", \"latency\")\n",
    "\n",
    "    def encode_poisson(img_tensor):\n",
    "        x = img_tensor.view(-1).clamp(0, 1)\n",
    "        rates = x * poisson_rate_scale\n",
    "        rand = torch.rand((T, rates.numel()), device=rates.device if x.is_cuda else None)\n",
    "        spikes = (rand < rates).float()\n",
    "        return spikes.view(T, 1, 784)\n",
    "\n",
    "    def encode_latency(img_tensor):\n",
    "        x = img_tensor.squeeze(0).clamp(0, 1)\n",
    "        spikes = torch.zeros((T, 1, 784), dtype=torch.float32)\n",
    "        nz = (x > 0).nonzero(as_tuple=False)\n",
    "        if nz.numel() == 0:\n",
    "            return spikes\n",
    "        for idx in nz:\n",
    "            i, j = int(idx[0]), int(idx[1])\n",
    "            p = float(x[i, j])\n",
    "            t = int(round((1.0 - p) * (T - 1)))\n",
    "            # –º–∞–ª–µ–Ω—å–∫–∏–π –¥–∂–∏—Ç—Ç–µ—Ä ¬±1 —Ç–∏–∫ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–∫–Ω–∞)\n",
    "            if T >= 3:\n",
    "                t += int(torch.randint(-1, 2, (1,)).item())\n",
    "                t = max(0, min(T-1, t))\n",
    "            spikes[t, 0, i*28 + j] = 1.0\n",
    "        return spikes\n",
    "\n",
    "    return (encode_poisson if encoder_type == \"poisson\" else encode_latency), preprocess\n",
    "        \n",
    "def _to_2d(s):  # [T, B, N] -> [T, N]\n",
    "    return s[:, 0, :] if s.dim()==3 else s\n",
    "    \n",
    "# ====== One Experiment ======\n",
    "def run_experiment(cfg: Cfg, verbose=True):\n",
    "    set_seed(cfg.seed)\n",
    "    device = cfg.device\n",
    "    print(\"–ò—Å–ø–æ–ª—å–∑—É–µ–º:\", device)\n",
    "    # –î–∞—Ç–∞—Å–µ—Ç (MNIST —É–∂–µ –≤ [0,1] –∏ [1,28,28])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # –°–µ—Ç—å + –º–æ–Ω–∏—Ç–æ—Ä—ã\n",
    "    net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "    net = net.to(device)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # ‚Üì –°–†–ê–ó–£ –ü–û–°–õ–ï build_net(cfg)\n",
    "    with torch.no_grad():\n",
    "        # —É —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π BindsNET –ø–æ—Ä–æ–≥ –ª–µ–∂–∏—Ç –≤ v_thresh –ò–õ–ò –≤ thresh\n",
    "        if hasattr(lif_layer, \"v_thresh\"):\n",
    "            vt = lif_layer.v_thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.v_thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)  # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.v_thresh.fill_(0.12)\n",
    "        else:\n",
    "            vt = lif_layer.thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)   # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.thresh.fill_(0.12)\n",
    "        if hasattr(lif_layer, \"refrac\"):\n",
    "            lif_layer.refrac = torch.tensor(2.0, device=vt.device)  # 2 —Ç–∏–∫–∞\n",
    "            #print(f\"set refrac {lif_layer.refrac}\")\n",
    "            \n",
    "    \n",
    "    # –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –æ—Å—Ç–∞–≤—å print –æ–¥–∏–Ω —Ä–∞–∑\n",
    "    vt_chk = (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\">>> THRESH SET TO:\", float(vt_chk.mean().item()))\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    rf = lif_layer.refrac\n",
    "    #print(\"v_thresh mean¬±std refrac:\", float(vt.mean()), float(vt.std()),rf)\n",
    "    \n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    inp_mon = Monitor(input_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    net.add_monitor(lif_mon, name=\"lif_mon\")\n",
    "    net.add_monitor(inp_mon, name=\"inp_mon\")\n",
    "\n",
    "    # –≠–Ω–∫–æ–¥–µ—Ä\n",
    "    ENCODER_TYPE = cfg.encoder\n",
    "    T = cfg.time\n",
    "    encoder, _ = make_encoder(ENCODER_TYPE, T, poisson_rate_scale=cfg.poisson_rate_scale)\n",
    "\n",
    "    # --- DEBUG METRICS INIT --------------------------------------------\n",
    "    DEBUG = cfg.debug\n",
    "    pix_total = 28 * 28\n",
    "    # –∞–∫–∫—É–º—É–ª–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º—É —Ä–∞–Ωe\n",
    "    inp_empty_steps_total = 0     # —Å–∫–æ–ª—å–∫–æ —Ç–∞–π–º-—Å—Ç–µ–ø–æ–≤ –≤–æ–æ–±—â–µ –ø—É—Å—Ç—ã–µ (–Ω–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö —Å–ø–∞–π–∫–æ–≤)\n",
    "    lif_empty_steps_total = 0\n",
    "    steps_total = 0\n",
    "    pix_fire_counts = torch.zeros(pix_total)  # —Å—É–º–º–∞—Ä–Ω—ã–µ —Å–ø–∞–π–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ø–∏–∫—Å–µ–ª—é\n",
    "    run_pairs = []  # (sum_in_window, sum_lif_window)\n",
    "    # --------------------------------------------------------------------\n",
    "    \n",
    "    # --------- WARMUP (–±–µ–∑ STDP) ---------\n",
    "    WARMUP = getattr(cfg, \"warmup_N\", 50)\n",
    "    if WARMUP > 0:\n",
    "        # –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤ STDP –≤—ã–∫–ª.\n",
    "        set_stdp_nu(connection, 0.0, 0.0)\n",
    "        for wi in range(min(WARMUP, len(dataset))):\n",
    "            image = dataset[wi][\"image\"]\n",
    "             # === –í–°–¢–ê–í–ò–¢–¨ –í –¶–ò–ö–õ –ü–ï–†–ï–î net.run(...) ===\n",
    "            # –û—Ü–µ–Ω–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ —á–∏—Å–ª–∞ –≤—Ö–æ–¥–Ω—ã—Ö —Å–ø–∞–π–∫–æ–≤ (–¥–ª—è Poisson)\n",
    "            if cfg.encoder.lower() == \"poisson\":\n",
    "                # –ï—Å–ª–∏ –≤ Poisson —Ç—ã –¥–µ–ª–∞–µ—à—å: spikes[t] ~ Bernoulli(rate_scale * pixel)\n",
    "                img_mean = float(image.mean().item())  # [0..1]\n",
    "                expected_total = cfg.time * 784 * cfg.poisson_rate_scale * img_mean\n",
    "            else:\n",
    "                expected_total = None\n",
    "            spike_input = encoder(image).to(device)\n",
    "            net.run(inputs={\"Input\": spike_input}, time=cfg.time)\n",
    "\n",
    "            # –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é ‚Äî –ø–æ–ª–µ–∑–Ω–æ)\n",
    "            lif_s_full = lif_mon.get(\"s\")\n",
    "            spike_counts = to_2d(lif_s_full).sum(0).float().squeeze()\n",
    "            # adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "            \n",
    "\n",
    "            # –æ—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "            net.reset_state_variables()\n",
    "            lif_mon.reset_state_variables()\n",
    "            inp_mon.reset_state_variables()\n",
    "\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "    # --------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ---------\n",
    "    with torch.no_grad():\n",
    "        I = torch.eye(cfg.n_hidden, device=recurrent_inh.w.device, dtype=recurrent_inh.w.dtype)\n",
    "        recurrent_inh.w.copy_(-0.55 * (1 - I)) \n",
    "    ema = ThreshEMA()\n",
    "    meter = SNNMeter()\n",
    "    # –º—è–≥–∫–∏–π STDP –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    set_stdp_nu(connection, cfg.nu_plus, cfg.nu_minus) # –±—ã–ª–æ 1e-3 / -5e-4\n",
    "    \n",
    "\n",
    "    for i in range(cfg.N):\n",
    "        sample = dataset[i]\n",
    "        image  = sample[\"image\"]\n",
    "        spike_input = encoder(image).to(device)\n",
    "        inputs = {\"Input\": spike_input}\n",
    "        \n",
    "\n",
    "        net.run(inputs=inputs, time=cfg.time)\n",
    "\n",
    "        # –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\n",
    "        lif_s_full = lif_mon.get(\"s\")   # [T,B,N]\n",
    "        in_s_full  = inp_mon.get(\"s\")   # [T,B,784]\n",
    "        lif2 = _to_2d(lif_s_full); in2 = _to_2d(in_s_full)\n",
    "\n",
    "        # --- DEBUG METRICS PER-WINDOW ---------------------------------\n",
    "        # –ø–æ-–≤—Ä–µ–º–µ–Ω–∏: —Å–∫–æ–ª—å–∫–æ —Å–æ–±—ã—Ç–∏–π –Ω–∞ –∫–∞–∂–¥–æ–º t\n",
    "        inp_t = in2.sum(dim=1).cpu().numpy()   # [T]\n",
    "        lif_t = lif2.sum(dim=1).cpu().numpy()  # [T]\n",
    "        steps_total += T\n",
    "        inp_empty_steps_total += int((inp_t == 0).sum())\n",
    "        lif_empty_steps_total += int((lif_t == 0).sum())\n",
    "        # –ø–æ-–ø–∏–∫—Å–µ–ª—è–º: —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–∏–∫—Å–µ–ª—å —Å—Ç—Ä–µ–ª—è–ª –∑–∞ –æ–∫–Ω–æ\n",
    "        pix_fire_counts += in2.sum(dim=0).cpu()  # [784]\n",
    "        # –æ–∫–Ω–æ-—Å—É–º–º—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ ¬´–æ–∫–Ω–æ –≤—Ö–æ–¥–∞¬ª ‚Üí ¬´–æ–∫–Ω–æ –≤—ã—Ö–æ–¥–∞¬ª\n",
    "        run_pairs.append((float(inp_t.sum()), float(lif_t.sum())))\n",
    "        # --------------------------------------------------------------\n",
    "\n",
    "        # —á–µ–∫–ø–æ–∏–Ω—Ç-–ª–æ–≥ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)\n",
    "        if i in (0, 50, 100, 150, 199) or ((i+1) % cfg.log_every == 0):\n",
    "            print(f\"INPUT window sum: {int(inp_t.sum())}\")\n",
    "            print(f\"LIF   window sum: {int(lif_t.sum())}\")\n",
    "\n",
    "            if DEBUG:\n",
    "                # –¥–æ–ª—è –ø—É—Å—Ç—ã—Ö —Ç–∞–π–º—Å—Ç–µ–ø–æ–≤ –≤ —Ç–µ–∫—É—â–µ–º –æ–∫–Ω–µ\n",
    "                empty_frac_in  = float((inp_t == 0).mean())\n",
    "                empty_frac_lif = float((lif_t == 0).mean())\n",
    "                mean_in_t  = float(inp_t.mean());  max_in_t  = float(inp_t.max(initial=0))\n",
    "                mean_lif_t = float(lif_t.mean());  max_lif_t = float(lif_t.max(initial=0))\n",
    "\n",
    "                # –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø–æ —Ç–∞–π–º-–æ—Å—å: —Å–∫–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π ‚Üî —Å–∫–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥–Ω—ã—Ö\n",
    "                if (inp_t.std() > 1e-8) and (lif_t.std() > 1e-8):\n",
    "                    corr = float(np.corrcoef(inp_t, lif_t)[0,1])\n",
    "                else:\n",
    "                    corr = float('nan')\n",
    "\n",
    "                print(f\"[dbg] per-timestep INPUT mean={mean_in_t:.2f} max={max_in_t} empty_frac={empty_frac_in:.2f}\")\n",
    "                print(f\"[dbg] per-timestep LIF   mean={mean_lif_t:.2f} max={max_lif_t} empty_frac={empty_frac_lif:.2f}\")\n",
    "                print(f\"[dbg] corr(input_t, lif_t)={corr:.3f}\")\n",
    "\n",
    "                # —Ç–æ–ø-8 –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π (–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä, —á—Ç–æ –≤—Ö–æ–¥ –Ω–µ —Å–æ–≤—Å–µ–º ¬´–Ω–µ–º–æ–π¬ª)\n",
    "                topk = torch.topk(pix_fire_counts, k=8)\n",
    "                print(f\"[dbg] top8 pixels counts: {topk.values.int().tolist()}  idx: {topk.indices.tolist()[:8]}\")\n",
    "\n",
    "\n",
    "        # WTA (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n",
    "        winners = []\n",
    "        if cfg.top_k and cfg.top_k > 0:\n",
    "            ok, idxs = apply_wta(lif_layer.s, top_k=cfg.top_k)\n",
    "            winners = idxs if ok and idxs is not None else []\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–∫–Ω–∞\n",
    "        m = spiking_metrics_window(lif_s_full, winners)\n",
    "        if verbose and ((i+1) % cfg.log_every == 0 or i == 0):\n",
    "            print(f\"[{i+1}] total={m['total_spikes']} active={m['active']}/{m['N']} HHI={m['HHI']:.3f}\")\n",
    "\n",
    "        # Homeostasis –ø–æ ¬´—Å—ã—Ä—ã–º¬ª —Å–ø–∞–π–∫–∞–º (–¥–æ WTA)\n",
    "        spike_counts = to_2d(lif_s_full).sum(0).float().to(device)\n",
    "        ema.step(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "\n",
    "        # –ö–ª–∞–º–ø –≤–µ—Å–æ–≤ (–±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –∫–æ–ª–æ–Ω–æ—á–Ω–æ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥—ã–π —à–∞–≥)\n",
    "        with torch.no_grad():\n",
    "            connection.w.clamp_(0.0, 1.0)\n",
    "\n",
    "        # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ / —É—á—ë—Ç\n",
    "        meter.log_sample(lif_s_full, in_s_full, cfg.n_hidden, cfg.time, winners=winners)\n",
    "\n",
    "        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –º–æ–Ω–∏—Ç–æ—Ä–æ–≤\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "        inp_mon.reset_state_variables()\n",
    "\n",
    "        \n",
    "    # --- DEBUG METRICS FINAL SUMMARY -----------------------------------\n",
    "    if DEBUG and steps_total > 0:\n",
    "        inp_empty_frac_all = inp_empty_steps_total / steps_total\n",
    "        lif_empty_frac_all = lif_empty_steps_total / steps_total\n",
    "        silent_pixels_frac = float((pix_fire_counts == 0).float().mean())\n",
    "\n",
    "        # –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è ¬´—Å—É–º–º–∞ –≤—Ö–æ–¥–∞ –ø–æ –æ–∫–Ω—É ‚Üí —Å—É–º–º–∞ –≤—ã—Ö–æ–¥–∞ –ø–æ –æ–∫–Ω—É¬ª\n",
    "        if len(run_pairs) > 1:\n",
    "            inp_sums = np.array([p[0] for p in run_pairs], dtype=float)\n",
    "            lif_sums = np.array([p[1] for p in run_pairs], dtype=float)\n",
    "            if inp_sums.std() > 1e-8 and lif_sums.std() > 1e-8:\n",
    "                corr_win = float(np.corrcoef(inp_sums, lif_sums)[0,1])\n",
    "            else:\n",
    "                corr_win = float('nan')\n",
    "        else:\n",
    "            corr_win = float('nan')\n",
    "\n",
    "        q = torch.quantile(pix_fire_counts, torch.tensor([0.0, 0.5, 0.9, 0.99]))\n",
    "        print(\"\\n=== INPUT DENSITY SUMMARY ===\")\n",
    "        print(f\"empty_frac_all (per-timestep): INPUT={inp_empty_frac_all:.2f} | LIF={lif_empty_frac_all:.2f}\")\n",
    "        print(f\"silent_pixels_frac: {silent_pixels_frac:.2f}\")\n",
    "        print(f\"pix_fire_counts quantiles [min,median,p90,p99]: {q.tolist()}\")\n",
    "        print(f\"corr(window_sum_in, window_sum_lif): {corr_win:.3f}\")\n",
    "    # --------------------------------------------------------------------\n",
    "   \n",
    "    rpt = meter.report()\n",
    "    if getattr(meter, \"samples\", 0) == 0:\n",
    "        print(\"!! meter: no samples logged ‚Äî –ø—Ä–æ–≤–µ—Ä—å –ø–æ—Ä—è–¥–æ–∫ log_sample()/reset() –∏ continue –≤ —Ü–∏–∫–ª–µ\")\n",
    "    out = {**asdict(cfg), **rpt}\n",
    "    return out, connection, lif_layer\n",
    "\n",
    "# ====== Grid Runner (compact) ======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8eb2b6-28b4-499d-9679-d66f8b0c23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Cfg(\n",
    "    time=200,\n",
    "    n_hidden=100,\n",
    "    encoder=\"poisson\",                 # —Å–Ω–∞—á–∞–ª–∞ Poisson\n",
    "    top_k=3,                           # WTA –≤—ã–∫–ª. –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "    enable_inhibition_at_start=False,  # –∏–Ω–≥–∏–±–∏—Ü–∏—é –≤–∫–ª—é—á–∏–º –ø–æ–∑–∂–µ\n",
    "   \n",
    "    poisson_rate_scale = 0.006\n",
    ")\n",
    "res = run_experiment(cfg, verbose=True)\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314ca5-f60c-435e-945a-7594a098bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "# –°–µ—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "scales = [0.002, 0.004, 0.006, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "results = []\n",
    "print(\"scan poisson_rate_scale ‚Üí [spikes/sample, winners_unique, HHI, energy_proxy]\\n\")\n",
    "for s in scales:\n",
    "    cfg_s = Cfg(**{**asdict(cfg), \"poisson_rate_scale\": s})\n",
    "    res = run_experiment(cfg_s, verbose=False)\n",
    "    results.append(res)\n",
    "    print(f\"{s:>6}: {res['spikes_per_sample']:.2f}, \"\n",
    "          f\"{res['winners_unique']}, \"\n",
    "          f\"{res['winner_HHI']:.3f}, \"\n",
    "          f\"{res['energy_proxy_per_sample']:.1f}\")\n",
    "\n",
    "# –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –æ—Ç–±–æ—Ä ¬´—Ä–∞–∑—É–º–Ω—ã—Ö¬ª –Ω–∞—Å—Ç—Ä–æ–µ–∫:\n",
    "#   - —Ö–æ—Ç–∏–º winners_unique > 0 (–µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)\n",
    "#   - —Ö–æ—Ç–∏–º —É–º–µ—Ä–µ–Ω–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–Ω–µ –ª–∞–≤–∏–Ω–∞): spikes_per_sample –≤ [20, 400] (–ø–æ–¥–ø—Ä–∞–≤—å –ø–æ–¥ —Å–≤–æ—é —Ü–µ–ª—å)\n",
    "#   - –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º energy_proxy_per_sample\n",
    "candidates = [\n",
    "    r for r in results\n",
    "    if r[\"winners_unique\"] > 0 and 20 <= r[\"spikes_per_sample\"] <= 400\n",
    "]\n",
    "if candidates:\n",
    "    best = min(candidates, key=lambda r: r[\"energy_proxy_per_sample\"])\n",
    "    print(\"\\nBEST (by lowest energy among reasonable activity):\")\n",
    "    print({k: best[k] for k in [\"poisson_rate_scale\",\"spikes_per_sample\",\n",
    "                                \"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "else:\n",
    "    print(\"\\nNo reasonable candidates found ‚Äî relax constraints or widen scales.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f981614-7982-4266-86e8-e76f58315789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools, csv, math, traceback\n",
    "\n",
    "# ---- –Ω–∞—Å—Ç—Ä–æ–∏ÃÜ —Å–µ—Ç–∫—É –∑–¥–µ—Å—å ----\n",
    "param_grid = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [0, 1, 3, 4, 5],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "\n",
    "def grid_search(param_grid, out_csv=\"grid_results.csv\", seed=42, verbose_every=0):\n",
    "    keys = list(param_grid.keys())\n",
    "    vals = [param_grid[k] for k in keys]\n",
    "    total = 1\n",
    "    for v in vals: total *= len(v)\n",
    "    print(f\"–ö–æ–º–±–∏–Ω–∞—Ü–∏–π: {total}\")\n",
    "\n",
    "    # CSV\n",
    "    header = keys + [\n",
    "        \"spikes_per_sample\",\n",
    "        \"winners_unique\",\n",
    "        \"winner_HHI\",\n",
    "        \"energy_proxy_per_sample\",\n",
    "    ]\n",
    "    f = open(out_csv, \"w\", newline=\"\")\n",
    "    writer = csv.writer(f); writer.writerow(header)\n",
    "\n",
    "    best = []  # –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ø-5\n",
    "    def score(res):\n",
    "        # —Ü–µ–ª—å: –±–æ–ª—å—à–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –º–µ–Ω—å—à–µ —ç–Ω–µ—Ä–≥–∏–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–ø–∞–π–∫–æ–≤\n",
    "        # –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á: (-winners_unique, winner_HHI –≤–æ–∑–º., energy, spikes)\n",
    "        # –Ω–æ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –≤–æ–∑—å–º—ë–º tuple (—ç–Ω–µ—Ä–≥–∏—è, -winners_unique, winner_HHI)\n",
    "        return (res[\"energy_proxy_per_sample\"], -res[\"winners_unique\"], res[\"winner_HHI\"])\n",
    "\n",
    "    with tqdm(total=total, desc=\"Grid search\") as pbar:\n",
    "        for combo in itertools.product(*vals):\n",
    "            cfg_dict = dict(zip(keys, combo))\n",
    "            try:\n",
    "                cfg = Cfg(\n",
    "                    time=200,\n",
    "                    n_hidden=100,\n",
    "                    encoder=\"poisson\",\n",
    "                    top_k=int(cfg_dict[\"top_k\"]),\n",
    "                    enable_inhibition_at_start=False,\n",
    "                    nu_plus=float(cfg_dict[\"nu_plus\"]),\n",
    "                    nu_minus=float(cfg_dict[\"nu_minus\"]),           # –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –¥–æ–ø—É—Å—Ç–∏–º—ã\n",
    "                    poisson_rate_scale=float(cfg_dict[\"poisson_rate_scale\"]),\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                res = run_experiment(cfg, verbose=False)\n",
    "                row = [cfg_dict[k] for k in keys] + [\n",
    "                    res[\"spikes_per_sample\"],\n",
    "                    res[\"winners_unique\"],\n",
    "                    res[\"winner_HHI\"],\n",
    "                    res[\"energy_proxy_per_sample\"],\n",
    "                ]\n",
    "                writer.writerow(row); f.flush()\n",
    "\n",
    "                # –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–ø-5\n",
    "                best.append(res)\n",
    "                best.sort(key=score)\n",
    "                if len(best) > 5: best = best[:5]\n",
    "\n",
    "            except Exception as e:\n",
    "                # –ª–æ–≥–∏—Ä—É–µ–º ¬´–ø–ª–æ—Ö—É—é¬ª —Ç–æ—á–∫—É\n",
    "                row = [cfg_dict[k] for k in keys] + [\"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"]\n",
    "                writer.writerow(row); f.flush()\n",
    "                print(\"\\n[WARN] –û—à–∏–±–∫–∞ –Ω–∞ –∫–æ–º–±–µ:\", cfg_dict)\n",
    "                traceback.print_exc()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(\"\\nTop-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\")\n",
    "    for i, r in enumerate(best, 1):\n",
    "        short = {\n",
    "            \"poisson_rate_scale\": r.get(\"poisson_rate_scale\", None) if isinstance(r.get(\"poisson_rate_scale\", None), (int,float)) else None,\n",
    "            \"nu_plus\": r.get(\"nu_plus\", None) if isinstance(r.get(\"nu_plus\", None), (int,float)) else None,\n",
    "            \"nu_minus\": r.get(\"nu_minus\", None) if isinstance(r.get(\"nu_minus\", None), (int,float)) else None,\n",
    "            \"top_k\": r.get(\"top_k\", None) if isinstance(r.get(\"top_k\", None), (int,float)) else None,\n",
    "            \"spikes_per_sample\": r[\"spikes_per_sample\"],\n",
    "            \"winners_unique\": r[\"winners_unique\"],\n",
    "            \"winner_HHI\": r[\"winner_HHI\"],\n",
    "            \"energy_proxy_per_sample\": r[\"energy_proxy_per_sample\"],\n",
    "        }\n",
    "        print(f\"{i}.\", short)\n",
    "\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df7b10dc-1cd8-4c72-8fd6-a449cb7a4505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–º–±–∏–Ω–∞—Ü–∏–π: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [04:54<00:00, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\n",
      "1. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 8, 'spikes_per_sample': 18.885, 'winners_unique': 35, 'winner_HHI': 0.036458333333333336, 'energy_proxy_per_sample': 711.21}\n",
      "2. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 7, 'spikes_per_sample': 18.885, 'winners_unique': 32, 'winner_HHI': 0.03854875283446711, 'energy_proxy_per_sample': 711.21}\n",
      "3. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 6, 'spikes_per_sample': 18.885, 'winners_unique': 28, 'winner_HHI': 0.04166666666666667, 'energy_proxy_per_sample': 711.21}\n",
      "4. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 5, 'spikes_per_sample': 18.885, 'winners_unique': 25, 'winner_HHI': 0.04666666666666667, 'energy_proxy_per_sample': 711.21}\n",
      "5. {'poisson_rate_scale': 0.065, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 8, 'spikes_per_sample': 1419.19, 'winners_unique': 94, 'winner_HHI': 0.017494960947341893, 'energy_proxy_per_sample': 7970.165}\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: grid_results_set3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- –Ω–∞—Å—Ç—Ä–æ–∏ÃÜ —Å–µ—Ç–∫—É –∑–¥–µ—Å—å ----\n",
    "param_grid_set2 = {\n",
    "    \"poisson_rate_scale\": [0.004, 0.006, 0.008],\n",
    "    \"nu_plus\": [0.001, 0.002, 0.003],\n",
    "    \"nu_minus\": [-0.0005, -0.001, -0.002],\n",
    "    \"top_k\": [0, 3, 5]\n",
    "}\n",
    "param_grid_set1 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [0,  3,  5,6],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "param_grid_set3 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.065,],\n",
    "    \"nu_plus\":            [0.0001],\n",
    "    \"nu_minus\":           [-0.001],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [ 5,6,7,8],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "\n",
    "grid_search(param_grid_set3, out_csv=\"grid_results_set3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ee5c9-dd5c-472f-ae14-e1691c18b023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5608d0cb-e714-4826-9ac0-0e7422dce145",
   "metadata": {},
   "source": [
    "Top-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\n",
    "1. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 0, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "2. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 3, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "3. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 5, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "4. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 0, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}\n",
    "5. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 3, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6385223-e6d4-45d9-a080-e30a2b9c8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, torch\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "# ====== 1) SAVE / LOAD ======\n",
    "def save_snn(path, cfg, connection, lif_layer):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "    ckpt = {\n",
    "        \"cfg\": asdict(cfg),\n",
    "        \"W\": connection.w.detach().cpu(),\n",
    "        \"v_thresh\": vt.detach().cpu(),\n",
    "    }\n",
    "    torch.save(ckpt, path)\n",
    "    print(f\"Saved to {path} | W {tuple(ckpt['W'].shape)}\")\n",
    "\n",
    "def load_weights_into(net, connection, lif_layer, ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        connection.w.copy_(ckpt[\"W\"])\n",
    "        vt = ckpt[\"v_thresh\"]\n",
    "        if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh.copy_(vt)\n",
    "        else: lif_layer.thresh.copy_(vt)\n",
    "    print(f\"Loaded from {ckpt_path}\")\n",
    "\n",
    "# ====== 2) –ö–ê–õ–ò–ë–†–û–í–ö–ê (–Ω–µ–π—Ä–æ–Ω -> –º–µ—Ç–∫–∞) ======\n",
    "@torch.no_grad()\n",
    "def build_label_map(net, input_layer, lif_layer, encoder, n_calib=2000, T=200, top_k=3, seed=123):\n",
    "    # –≤—ã–∫–ª—é—á–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_eval_tmp\")\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_train = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_calib, len(ds_train))))\n",
    "    usage = torch.zeros((lif_layer.n,), dtype=torch.long)          # —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –Ω–µ–π—Ä–æ–Ω –≤—ã–∏–≥—Ä—ã–≤–∞–ª\n",
    "    wins  = torch.zeros((lif_layer.n, 10), dtype=torch.long)       # –Ω–µ–π—Ä–æ–Ω x –∫–ª–∞—Å—Å\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)  # —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Å—Ç–æ—Ö–∞—Å—Ç–∏–∫—É Poisson per-sample\n",
    "        x = ds_train[i][\"image\"]\n",
    "        y = int(ds_train[i][\"label\"])\n",
    "        spikes_in = encoder(x)                       # [T,1,784]\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        # –≤—ã–±–∏—Ä–∞–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –ø–æ —Å—É–º–º–µ —Å–ø–∞–π–∫–æ–≤ –∑–∞ –æ–∫–Ω–æ\n",
    "        s = lif_mon.get(\"s\")                         # [T,1,N]\n",
    "        s2 = s[:,0,:]                                # [T,N]\n",
    "        counts = s2.sum(0)                           # [N]\n",
    "        if counts.sum() > 0:\n",
    "            k = min(top_k, lif_layer.n)\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            for j in topi.tolist():\n",
    "                usage[j] += 1\n",
    "                wins[j, y] += 1\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    net.monitors.pop(\"lif_eval_tmp\", None)\n",
    "\n",
    "    # –Ω–µ–π—Ä–æ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ = argmax –ø–æ –∫–ª–∞—Å—Å–∞–º (–µ—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω —Ö–æ—Ç—å —Ä–∞–∑ –≤—ã–∏–≥—Ä—ã–≤–∞–ª)\n",
    "    label_map = -torch.ones((lif_layer.n,), dtype=torch.long)\n",
    "    active = (usage > 0).nonzero().flatten().tolist()\n",
    "    for j in active:\n",
    "        label_map[j] = wins[j].argmax().item()\n",
    "\n",
    "    covered = int((label_map >= 0).sum())\n",
    "    print(f\"Label-map built: {covered}/{lif_layer.n} neurons assigned; active winners {int((usage>0).sum())}\")\n",
    "    return label_map\n",
    "\n",
    "# ====== 3) –û–¶–ï–ù–ö–ê –ù–ê TEST ======\n",
    "@torch.no_grad()\n",
    "def evaluate_on_mnist(net, input_layer, lif_layer, encoder, label_map, T=200, top_k=3, n_test=1000, seed=999):\n",
    "    # freeze learning\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_test_tmp\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_test = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_test, len(ds_test))))\n",
    "\n",
    "    correct = 0\n",
    "    meter = SNNMeter()\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)\n",
    "        x = ds_test[i][\"image\"]; y = int(ds_test[i][\"label\"])\n",
    "        spikes_in = encoder(x)\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        s_full = lif_mon.get(\"s\")              # [T,1,N]\n",
    "        s2 = s_full[:,0,:]                     # [T,N]\n",
    "        counts = s2.sum(0)                     # [N]\n",
    "\n",
    "        # WTA –Ω–∞ –æ—Ü–µ–Ω–∫–µ ‚Äî –±–µ—Ä—ë–º top_k –Ω–µ–π—Ä–æ–Ω–æ–≤ –∏ –≥–æ–ª–æ—Å—É–µ–º –∏—Ö –º–µ—Ç–∫–∞–º–∏\n",
    "        k = min(top_k, lif_layer.n)\n",
    "        if counts.sum() == 0:\n",
    "            pred = -1\n",
    "        else:\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            votes = torch.zeros(10, dtype=torch.float32)\n",
    "            for j, v in zip(topi.tolist(), topv.tolist()):\n",
    "                lbl = int(label_map[j].item())\n",
    "                if lbl >= 0: votes[lbl] += float(v)\n",
    "            pred = int(votes.argmax().item()) if votes.sum() > 0 else -1\n",
    "\n",
    "        if pred == y: correct += 1\n",
    "\n",
    "        # —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ (–¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è)\n",
    "        # —Å–æ–∑–¥–∞–¥–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π ‚Äúinput monitor‚Äù –∏–∑ —Ç–µ—Ö –∂–µ —Å–ø–∞–π–∫–æ–≤\n",
    "        meter.log_sample(s_full, spikes_in, lif_layer.n, T, winners=topi.tolist() if counts.sum()>0 else None)\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    acc = correct / len(idxs)\n",
    "    rpt = meter.report()\n",
    "    net.monitors.pop(\"lif_test_tmp\", None)\n",
    "    print(f\"TEST accuracy: {acc:.3f}  | spikes/sample={rpt['spikes_per_sample']:.2f}  energy‚âà{rpt['energy_proxy_per_sample']:.1f}\")\n",
    "    return {\"accuracy\": acc, **rpt}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26c63233-0d2b-43c2-a3fa-8744a8a2523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ–º: cpu\n",
      "[lif] thresh = scalar 0.350\n",
      "[lif] tc_decay = scalar 150.000\n",
      "[lif] refrac = 2\n",
      "[lif] reset = 0.0\n",
      "INPUT window sum: 117\n",
      "LIF   window sum: 0\n",
      "[1] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 67\n",
      "[50] total=67 active=13/100 HHI=0.082\n",
      "INPUT window sum: 79\n",
      "LIF   window sum: 0\n",
      "INPUT window sum: 53\n",
      "LIF   window sum: 0\n",
      "[100] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 88\n",
      "LIF   window sum: 0\n",
      "INPUT window sum: 165\n",
      "LIF   window sum: 90\n",
      "[150] total=90 active=7/100 HHI=0.143\n",
      "INPUT window sum: 119\n",
      "LIF   window sum: 11\n",
      "INPUT window sum: 112\n",
      "LIF   window sum: 0\n",
      "[200] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 183\n",
      "LIF   window sum: 641\n",
      "[250] total=641 active=100/100 HHI=0.014\n",
      "INPUT window sum: 157\n",
      "LIF   window sum: 357\n",
      "[300] total=357 active=76/100 HHI=0.018\n",
      "INPUT window sum: 107\n",
      "LIF   window sum: 0\n",
      "[350] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 224\n",
      "LIF   window sum: 366\n",
      "[400] total=366 active=43/100 HHI=0.042\n",
      "INPUT window sum: 146\n",
      "LIF   window sum: 459\n",
      "[450] total=459 active=98/100 HHI=0.010\n",
      "INPUT window sum: 128\n",
      "LIF   window sum: 4\n",
      "[500] total=4 active=2/100 HHI=0.625\n",
      "INPUT window sum: 132\n",
      "LIF   window sum: 110\n",
      "[550] total=110 active=55/100 HHI=0.018\n",
      "INPUT window sum: 119\n",
      "LIF   window sum: 0\n",
      "[600] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 145\n",
      "LIF   window sum: 79\n",
      "[650] total=79 active=13/100 HHI=0.100\n",
      "INPUT window sum: 149\n",
      "LIF   window sum: 91\n",
      "[700] total=91 active=60/100 HHI=0.034\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 243\n",
      "[750] total=243 active=76/100 HHI=0.016\n",
      "INPUT window sum: 130\n",
      "LIF   window sum: 119\n",
      "[800] total=119 active=49/100 HHI=0.022\n",
      "INPUT window sum: 183\n",
      "LIF   window sum: 298\n",
      "[850] total=298 active=45/100 HHI=0.027\n",
      "INPUT window sum: 112\n",
      "LIF   window sum: 0\n",
      "[900] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 186\n",
      "LIF   window sum: 109\n",
      "[950] total=109 active=21/100 HHI=0.121\n",
      "INPUT window sum: 136\n",
      "LIF   window sum: 24\n",
      "[1000] total=24 active=6/100 HHI=0.167\n",
      "\n",
      "SUMMARY: {'spikes_per_sample': 81.135, 'winners_unique': 80, 'winner_HHI': 0.016851851851851854, 'energy_proxy_per_sample': 782.995}\n",
      "Saved to out/snn_mnist.pt | W (784, 100)\n",
      "[lif] thresh = scalar 0.350\n",
      "[lif] tc_decay = scalar 150.000\n",
      "[lif] refrac = 2\n",
      "[lif] reset = 0.0\n",
      "Loaded from out/snn_mnist.pt\n",
      "Label-map built: 64/100 neurons assigned; active winners 64\n",
      "TEST accuracy: 0.099  | spikes/sample=6640.19  energy‚âà73855.0\n",
      "{'accuracy': 0.099, 'spikes_per_sample': 6640.193, 'synops_per_sample': 1342296.9, 'v_updates_per_sample': 20000.0, 'energy_proxy_per_sample': 73855.038, 'winners_unique': 45, 'winner_HHI': 0.31625799999999993}\n"
     ]
    }
   ],
   "source": [
    "# ====== –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ======\n",
    "# 1) —Ç—Ä–µ–Ω–∏—Ä—É–µ–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ:\n",
    "cfg = Cfg(\n",
    "    time = 200,                 # —á–∏—Å–ª–æ —Ç–∞–∫—Ç–æ–≤ —Å–∏–º—É–ª—è—Ü–∏–∏ –Ω–∞ –æ–±—Ä–∞–∑\n",
    "    n_hidden = 100    ,         # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "    encoder = \"poisson\",        # –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –≤—Ö–æ–¥–∞: –ø—É–∞—Å—Å–æ–Ω–æ–≤—Å–∫–∏–π\n",
    "    top_k = 3           ,       # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –≤ WTA\n",
    "    enable_inhibition_at_start = False,  # –≤–∫–ª—é—á–∞—Ç—å –ª–∏ —Ç–æ—Ä–º–æ–∂–µ–Ω–∏–µ —Å—Ä–∞–∑—É\n",
    "    nu_plus = 0.0001,           # —à–∞–≥ LTP –ø—Ä–∏ STDP\n",
    "    nu_minus = -0.001 ,         # —à–∞–≥ LTD –ø—Ä–∏ STDP\n",
    "    poisson_rate_scale = 0.006, # –º–∞—Å—à—Ç–∞–± –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏ –ø—É–∞—Å—Å–æ–Ω–æ–≤—Å–∫–∏—Ö –ø–æ—Ç–æ–∫–æ–≤\n",
    "    device = \"cpu\",             # —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "    log_every = 50 ,            # –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤/–æ–±—Ä–∞–∑–æ–≤\n",
    "    N = 1000   ,                # —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    vt_mean = 0.35,             # —Å—Ä–µ–¥–Ω–∏–π –ø–æ—Ä–æ–≥ –≤–æ–∑–±—É–∂–¥–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "    vt_jitter = 0.02   ,        # —Ä–∞–∑–±—Ä–æ—Å –ø–æ—Ä–æ–≥–æ–≤ –ø–æ –Ω–µ–π—Ä–æ–Ω–∞–º\n",
    "    tau_val = 150.0   ,          # –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ —É—Ç–µ—á–∫–∏ –º–µ–º–±—Ä–∞–Ω—ã (aka tc_decay)\n",
    "    refrac_val = 2.0  ,         # —Ä–µ—Ñ—Ä–∞–∫—Ç–µ—Ä–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –ø–æ—Å–ª–µ —Å–ø–∞–π–∫–∞\n",
    "    debug = False\n",
    ")\n",
    "\n",
    "res, connection, lif_layer = run_experiment(cfg, verbose=True)   # —Ç—É—Ç —Ç—ã —É–∂–µ –æ–±—É—á–∞–ª\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "\n",
    "# 2) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:\n",
    "save_snn(\"out/snn_mnist.pt\", cfg, connection, lif_layer)\n",
    "\n",
    "# 3) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ ‚Äî –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º —Å–µ—Ç—å (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é), –≥—Ä—É–∑–∏–º –≤–µ—Å–∞:\n",
    "net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "\n",
    "load_weights_into(net, connection, lif_layer, \"out/snn_mnist.pt\")\n",
    "\n",
    "# 4) —Ç–æ—Ç –∂–µ —ç–Ω–∫–æ–¥–µ—Ä, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏:\n",
    "encoder, _ = make_encoder(\"poisson\", T=cfg.time)\n",
    "\n",
    "# 5) –∫–∞–ª–∏–±—Ä—É–µ–º –Ω–µ–π—Ä–æ–Ω‚Üí–º–µ—Ç–∫–∞ –ø–æ train (–±–µ–∑ –æ–±—É—á–µ–Ω–∏—è!):\n",
    "label_map = build_label_map(net, input_layer, lif_layer, encoder,  n_calib=2000, T=cfg.time, top_k=cfg.top_k)\n",
    "\n",
    "# 6) —Å—á–∏—Ç–∞–µ–º accuracy –Ω–∞ test:\n",
    "test_report = evaluate_on_mnist(net, input_layer, lif_layer, encoder,label_map, T=cfg.time, top_k=cfg.top_k, n_test=1000)\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0968c3-e842-48ce-860b-9beff1f775a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
