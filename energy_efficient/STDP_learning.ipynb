{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f620028-87ed-4c99-a115-950ce07e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LatencyEncoder:\n",
    "    def __init__(self, time: int = 100):\n",
    "        self.time = time  # –û–±—â–µ–µ —á–∏—Å–ª–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤\n",
    "\n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        image: Tensor [1, 28, 28] –∏–ª–∏ [28, 28], –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1 –∏–ª–∏ –¥–æ 255\n",
    "        return: spike_tensor [time, 1, 784]\n",
    "        \"\"\"\n",
    "        if image.ndim == 3:\n",
    "            image = image.squeeze()\n",
    "\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "\n",
    "        spike_tensor = torch.zeros((self.time, 1, 784))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                pixel = image[i, j].item()\n",
    "                if pixel > 0:\n",
    "                    spike_time = int((1.0 - pixel) * (self.time - 1))\n",
    "                    spike_tensor[spike_time, 0, i * 28 + j] = 1.0\n",
    "\n",
    "        return spike_tensor.view(self.time, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297294ce-41ea-4446-bfed-081c022d6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stdp_nu(conn, nu_plus, nu_minus):\n",
    "    dev = conn.w.device\n",
    "    conn.update_rule.nu = (torch.tensor(nu_plus, device=dev),\n",
    "                           torch.tensor(nu_minus, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b04cd6b1-9541-4bf7-bfec-daba59b3f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–¥ run_experiment\n",
    "class ThreshEMA:\n",
    "    def __init__(self): self.rate_ema = None\n",
    "    def step(self, layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "        with torch.no_grad():\n",
    "            rate = spike_counts / max(1, T)\n",
    "            if self.rate_ema is None:\n",
    "                self.rate_ema = rate.clone()\n",
    "            self.rate_ema = alpha * self.rate_ema + (1 - alpha) * rate\n",
    "            vt = layer.v_thresh if hasattr(layer,'v_thresh') else layer.thresh\n",
    "            vt += k * (self.rate_ema - target)\n",
    "            vt.clamp_(0.15, 1.2)\n",
    "            if hasattr(layer,'v_thresh'): layer.v_thresh = vt\n",
    "            else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd656371-a693-4252-9532-7e8105b90ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rate_ema = None\n",
    "def adapt_thresholds_ema(layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "    global _rate_ema\n",
    "    with torch.no_grad():\n",
    "        rate = spike_counts / max(1, T)\n",
    "        if _rate_ema is None: _rate_ema = rate.clone()\n",
    "        _rate_ema = alpha * _rate_ema + (1 - alpha) * rate\n",
    "        vt = layer.v_thresh if hasattr(layer,\"v_thresh\") else layer.thresh\n",
    "        vt += k * (_rate_ema - target)\n",
    "        vt.clamp_(vt_min, vt_max)  \n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6059930-22e3-4bdf-af94-50037eb25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_param(module, name, value, prefer_scalar=False, fallback_scalar=None):\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ—Å—Ç–∞–≤–ª—è–µ—Ç module.<name>.\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor —Å–∫–∞–ª—è—Ä–Ω—ã–π (numel()==1) –∏ value –≤–µ–∫—Ç–æ—Ä -> –∫–ª–∞–¥—ë–º 0-D —Ç–µ–Ω–∑–æ—Ä (—Å—Ä. –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ fallback_scalar).\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor –≤–µ–∫—Ç–æ—Ä–Ω—ã–π -> –∫–æ–ø–∏—Ä—É–µ–º –ø–æ —Ñ–æ—Ä–º–µ.\n",
    "    - prefer_scalar=True –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –¥–µ–ª–∞–µ—Ç 0-D (–¥–ª—è refrac/reset).\n",
    "    \"\"\"\n",
    "    if not hasattr(module, name):\n",
    "        return False\n",
    "\n",
    "    cur = getattr(module, name)\n",
    "\n",
    "    # –µ—Å–ª–∏ —ç—Ç–æ Tensor-–±—É—Ñ–µ—Ä\n",
    "    if isinstance(cur, torch.Tensor):\n",
    "        dev, dt = cur.device, cur.dtype\n",
    "\n",
    "        if prefer_scalar:\n",
    "            # –≤—Å–µ–≥–¥–∞ 0-D —Ç–µ–Ω–∑–æ—Ä\n",
    "            val = float(value.mean().item() if torch.is_tensor(value) else value)\n",
    "            setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            return True\n",
    "\n",
    "        if torch.is_tensor(value):\n",
    "            if cur.numel() == 1 and value.numel() > 1:\n",
    "                # –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π, value –≤–µ–∫—Ç–æ—Ä -> –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ/—Ñ–æ–ª–±—ç–∫\n",
    "                val = float(value.mean().item())\n",
    "                if fallback_scalar is not None:\n",
    "                    val = float(fallback_scalar)\n",
    "                setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            else:\n",
    "                if value.shape != cur.shape:\n",
    "                    value = value.view_as(cur)\n",
    "                cur.data.copy_(value.to(dev, dtype=dt))\n",
    "        else:\n",
    "            # value —Å–∫–∞–ª—è—Ä Python -> –ø—Ä–æ—Å—Ç–æ –∑–∞–ª–∏–≤–∞–µ–º\n",
    "            if cur.numel() == 1:\n",
    "                setattr(module, name, torch.tensor(float(value), device=dev, dtype=dt))\n",
    "            else:\n",
    "                cur.data.fill_(float(value))\n",
    "        return True\n",
    "\n",
    "    # –Ω–µ Tensor-–±—É—Ñ–µ—Ä ‚Äì –æ–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç\n",
    "    setattr(module, name, float(value) if prefer_scalar else value)\n",
    "    return True\n",
    "\n",
    "\n",
    "def tune_lif_params(lif_layer, n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0):\n",
    "    with torch.no_grad():\n",
    "        # –ø–æ—Ä–æ–≥: –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä; –µ—Å–ª–∏ –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π ‚Äî –∞–≤—Ç–æ-–¥–∞—É–Ω–º–∏–∫—Å –≤ —Å–∫–∞–ª—è—Ä\n",
    "        vt_vec = (vt_mean + vt_jitter * torch.randn(n_hidden)).clamp(0.05, 2.0)\n",
    "        if not _set_param(lif_layer, \"v_thresh\", vt_vec, fallback_scalar=vt_mean):\n",
    "            _set_param(lif_layer, \"thresh\", vt_vec, fallback_scalar=vt_mean)\n",
    "\n",
    "        # tau: –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å v–µ–∫—Ç–æ—Ä/—Å–∫–∞–ª—è—Ä –≤ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö)\n",
    "        if not _set_param(lif_layer, \"tau_m\", torch.full((n_hidden,), tau_val), fallback_scalar=tau_val):\n",
    "            _set_param(lif_layer, \"tau\",   torch.full((n_hidden,), tau_val),   fallback_scalar=tau_val)\n",
    "\n",
    "        # refrac ‚Äî —Å—Ç—Ä–æ–≥–æ —Å–∫–∞–ª—è—Ä (0-D)\n",
    "        _set_param(lif_layer, \"refrac\", refrac_val, prefer_scalar=True)\n",
    "\n",
    "        # reset ‚Äî —Å–∫–∞–ª—è—Ä\n",
    "        if not _set_param(lif_layer, \"v_reset\", 0.0, prefer_scalar=True):\n",
    "            _set_param(lif_layer, \"reset\",  0.0, prefer_scalar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080659-6ab0-4b4c-9dc8-1a070c04babe",
   "metadata": {},
   "source": [
    "# üß† Spiking Neural Network (SNN) –Ω–∞ –±–∞–∑–µ BindsNET —Å –æ–±—É—á–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ STDP\n",
    "\n",
    "–í —ç—Ç–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è —Å–ø–∞–π–∫–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å (SNN) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST.\n",
    "\n",
    "## üìå –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏:\n",
    "- **–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`Input`, 784 –Ω–µ–π—Ä–æ–Ω–∞)** ‚Äî –ø–æ –æ–¥–Ω–æ–º—É –Ω–µ–π—Ä–æ–Ω—É –Ω–∞ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 28√ó28.\n",
    "- **Poisson-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫** ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —è—Ä–∫–æ—Å—Ç—å –ø–∏–∫—Å–µ–ª–µ–π –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π (`Connection`)** ‚Äî —Å–æ–µ–¥–∏–Ω—è–µ—Ç –≤—Ö–æ–¥ —Å –≤—ã—Ö–æ–¥–æ–º (–º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ 784 √ó 100).\n",
    "- **–í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`LIF`, 100 –Ω–µ–π—Ä–æ–Ω–æ–≤)** ‚Äî Leaky Integrate-and-Fire –Ω–µ–π—Ä–æ–Ω—ã —Å —É—Ç–µ—á–∫–æ–π –∏ –ø–æ—Ä–æ–≥–æ–º.\n",
    "- **STDP (Spike-Timing Dependent Plasticity)** ‚Äî –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤; –≤–µ—Å–∞ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è, –µ—Å–ª–∏ –≤—Ö–æ–¥ –∞–∫—Ç–∏–≤–µ–Ω –¥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∞–π–∫–∞.\n",
    "\n",
    "## üî¨ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è:\n",
    "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ MNIST.\n",
    "2. –ö–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ Poisson-—Å–ø–∞–π–∫–æ–≤—ã–π –ø–æ—Ç–æ–∫.\n",
    "3. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–µ—Ç—å:\n",
    "   - `Input` –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏,\n",
    "   - `LIF` –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Å–æ–≤.\n",
    "4. –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:\n",
    "   - –°–ø–∞–π–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å `LIF`-–Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ –ø–æ–¥–∞—á–∏ –≤—Ö–æ–¥–∞.\n",
    "   - –°—É–º–º–∞ —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ (`Input`) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø–∏–∫—Å–µ–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã.\n",
    "   - –í–µ—Å–∞ –æ–¥–Ω–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ `LIF`-–Ω–µ–π—Ä–æ–Ω–∞ ‚Äî –¥–æ –∏ –ø–æ—Å–ª–µ STDP.\n",
    "\n",
    "## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:\n",
    "- –ì—Ä–∞—Ñ–∏–∫: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–∞–π–∫–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ/–ø–æ—Å–ª–µ + –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- –ì—Ä–∞—Ñ–∏–∫: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤, –≤–µ–¥—É—â–∏—Ö –∫ –Ω–µ–π—Ä–æ–Ω—É `LIF[42]` ‚Äî –≤–∏–¥–Ω–æ, –∫–∞–∫ STDP —É—Å–∏–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–≤—è–∑–∏.\n",
    "\n",
    "## üéØ –¶–µ–ª—å:\n",
    "–ü–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ SNN:\n",
    "- –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ—Ç–æ–∫ —Å–ø–∞–π–∫–æ–≤,\n",
    "- –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã,\n",
    "- –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ (STDP), –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62625648-17a4-47af-9950-dfa00b772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SETUP (Colab/Local) ======\n",
    "# !pip -q install bindsnet==0.2.8 torchvision==0.18.1 torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import os, itertools, random, csv, time as _ptime\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Utils ======\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def to_2d(s):  # [T,N] or [T,1,N] -> [T,N]\n",
    "    return s[:,0,:] if (s.dim()==3 and s.size(1)==1) else s\n",
    "\n",
    "# ====== Config ======\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    # core\n",
    "    time:   int = 200\n",
    "    n_hidden: int = 100\n",
    "    nu_plus:  float = 0.02\n",
    "    nu_minus: float = -0.02\n",
    "\n",
    "    # inhibition / WTA\n",
    "    inhib_strength: float = 0.3\n",
    "    inh_decay: float = 0.9\n",
    "    top_k: int = 0                    # 0 = WTA off for diagnostics\n",
    "    enable_inhibition_at_start: bool = False\n",
    "\n",
    "    # encoder\n",
    "    encoder: str = \"latency\"         # start with Poisson to \"ignite\" spikes\n",
    "\n",
    "    # homeostasis\n",
    "    target_spikes: float = 2.0\n",
    "    eta_up: float = 1.0\n",
    "    eta_down: float = 0.5\n",
    "    thresh_min: float = 0.2\n",
    "    thresh_max: float = 2.0\n",
    "    thresh_init: float = 0.5          # v_thresh initial (BindsNET positive scale)\n",
    "\n",
    "    # weights\n",
    "    w_clip_min: float = 0.0\n",
    "    w_clip_max: float = 1.5\n",
    "    w_col_target_norm: float = 20.0\n",
    "    w_init_lo: float = 0.8\n",
    "    w_init_hi: float = 1.2\n",
    "    wmin:float = 0.0\n",
    "    wmax:float = 2.0\n",
    "    # loop\n",
    "    N: int = 200\n",
    "    log_every: int = 50\n",
    "    seed: int = 42\n",
    "\n",
    "# ====== Helpers: WTA, norm, thresholds, plots, metrics ======\n",
    "def apply_wta(s, top_k=1):\n",
    "    s2 = to_2d(s)\n",
    "    sb = s2.sum(0).float().squeeze()\n",
    "    if sb.sum() == 0:\n",
    "        return False, None\n",
    "    vals, idxs = torch.topk(sb, k=min(top_k, sb.numel()))\n",
    "    s.zero_()\n",
    "    for j in idxs.tolist():\n",
    "        if s.dim()==3:\n",
    "            s[:,0,j] = True\n",
    "        else:\n",
    "            s[:,j] = True\n",
    "    return True, idxs.tolist()\n",
    "\n",
    "def weight_soft_bound_and_colnorm(conn_w, w_clip_min, w_clip_max, target_norm):\n",
    "    with torch.no_grad():\n",
    "        w = conn_w.data\n",
    "        w.clamp_(w_clip_min, w_clip_max)\n",
    "        col_norm = w.norm(p=1, dim=0, keepdim=True) + 1e-6\n",
    "        w.mul_(target_norm / col_norm)\n",
    "\n",
    "def adapt_thresholds(layer, spike_counts, cfg: Cfg):\n",
    "    with torch.no_grad():\n",
    "        vt = layer.v_thresh if hasattr(layer, \"v_thresh\") else layer.thresh\n",
    "        vt -= 0.05 * (spike_counts < 1.0).float()        # if silent -> lower threshold\n",
    "        vt += 0.02 * (spike_counts > 3.0).float()        # if too active -> raise\n",
    "        vt.clamp_(cfg.thresh_min, cfg.thresh_max)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt\n",
    "\n",
    "def spiking_metrics_window(lif_s, winners=None):\n",
    "    s = to_2d(lif_s).to(torch.bool)\n",
    "    T, N = s.shape\n",
    "    per_n = s.sum(0)\n",
    "    tot = int(per_n.sum())\n",
    "    active = int((per_n > 0).sum())\n",
    "    if tot > 0:\n",
    "        p = (per_n / tot).float().cpu().numpy()\n",
    "        HHI = float((p**2).sum())\n",
    "        ps = np.sort(p)\n",
    "        Gini = float((np.cumsum(ps).sum()/ps.sum() - (len(ps)+1)/2)/len(ps))\n",
    "    else:\n",
    "        HHI, Gini = 1.0, 1.0\n",
    "    uniq_winners = len(set(winners)) if winners else 0\n",
    "    return dict(T=T, N=N, total_spikes=tot, active=active, HHI=HHI, Gini=Gini, uniq_winners=uniq_winners)\n",
    "\n",
    "class SNNMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.samples=0; self.S_out=0; self.S_in=0; self.SynOps=0; self.V_updates=0\n",
    "        self.usage_counts = {}\n",
    "    def log_sample(self, lif_s, in_s, n_hidden, T, winners=None):\n",
    "        lif2 = to_2d(lif_s);  in2 = to_2d(in_s)\n",
    "        s_out = int(lif2.sum().item())\n",
    "        s_in  = int(in2.sum().item())\n",
    "        self.S_out += s_out; self.S_in += s_in\n",
    "        self.SynOps += s_in * n_hidden\n",
    "        self.V_updates += n_hidden * T\n",
    "        self.samples += 1\n",
    "        if winners:\n",
    "            for j in winners:\n",
    "                self.usage_counts[j] = self.usage_counts.get(j,0)+1\n",
    "    def report(self, a=1.0, b=0.05, c=0.005):\n",
    "        s = max(1, self.samples)\n",
    "        HHI_win = 0.0\n",
    "        if self.usage_counts:\n",
    "            tot = sum(self.usage_counts.values())\n",
    "            ps = np.array([v/tot for v in self.usage_counts.values()], dtype=float)\n",
    "            HHI_win = float((ps**2).sum())\n",
    "        return {\n",
    "            \"spikes_per_sample\": self.S_out/s,\n",
    "            \"synops_per_sample\": self.SynOps/s,\n",
    "            \"v_updates_per_sample\": self.V_updates/s,\n",
    "            \"energy_proxy_per_sample\": (a*self.S_out + b*self.SynOps + c*self.V_updates)/s,\n",
    "            \"winners_unique\": len(self.usage_counts),\n",
    "            \"winner_HHI\": HHI_win,\n",
    "        }\n",
    "\n",
    "# ====== Build Net & Encoder ======\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "def build_net(cfg: Cfg):\n",
    "    net = Network()\n",
    "\n",
    "    input_layer = Input(n=784, traces=True)\n",
    "    lif_layer   = LIFNodes(n=cfg.n_hidden, traces=True)\n",
    "    tune_lif_params(lif_layer, cfg.n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0)\n",
    "            \n",
    "    net.add_layer(input_layer, name='Input')\n",
    "    net.add_layer(lif_layer,   name='LIF')\n",
    "    \n",
    "\n",
    "    connection = Connection(source=input_layer, target=lif_layer)\n",
    "    connection.update_rule = PostPre(connection=connection,\n",
    "                                 nu=(torch.tensor(cfg.nu_plus),\n",
    "                                     torch.tensor(cfg.nu_minus)))\n",
    "    net.add_connection(connection, source='Input', target='LIF')\n",
    "\n",
    "    # Lateral inhibition (created, but optionally disabled at start)\n",
    "    W_inh = torch.full((cfg.n_hidden, cfg.n_hidden), -cfg.inhib_strength)\n",
    "    W_inh.fill_diagonal_(0.0)\n",
    "    recurrent_inh = Connection(source=lif_layer, target=lif_layer, w=W_inh.clone())\n",
    "    net.add_connection(recurrent_inh, source='LIF', target='LIF')\n",
    "\n",
    "    # Weights init (stronger to ignite)\n",
    "    with torch.no_grad():\n",
    "        connection.w.data.uniform_(cfg.w_init_lo, cfg.w_init_hi)\n",
    "\n",
    "    # Thresholds: use v_thresh if available\n",
    "    th0 = torch.full((cfg.n_hidden,), cfg.thresh_init)\n",
    "    if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh = th0.clone()\n",
    "    else: lif_layer.thresh = th0.clone()\n",
    "\n",
    "    # Optionally disable inhibition at start (for diagnostics)\n",
    "    if not cfg.enable_inhibition_at_start:\n",
    "        with torch.no_grad():\n",
    "            recurrent_inh.w.zero_()\n",
    "\n",
    "    return net, input_layer, lif_layer, connection, recurrent_inh, W_inh\n",
    "\n",
    "# –ü—Ä–µ-–ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL / np / tensor)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28), antialias=True),\n",
    "    transforms.ToTensor(),                 # -> [1,28,28] float in [0,1]\n",
    "    # –ù–∏–∫–∞–∫–∏—Ö Normalize(mean,std) –∑–¥–µ—Å—å ‚Äî –Ω–∞–º –Ω—É–∂–Ω—ã ¬´—Å—ã—Ä—ã–µ¬ª 0..1!\n",
    "])\n",
    "\n",
    "def make_encoder(encoder_type: str, T: int, rate_floor: float = 0.0):  # floor –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0\n",
    "    encoder_type = encoder_type.lower()\n",
    "    assert encoder_type in (\"poisson\", \"latency\")\n",
    "\n",
    "    def encode_poisson(img_tensor):\n",
    "        RATE_SCALE = 0.008  # –±—ã–ª–æ –±–æ–ª—å—à–µ; –¥–µ–ª–∞–µ–º –≤—Ö–æ–¥ –≤ 3‚Äì10 —Ä–∞–∑ —Ä–µ–∂–µ\n",
    "        x = img_tensor.view(-1).clamp(0, 1)\n",
    "        rates = x * RATE_SCALE\n",
    "        rand = torch.rand((T, rates.numel()), device=rates.device if x.is_cuda else None)\n",
    "        spikes = (rand < rates).float()\n",
    "        return spikes.view(T, 1, 784)\n",
    "\n",
    "    def encode_latency(img_tensor):\n",
    "        x = img_tensor.squeeze(0).clamp(0, 1)\n",
    "        spikes = torch.zeros((T, 1, 784), dtype=torch.float32)\n",
    "        nz = (x > 0).nonzero(as_tuple=False)\n",
    "        if nz.numel() == 0:\n",
    "            return spikes\n",
    "        for idx in nz:\n",
    "            i, j = int(idx[0]), int(idx[1])\n",
    "            p = float(x[i, j])\n",
    "            t = int(round((1.0 - p) * (T - 1)))\n",
    "            # –º–∞–ª–µ–Ω—å–∫–∏–π –¥–∂–∏—Ç—Ç–µ—Ä ¬±1 —Ç–∏–∫ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–∫–Ω–∞)\n",
    "            if T >= 3:\n",
    "                t += int(torch.randint(-1, 2, (1,)).item())\n",
    "                t = max(0, min(T-1, t))\n",
    "            spikes[t, 0, i*28 + j] = 1.0\n",
    "        return spikes\n",
    "\n",
    "    return (encode_poisson if encoder_type == \"poisson\" else encode_latency), preprocess\n",
    "        \n",
    "def _to_2d(s):  # [T, B, N] -> [T, N]\n",
    "    return s[:, 0, :] if s.dim()==3 else s\n",
    "    \n",
    "# ====== One Experiment ======\n",
    "def run_experiment(cfg: Cfg, verbose=True):\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # –î–∞—Ç–∞—Å–µ—Ç (MNIST —É–∂–µ –≤ [0,1] –∏ [1,28,28])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # –°–µ—Ç—å + –º–æ–Ω–∏—Ç–æ—Ä—ã\n",
    "    net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "    # ‚Üì –°–†–ê–ó–£ –ü–û–°–õ–ï build_net(cfg)\n",
    "    with torch.no_grad():\n",
    "        # —É —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π BindsNET –ø–æ—Ä–æ–≥ –ª–µ–∂–∏—Ç –≤ v_thresh –ò–õ–ò –≤ thresh\n",
    "        if hasattr(lif_layer, \"v_thresh\"):\n",
    "            vt = lif_layer.v_thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.v_thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)  # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.v_thresh.fill_(0.12)\n",
    "        else:\n",
    "            vt = lif_layer.thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)   # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.thresh.fill_(0.12)\n",
    "    \n",
    "    # –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –æ—Å—Ç–∞–≤—å print –æ–¥–∏–Ω —Ä–∞–∑\n",
    "    vt_chk = (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    print(\">>> THRESH SET TO:\", float(vt_chk.mean().item()))\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "    \n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    inp_mon = Monitor(input_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    net.add_monitor(lif_mon, name=\"lif_mon\")\n",
    "    net.add_monitor(inp_mon, name=\"inp_mon\")\n",
    "\n",
    "    # –≠–Ω–∫–æ–¥–µ—Ä\n",
    "    ENCODER_TYPE = cfg.encoder\n",
    "    T = cfg.time\n",
    "    encoder, _ = make_encoder(ENCODER_TYPE, T)\n",
    "    \n",
    "    # --------- WARMUP (–±–µ–∑ STDP) ---------\n",
    "    WARMUP = getattr(cfg, \"warmup_N\", 50)\n",
    "    if WARMUP > 0:\n",
    "        # –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤ STDP –≤—ã–∫–ª.\n",
    "        set_stdp_nu(connection, 0.0, 0.0)\n",
    "        for wi in range(min(WARMUP, len(dataset))):\n",
    "            image = dataset[wi][\"image\"]\n",
    "            spike_input = encoder(image)\n",
    "            net.run(inputs={\"Input\": spike_input}, time=cfg.time)\n",
    "\n",
    "            # –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é ‚Äî –ø–æ–ª–µ–∑–Ω–æ)\n",
    "            lif_s_full = lif_mon.get(\"s\")\n",
    "            spike_counts = to_2d(lif_s_full).sum(0).float().squeeze()\n",
    "            # adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "            \n",
    "\n",
    "            # –æ—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "            net.reset_state_variables()\n",
    "            lif_mon.reset_state_variables()\n",
    "            inp_mon.reset_state_variables()\n",
    "\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "    # --------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ---------\n",
    "    with torch.no_grad():\n",
    "        I = torch.eye(cfg.n_hidden, device=recurrent_inh.w.device, dtype=recurrent_inh.w.dtype)\n",
    "        recurrent_inh.w.copy_(-0.25 * (1 - I))\n",
    "    ema = ThreshEMA()\n",
    "    meter = SNNMeter()\n",
    "    # –º—è–≥–∫–∏–π STDP –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    set_stdp_nu(connection, 5e-5, -2e-5) # –±—ã–ª–æ 1e-3 / -5e-4\n",
    "    \n",
    "\n",
    "    for i in range(cfg.N):\n",
    "        sample = dataset[i]\n",
    "        image  = sample[\"image\"]\n",
    "        spike_input = encoder(image)\n",
    "        inputs = {\"Input\": spike_input}\n",
    "\n",
    "        net.run(inputs=inputs, time=cfg.time)\n",
    "\n",
    "        # –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\n",
    "        lif_s_full = lif_mon.get(\"s\")   # [T,B,N]\n",
    "        in_s_full  = inp_mon.get(\"s\")   # [T,B,784]\n",
    "        lif2 = _to_2d(lif_s_full); in2 = _to_2d(in_s_full)\n",
    "\n",
    "        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º\n",
    "        if (i+1) in (1, 50, 150):\n",
    "            print(\"INPUT spikes sum (window):\", int(in2.sum().item()))\n",
    "            print(\"LIF   spikes sum (window):\",   int(lif2.sum().item()))\n",
    "            print(\"INPUT window sum:\", int(in2.sum()))\n",
    "            print(\"LIF   window sum:\", int(lif2.sum()))\n",
    "            vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "            print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "            print(\"w[min,max]:\", float(connection.w.min()), float(connection.w.max()))\n",
    "\n",
    "        # WTA (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n",
    "        winners = None\n",
    "        if cfg.top_k and cfg.top_k > 0:\n",
    "            ok, winners = apply_wta(lif_layer.s, top_k=cfg.top_k)\n",
    "            if not ok:\n",
    "                net.reset_state_variables(); lif_mon.reset_state_variables(); inp_mon.reset_state_variables()\n",
    "                continue\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–∫–Ω–∞\n",
    "        m = spiking_metrics_window(lif_s_full, winners)\n",
    "        if verbose and ((i+1) % cfg.log_every == 0 or i == 0):\n",
    "            print(f\"[{i+1}] total={m['total_spikes']} active={m['active']}/{m['N']} HHI={m['HHI']:.3f}\")\n",
    "\n",
    "        # Homeostasis –ø–æ ¬´—Å—ã—Ä—ã–º¬ª —Å–ø–∞–π–∫–∞–º (–¥–æ WTA)\n",
    "        spike_counts = to_2d(lif_s_full).sum(0).float()\n",
    "        ema.step(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "\n",
    "        # –ö–ª–∞–º–ø –≤–µ—Å–æ–≤ (–±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –∫–æ–ª–æ–Ω–æ—á–Ω–æ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥—ã–π —à–∞–≥)\n",
    "        with torch.no_grad():\n",
    "            connection.w.clamp_(0.0, 1.0)\n",
    "\n",
    "        # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ / —É—á—ë—Ç\n",
    "        meter.log_sample(lif_s_full, in_s_full, cfg.n_hidden, cfg.time, winners=winners)\n",
    "\n",
    "        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –º–æ–Ω–∏—Ç–æ—Ä–æ–≤\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "        inp_mon.reset_state_variables()\n",
    "\n",
    "   \n",
    "    rpt = meter.report()\n",
    "    if getattr(meter, \"samples\", 0) == 0:\n",
    "        print(\"!! meter: no samples logged ‚Äî –ø—Ä–æ–≤–µ—Ä—å –ø–æ—Ä—è–¥–æ–∫ log_sample()/reset() –∏ continue –≤ —Ü–∏–∫–ª–µ\")\n",
    "    out = {**asdict(cfg), **rpt}\n",
    "    return out\n",
    "\n",
    "# ====== Grid Runner (compact) ======\n",
    "def grid_run(base: Cfg):\n",
    "    grid = {\n",
    "        \"inhib_strength\": [0.3, 0.5],\n",
    "        \"top_k\": [0, 3],\n",
    "        \"time\": [200, 300],\n",
    "        \"use_latency\": [False, True],\n",
    "    }\n",
    "    keys, vals = zip(*grid.items())\n",
    "    results = []\n",
    "    t0 = _ptime.time()\n",
    "    for combo in itertools.product(*vals):\n",
    "        cfg = Cfg(**{**asdict(base), **dict(zip(keys, combo))})\n",
    "        print(\">>> run:\", {k: getattr(cfg,k) for k in keys})\n",
    "        res = run_experiment(cfg, verbose=False)\n",
    "        print({k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "        results.append(res)\n",
    "\n",
    "    os.makedirs(\"out\", exist_ok=True)\n",
    "    csv_path = os.path.join(\"out\",\"snn_energy_accuracy_grid.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "        writer.writeheader(); writer.writerows(results)\n",
    "    print(f\"Saved: {csv_path} | runs={len(results)} | elapsed={_ptime.time()-t0:.1f}s\")\n",
    "\n",
    "    # quick Pareto-ish\n",
    "    best = (sorted(results, key=lambda r: (r[\"energy_proxy_per_sample\"], r[\"winner_HHI\"], -r[\"winners_unique\"])))[:5]\n",
    "    print(\"\\nTop-5 Pareto-ish:\")\n",
    "    for r in best:\n",
    "        print({k: r[k] for k in [\"inhib_strength\",\"top_k\",\"time\",\"use_latency\",\n",
    "                                 \"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f8eb2b6-28b4-499d-9679-d66f8b0c23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> THRESH SET TO: 0.11999998986721039\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "INPUT spikes sum (window): 172\n",
      "LIF   spikes sum (window): 144\n",
      "INPUT window sum: 172\n",
      "LIF   window sum: 144\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "w[min,max]: 0.8000055551528931 1.1999914646148682\n",
      "[1] total=144 active=38/100 HHI=0.030\n",
      "INPUT spikes sum (window): 178\n",
      "LIF   spikes sum (window): 233\n",
      "INPUT window sum: 178\n",
      "LIF   window sum: 233\n",
      "v_thresh mean¬±std: 0.15000000596046448 0.0\n",
      "w[min,max]: 0.7993040680885315 1.0\n",
      "[50] total=233 active=48/100 HHI=0.024\n",
      "[100] total=0 active=0/100 HHI=1.000\n",
      "INPUT spikes sum (window): 227\n",
      "LIF   spikes sum (window): 520\n",
      "INPUT window sum: 227\n",
      "LIF   window sum: 520\n",
      "v_thresh mean¬±std: 0.15000000596046448 0.0\n",
      "w[min,max]: 0.7985788583755493 1.0\n",
      "[150] total=520 active=100/100 HHI=0.023\n",
      "[200] total=0 active=0/100 HHI=1.000\n",
      "\n",
      "SUMMARY: {'spikes_per_sample': 176.115, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 1065.115}\n"
     ]
    }
   ],
   "source": [
    "cfg = Cfg(\n",
    "    time=200,\n",
    "    n_hidden=100,\n",
    "    encoder=\"poisson\",                 # —Å–Ω–∞—á–∞–ª–∞ Poisson\n",
    "    top_k=0,                           # WTA –≤—ã–∫–ª. –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "    enable_inhibition_at_start=False,  # –∏–Ω–≥–∏–±–∏—Ü–∏—é –≤–∫–ª—é—á–∏–º –ø–æ–∑–∂–µ\n",
    "    nu_plus = 0.002,\n",
    "    nu_minus = -0.001\n",
    ")\n",
    "res = run_experiment(cfg, verbose=True)\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314ca5-f60c-435e-945a-7594a098bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
