{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f620028-87ed-4c99-a115-950ce07e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LatencyEncoder:\n",
    "    def __init__(self, time: int = 100):\n",
    "        self.time = time  # –û–±—â–µ–µ —á–∏—Å–ª–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤\n",
    "\n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        image: Tensor [1, 28, 28] –∏–ª–∏ [28, 28], –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1 –∏–ª–∏ –¥–æ 255\n",
    "        return: spike_tensor [time, 1, 784]\n",
    "        \"\"\"\n",
    "        if image.ndim == 3:\n",
    "            image = image.squeeze()\n",
    "\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "\n",
    "        spike_tensor = torch.zeros((self.time, 1, 784))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                pixel = image[i, j].item()\n",
    "                if pixel > 0:\n",
    "                    spike_time = int((1.0 - pixel) * (self.time - 1))\n",
    "                    spike_tensor[spike_time, 0, i * 28 + j] = 1.0\n",
    "\n",
    "        return spike_tensor.view(self.time, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "297294ce-41ea-4446-bfed-081c022d6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stdp_nu(conn, nu_plus, nu_minus):\n",
    "    dev = conn.w.device\n",
    "    conn.update_rule.nu = (torch.tensor(nu_plus, device=dev),\n",
    "                           torch.tensor(nu_minus, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd656371-a693-4252-9532-7e8105b90ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rate_ema = None\n",
    "def adapt_thresholds_ema(layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "    global _rate_ema\n",
    "    with torch.no_grad():\n",
    "        rate = spike_counts / max(1, T)\n",
    "        if _rate_ema is None: _rate_ema = rate.clone()\n",
    "        _rate_ema = alpha * _rate_ema + (1 - alpha) * rate\n",
    "        vt = layer.v_thresh if hasattr(layer,\"v_thresh\") else layer.thresh\n",
    "        vt += k * (_rate_ema - target)\n",
    "        vt.clamp_(0.15, 1.2)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6059930-22e3-4bdf-af94-50037eb25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä—ã/–∞—Ç—Ä–∏–±—É—Ç—ã –º–æ–¥—É–ª—è ---\n",
    "def _set_param(module, name, value, prefer_scalar=False):\n",
    "    \"\"\"\n",
    "    –°—Ç–∞–≤–∏—Ç value –≤ module.<name>, —É—á–∏—Ç—ã–≤–∞—è, —á—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±—É—Ñ–µ—Ä (Tensor).\n",
    "    prefer_scalar=True -> –¥–µ–ª–∞–µ—Ç 0-D —Ç–µ–Ω–∑–æ—Ä (–¥–ª—è refrac).\n",
    "    \"\"\"\n",
    "    if not hasattr(module, name):\n",
    "        return False\n",
    "    cur = getattr(module, name)\n",
    "\n",
    "    # –ï—Å–ª–∏ —ç—Ç–æ Tensor-–±—É—Ñ–µ—Ä\n",
    "    if isinstance(cur, torch.Tensor):\n",
    "        if prefer_scalar:\n",
    "            # –ù–∞–º –Ω—É–∂–µ–Ω 0-D, –∏–Ω–∞—á–µ masked_fill_ —É–ø–∞–¥—ë—Ç (–¥–ª—è refrac)\n",
    "            val = torch.tensor(float(value), device=cur.device)\n",
    "            setattr(module, name, val)  # –∑–∞–º–µ–Ω–∏—Ç—å –±—É—Ñ–µ—Ä –Ω–∞ 0-D —Ç–µ–Ω–∑–æ—Ä\n",
    "            return True\n",
    "\n",
    "        # –ò–Ω–∞—á–µ –∑–∞–ø–æ–ª–Ω—è–µ–º –ø–æ —Ñ–æ—Ä–º–µ —Ç–µ–∫—É—â–µ–≥–æ –±—É—Ñ–µ—Ä–∞\n",
    "        if torch.is_tensor(value):\n",
    "            if value.numel() == 1 and cur.numel() > 1:\n",
    "                cur.data.fill_(float(value))\n",
    "            else:\n",
    "                if value.shape != cur.shape:\n",
    "                    value = value.view_as(cur)\n",
    "                cur.data.copy_(value.to(cur.device, dtype=cur.dtype))\n",
    "        else:\n",
    "            cur.data.fill_(float(value))\n",
    "        return True\n",
    "\n",
    "    # –ù–µ –±—É—Ñ–µ—Ä ‚Äî –æ–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç: —Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å\n",
    "    setattr(module, name, value if not prefer_scalar else float(value))\n",
    "    return True\n",
    "\n",
    "\n",
    "def tune_lif_params(lif_layer, n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0):\n",
    "    with torch.no_grad():\n",
    "        # –ü–æ—Ä–æ–≥–∏: –≤–µ–∫—Ç–æ—Ä —Å –ª—ë–≥–∫–∏–º —Ä–∞–∑–±—Ä–æ—Å–æ–º\n",
    "        vt = (vt_mean + vt_jitter * torch.randn(n_hidden)).clamp(0.05, 2.0)\n",
    "        if not _set_param(lif_layer, \"v_thresh\", vt):\n",
    "            _set_param(lif_layer, \"thresh\", vt)  # thresh –∑–¥–µ—Å—å –∏–º–µ–Ω–Ω–æ Tensor, –Ω–µ float!\n",
    "\n",
    "        # –ú–µ–º–±—Ä–∞–Ω–Ω–∞—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (–∏–º—è –≤–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è –ø–æ –≤–µ—Ä—Å–∏—è–º)\n",
    "        if not _set_param(lif_layer, \"tau_m\", torch.full((n_hidden,), tau_val)):\n",
    "            _set_param(lif_layer, \"tau\",   torch.full((n_hidden,), tau_val))\n",
    "\n",
    "        # –í–ê–ñ–ù–û: —Ä–µ—Ñ—Ä–∞–∫—Ç–µ—Ä–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –°–ö–ê–õ–Ø–†–û–ú (0-D Tensor –∏–ª–∏ float)\n",
    "        _set_param(lif_layer, \"refrac\", refrac_val, prefer_scalar=True)\n",
    "\n",
    "        # reset ‚Äî —Å–∫–∞–ª—è—Ä\n",
    "        if not _set_param(lif_layer, \"v_reset\", 0.0, prefer_scalar=True):\n",
    "            _set_param(lif_layer, \"reset\",  0.0, prefer_scalar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080659-6ab0-4b4c-9dc8-1a070c04babe",
   "metadata": {},
   "source": [
    "# üß† Spiking Neural Network (SNN) –Ω–∞ –±–∞–∑–µ BindsNET —Å –æ–±—É—á–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ STDP\n",
    "\n",
    "–í —ç—Ç–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è —Å–ø–∞–π–∫–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å (SNN) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST.\n",
    "\n",
    "## üìå –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏:\n",
    "- **–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`Input`, 784 –Ω–µ–π—Ä–æ–Ω–∞)** ‚Äî –ø–æ –æ–¥–Ω–æ–º—É –Ω–µ–π—Ä–æ–Ω—É –Ω–∞ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 28√ó28.\n",
    "- **Poisson-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫** ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —è—Ä–∫–æ—Å—Ç—å –ø–∏–∫—Å–µ–ª–µ–π –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π (`Connection`)** ‚Äî —Å–æ–µ–¥–∏–Ω—è–µ—Ç –≤—Ö–æ–¥ —Å –≤—ã—Ö–æ–¥–æ–º (–º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ 784 √ó 100).\n",
    "- **–í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`LIF`, 100 –Ω–µ–π—Ä–æ–Ω–æ–≤)** ‚Äî Leaky Integrate-and-Fire –Ω–µ–π—Ä–æ–Ω—ã —Å —É—Ç–µ—á–∫–æ–π –∏ –ø–æ—Ä–æ–≥–æ–º.\n",
    "- **STDP (Spike-Timing Dependent Plasticity)** ‚Äî –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤; –≤–µ—Å–∞ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è, –µ—Å–ª–∏ –≤—Ö–æ–¥ –∞–∫—Ç–∏–≤–µ–Ω –¥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∞–π–∫–∞.\n",
    "\n",
    "## üî¨ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è:\n",
    "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ MNIST.\n",
    "2. –ö–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ Poisson-—Å–ø–∞–π–∫–æ–≤—ã–π –ø–æ—Ç–æ–∫.\n",
    "3. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–µ—Ç—å:\n",
    "   - `Input` –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏,\n",
    "   - `LIF` –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Å–æ–≤.\n",
    "4. –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:\n",
    "   - –°–ø–∞–π–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å `LIF`-–Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ –ø–æ–¥–∞—á–∏ –≤—Ö–æ–¥–∞.\n",
    "   - –°—É–º–º–∞ —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ (`Input`) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø–∏–∫—Å–µ–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã.\n",
    "   - –í–µ—Å–∞ –æ–¥–Ω–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ `LIF`-–Ω–µ–π—Ä–æ–Ω–∞ ‚Äî –¥–æ –∏ –ø–æ—Å–ª–µ STDP.\n",
    "\n",
    "## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:\n",
    "- –ì—Ä–∞—Ñ–∏–∫: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–∞–π–∫–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ/–ø–æ—Å–ª–µ + –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- –ì—Ä–∞—Ñ–∏–∫: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤, –≤–µ–¥—É—â–∏—Ö –∫ –Ω–µ–π—Ä–æ–Ω—É `LIF[42]` ‚Äî –≤–∏–¥–Ω–æ, –∫–∞–∫ STDP —É—Å–∏–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–≤—è–∑–∏.\n",
    "\n",
    "## üéØ –¶–µ–ª—å:\n",
    "–ü–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ SNN:\n",
    "- –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ—Ç–æ–∫ —Å–ø–∞–π–∫–æ–≤,\n",
    "- –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã,\n",
    "- –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ (STDP), –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62625648-17a4-47af-9950-dfa00b772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SETUP (Colab/Local) ======\n",
    "# !pip -q install bindsnet==0.2.8 torchvision==0.18.1 torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import os, itertools, random, csv, time as _ptime\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Utils ======\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def to_2d(s):  # [T,N] or [T,1,N] -> [T,N]\n",
    "    return s[:,0,:] if (s.dim()==3 and s.size(1)==1) else s\n",
    "\n",
    "# ====== Config ======\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    # core\n",
    "    time:   int = 200\n",
    "    n_hidden: int = 100\n",
    "    nu_plus:  float = 0.02\n",
    "    nu_minus: float = -0.02\n",
    "\n",
    "    # inhibition / WTA\n",
    "    inhib_strength: float = 0.3\n",
    "    inh_decay: float = 0.9\n",
    "    top_k: int = 0                    # 0 = WTA off for diagnostics\n",
    "    enable_inhibition_at_start: bool = False\n",
    "\n",
    "    # encoder\n",
    "    encoder: str = \"latency\"         # start with Poisson to \"ignite\" spikes\n",
    "\n",
    "    # homeostasis\n",
    "    target_spikes: float = 2.0\n",
    "    eta_up: float = 1.0\n",
    "    eta_down: float = 0.5\n",
    "    thresh_min: float = 0.2\n",
    "    thresh_max: float = 2.0\n",
    "    thresh_init: float = 0.5          # v_thresh initial (BindsNET positive scale)\n",
    "\n",
    "    # weights\n",
    "    w_clip_min: float = 0.0\n",
    "    w_clip_max: float = 1.5\n",
    "    w_col_target_norm: float = 20.0\n",
    "    w_init_lo: float = 0.8\n",
    "    w_init_hi: float = 1.2\n",
    "    wmin:float = 0.0\n",
    "    wmax:float = 2.0\n",
    "    # loop\n",
    "    N: int = 200\n",
    "    log_every: int = 50\n",
    "    seed: int = 42\n",
    "\n",
    "# ====== Helpers: WTA, norm, thresholds, plots, metrics ======\n",
    "def apply_wta(s, top_k=1):\n",
    "    s2 = to_2d(s)\n",
    "    sb = s2.sum(0).float().squeeze()\n",
    "    if sb.sum() == 0:\n",
    "        return False, None\n",
    "    vals, idxs = torch.topk(sb, k=min(top_k, sb.numel()))\n",
    "    s.zero_()\n",
    "    for j in idxs.tolist():\n",
    "        if s.dim()==3:\n",
    "            s[:,0,j] = True\n",
    "        else:\n",
    "            s[:,j] = True\n",
    "    return True, idxs.tolist()\n",
    "\n",
    "def weight_soft_bound_and_colnorm(conn_w, w_clip_min, w_clip_max, target_norm):\n",
    "    with torch.no_grad():\n",
    "        w = conn_w.data\n",
    "        w.clamp_(w_clip_min, w_clip_max)\n",
    "        col_norm = w.norm(p=1, dim=0, keepdim=True) + 1e-6\n",
    "        w.mul_(target_norm / col_norm)\n",
    "\n",
    "def adapt_thresholds(layer, spike_counts, cfg: Cfg):\n",
    "    with torch.no_grad():\n",
    "        vt = layer.v_thresh if hasattr(layer, \"v_thresh\") else layer.thresh\n",
    "        vt -= 0.05 * (spike_counts < 1.0).float()        # if silent -> lower threshold\n",
    "        vt += 0.02 * (spike_counts > 3.0).float()        # if too active -> raise\n",
    "        vt.clamp_(cfg.thresh_min, cfg.thresh_max)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt\n",
    "\n",
    "def spiking_metrics_window(lif_s, winners=None):\n",
    "    s = to_2d(lif_s).to(torch.bool)\n",
    "    T, N = s.shape\n",
    "    per_n = s.sum(0)\n",
    "    tot = int(per_n.sum())\n",
    "    active = int((per_n > 0).sum())\n",
    "    if tot > 0:\n",
    "        p = (per_n / tot).float().cpu().numpy()\n",
    "        HHI = float((p**2).sum())\n",
    "        ps = np.sort(p)\n",
    "        Gini = float((np.cumsum(ps).sum()/ps.sum() - (len(ps)+1)/2)/len(ps))\n",
    "    else:\n",
    "        HHI, Gini = 1.0, 1.0\n",
    "    uniq_winners = len(set(winners)) if winners else 0\n",
    "    return dict(T=T, N=N, total_spikes=tot, active=active, HHI=HHI, Gini=Gini, uniq_winners=uniq_winners)\n",
    "\n",
    "class SNNMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.samples=0; self.S_out=0; self.S_in=0; self.SynOps=0; self.V_updates=0\n",
    "        self.usage_counts = {}\n",
    "    def log_sample(self, lif_s, in_s, n_hidden, T, winners=None):\n",
    "        lif2 = to_2d(lif_s);  in2 = to_2d(in_s)\n",
    "        s_out = int(lif2.sum().item())\n",
    "        s_in  = int(in2.sum().item())\n",
    "        self.S_out += s_out; self.S_in += s_in\n",
    "        self.SynOps += s_in * n_hidden\n",
    "        self.V_updates += n_hidden * T\n",
    "        self.samples += 1\n",
    "        if winners:\n",
    "            for j in winners:\n",
    "                self.usage_counts[j] = self.usage_counts.get(j,0)+1\n",
    "    def report(self, a=1.0, b=0.05, c=0.005):\n",
    "        s = max(1, self.samples)\n",
    "        HHI_win = 0.0\n",
    "        if self.usage_counts:\n",
    "            tot = sum(self.usage_counts.values())\n",
    "            ps = np.array([v/tot for v in self.usage_counts.values()], dtype=float)\n",
    "            HHI_win = float((ps**2).sum())\n",
    "        return {\n",
    "            \"spikes_per_sample\": self.S_out/s,\n",
    "            \"synops_per_sample\": self.SynOps/s,\n",
    "            \"v_updates_per_sample\": self.V_updates/s,\n",
    "            \"energy_proxy_per_sample\": (a*self.S_out + b*self.SynOps + c*self.V_updates)/s,\n",
    "            \"winners_unique\": len(self.usage_counts),\n",
    "            \"winner_HHI\": HHI_win,\n",
    "        }\n",
    "\n",
    "# ====== Build Net & Encoder ======\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "def build_net(cfg: Cfg):\n",
    "    net = Network()\n",
    "\n",
    "    input_layer = Input(n=784, traces=True)\n",
    "    lif_layer   = LIFNodes(n=cfg.n_hidden, traces=True)\n",
    "    tune_lif_params(lif_layer, cfg.n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0)\n",
    "            \n",
    "    net.add_layer(input_layer, name='Input')\n",
    "    net.add_layer(lif_layer,   name='LIF')\n",
    "    \n",
    "\n",
    "    connection = Connection(source=input_layer, target=lif_layer)\n",
    "    connection.update_rule = PostPre(connection=connection,\n",
    "                                 nu=(torch.tensor(cfg.nu_plus),\n",
    "                                     torch.tensor(cfg.nu_minus)))\n",
    "    net.add_connection(connection, source='Input', target='LIF')\n",
    "\n",
    "    # Lateral inhibition (created, but optionally disabled at start)\n",
    "    W_inh = torch.full((cfg.n_hidden, cfg.n_hidden), -cfg.inhib_strength)\n",
    "    W_inh.fill_diagonal_(0.0)\n",
    "    recurrent_inh = Connection(source=lif_layer, target=lif_layer, w=W_inh.clone())\n",
    "    net.add_connection(recurrent_inh, source='LIF', target='LIF')\n",
    "\n",
    "    # Weights init (stronger to ignite)\n",
    "    with torch.no_grad():\n",
    "        connection.w.data.uniform_(cfg.w_init_lo, cfg.w_init_hi)\n",
    "\n",
    "    # Thresholds: use v_thresh if available\n",
    "    th0 = torch.full((cfg.n_hidden,), cfg.thresh_init)\n",
    "    if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh = th0.clone()\n",
    "    else: lif_layer.thresh = th0.clone()\n",
    "\n",
    "    # Optionally disable inhibition at start (for diagnostics)\n",
    "    if not cfg.enable_inhibition_at_start:\n",
    "        with torch.no_grad():\n",
    "            recurrent_inh.w.zero_()\n",
    "\n",
    "    return net, input_layer, lif_layer, connection, recurrent_inh, W_inh\n",
    "\n",
    "# –ü—Ä–µ-–ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL / np / tensor)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28), antialias=True),\n",
    "    transforms.ToTensor(),                 # -> [1,28,28] float in [0,1]\n",
    "    # –ù–∏–∫–∞–∫–∏—Ö Normalize(mean,std) –∑–¥–µ—Å—å ‚Äî –Ω–∞–º –Ω—É–∂–Ω—ã ¬´—Å—ã—Ä—ã–µ¬ª 0..1!\n",
    "])\n",
    "\n",
    "def make_encoder(encoder_type: str, T: int, rate_floor: float = 0.0):  # floor –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0\n",
    "    encoder_type = encoder_type.lower()\n",
    "    assert encoder_type in (\"poisson\", \"latency\")\n",
    "\n",
    "    def encode_poisson(img_tensor):\n",
    "        rates = img_tensor.view(-1).clamp(0, 1)\n",
    "        # –î–ï–õ–ê–ï–ú –†–ï–î–ö–ò–ô –ü–û–¢–û–ö, –ß–¢–û–ë–´ –ù–ï –ó–ê–õ–ò–í–ê–¢–¨ –°–ï–¢–¨\n",
    "        RATE_SCALE = 0.2\n",
    "        rates = rates * RATE_SCALE\n",
    "        # –Ω–µ–±–æ–ª—å—à–æ–π floor (–µ—Å–ª–∏ —Ö–æ—á–µ—à—å —Å–æ–≤—Å–µ–º –Ω–µ –Ω–æ–ª—å)\n",
    "        # rates = torch.maximum(rates, torch.full_like(rates, 5e-3))\n",
    "        rand = torch.rand((T, rates.numel()))\n",
    "        spikes = (rand < rates).float().view(T, 1, 784)\n",
    "        return spikes\n",
    "\n",
    "    def encode_latency(img_tensor):\n",
    "        x = img_tensor.squeeze(0).clamp(0, 1)\n",
    "        spikes = torch.zeros((T, 1, 784), dtype=torch.float32)\n",
    "        nz = (x > 0).nonzero(as_tuple=False)\n",
    "        if nz.numel() == 0:\n",
    "            return spikes\n",
    "        for idx in nz:\n",
    "            i, j = int(idx[0]), int(idx[1])\n",
    "            p = float(x[i, j])\n",
    "            t = int(round((1.0 - p) * (T - 1)))\n",
    "            # –º–∞–ª–µ–Ω—å–∫–∏–π –¥–∂–∏—Ç—Ç–µ—Ä ¬±1 —Ç–∏–∫ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–∫–Ω–∞)\n",
    "            if T >= 3:\n",
    "                t += int(torch.randint(-1, 2, (1,)).item())\n",
    "                t = max(0, min(T-1, t))\n",
    "            spikes[t, 0, i*28 + j] = 1.0\n",
    "        return spikes\n",
    "\n",
    "    return (encode_poisson if encoder_type == \"poisson\" else encode_latency), preprocess\n",
    "        \n",
    "def _to_2d(s):  # [T, B, N] -> [T, N]\n",
    "    return s[:, 0, :] if s.dim()==3 else s\n",
    "    \n",
    "# ====== One Experiment ======\n",
    "def run_experiment(cfg: Cfg, verbose=True):\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # –î–∞—Ç–∞—Å–µ—Ç (MNIST —É–∂–µ –≤ [0,1] –∏ [1,28,28])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # –°–µ—Ç—å + –º–æ–Ω–∏—Ç–æ—Ä—ã\n",
    "    net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "    with torch.no_grad():\n",
    "        recurrent_inh.w.fill_(0.0)\n",
    "        recurrent_inh.w -= 0.2 * (1 - torch.eye(cfg.n_hidden))  # –º—è–≥–∫–∞—è –∏–Ω–≥–∏–±–∏—Ü–∏—è\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    inp_mon = Monitor(input_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    net.add_monitor(lif_mon, name=\"lif_mon\")\n",
    "    net.add_monitor(inp_mon, name=\"inp_mon\")\n",
    "\n",
    "    # –≠–Ω–∫–æ–¥–µ—Ä\n",
    "    ENCODER_TYPE = cfg.encoder\n",
    "    T = cfg.time\n",
    "    encoder, _ = make_encoder(ENCODER_TYPE, T)\n",
    "\n",
    "    # --------- WARMUP (–±–µ–∑ STDP) ---------\n",
    "    WARMUP = getattr(cfg, \"warmup_N\", 50)\n",
    "    if WARMUP > 0:\n",
    "        # –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤ STDP –≤—ã–∫–ª.\n",
    "        set_stdp_nu(connection, 0.0, 0.0)\n",
    "        for wi in range(min(WARMUP, len(dataset))):\n",
    "            image = dataset[wi][\"image\"]\n",
    "            spike_input = encoder(image)\n",
    "            net.run(inputs={\"Input\": spike_input}, time=cfg.time)\n",
    "\n",
    "            # –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é ‚Äî –ø–æ–ª–µ–∑–Ω–æ)\n",
    "            lif_s_full = lif_mon.get(\"s\")\n",
    "            spike_counts = to_2d(lif_s_full).sum(0).float().squeeze()\n",
    "            adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=2.0)\n",
    "            \n",
    "\n",
    "            # –æ—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "            net.reset_state_variables()\n",
    "            lif_mon.reset_state_variables()\n",
    "            inp_mon.reset_state_variables()\n",
    "\n",
    "    # --------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ---------\n",
    "    meter = SNNMeter()\n",
    "    # –º—è–≥–∫–∏–π STDP –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    set_stdp_nu(connection, 2e-4, -1e-4)  # –±—ã–ª–æ 1e-3 / -5e-4\n",
    "    \n",
    "\n",
    "    for i in range(cfg.N):\n",
    "        sample = dataset[i]\n",
    "        image  = sample[\"image\"]\n",
    "        spike_input = encoder(image)\n",
    "        inputs = {\"Input\": spike_input}\n",
    "\n",
    "        net.run(inputs=inputs, time=cfg.time)\n",
    "\n",
    "        # –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\n",
    "        lif_s_full = lif_mon.get(\"s\")   # [T,B,N]\n",
    "        in_s_full  = inp_mon.get(\"s\")   # [T,B,784]\n",
    "        lif2 = _to_2d(lif_s_full); in2 = _to_2d(in_s_full)\n",
    "\n",
    "        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º\n",
    "        if i in (0, 50, 150):\n",
    "            print(\"INPUT spikes sum (window):\", int(in2.sum().item()))\n",
    "            print(\"LIF   spikes sum (window):\",   int(lif2.sum().item()))\n",
    "            print(\"INPUT window sum:\", int(in2.sum()))\n",
    "            print(\"LIF   window sum:\", int(lif2.sum()))\n",
    "            vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "            print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "            print(\"w[min,max]:\", float(connection.w.min()), float(connection.w.max()))\n",
    "\n",
    "        # WTA (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n",
    "        winners = None\n",
    "        if cfg.top_k and cfg.top_k > 0:\n",
    "            ok, winners = apply_wta(lif_layer.s, top_k=cfg.top_k)\n",
    "            if not ok:\n",
    "                net.reset_state_variables(); lif_mon.reset_state_variables(); inp_mon.reset_state_variables()\n",
    "                continue\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–∫–Ω–∞\n",
    "        m = spiking_metrics_window(lif_s_full, winners)\n",
    "        if verbose and ((i+1) % cfg.log_every == 0 or i == 0):\n",
    "            print(f\"[{i+1}] total={m['total_spikes']} active={m['active']}/{m['N']} HHI={m['HHI']:.3f}\")\n",
    "\n",
    "        # Homeostasis –ø–æ ¬´—Å—ã—Ä—ã–º¬ª —Å–ø–∞–π–∫–∞–º (–¥–æ WTA)\n",
    "        spike_counts = to_2d(lif_s_full).sum(0).float()\n",
    "        adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "\n",
    "        # –ö–ª–∞–º–ø –≤–µ—Å–æ–≤ (–±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –∫–æ–ª–æ–Ω–æ—á–Ω–æ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥—ã–π —à–∞–≥)\n",
    "        with torch.no_grad():\n",
    "            connection.w.clamp_(0.0, 1.0)\n",
    "\n",
    "        # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ / —É—á—ë—Ç\n",
    "        meter.log_sample(lif_s_full, in_s_full, cfg.n_hidden, cfg.time, winners=winners)\n",
    "\n",
    "        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –º–æ–Ω–∏—Ç–æ—Ä–æ–≤\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "        inp_mon.reset_state_variables()\n",
    "\n",
    "   \n",
    "    rpt = meter.report()\n",
    "    if getattr(meter, \"samples\", 0) == 0:\n",
    "        print(\"!! meter: no samples logged ‚Äî –ø—Ä–æ–≤–µ—Ä—å –ø–æ—Ä—è–¥–æ–∫ log_sample()/reset() –∏ continue –≤ —Ü–∏–∫–ª–µ\")\n",
    "    out = {**asdict(cfg), **rpt}\n",
    "    return out\n",
    "\n",
    "# ====== Grid Runner (compact) ======\n",
    "def grid_run(base: Cfg):\n",
    "    grid = {\n",
    "        \"inhib_strength\": [0.3, 0.5],\n",
    "        \"top_k\": [0, 3],\n",
    "        \"time\": [200, 300],\n",
    "        \"use_latency\": [False, True],\n",
    "    }\n",
    "    keys, vals = zip(*grid.items())\n",
    "    results = []\n",
    "    t0 = _ptime.time()\n",
    "    for combo in itertools.product(*vals):\n",
    "        cfg = Cfg(**{**asdict(base), **dict(zip(keys, combo))})\n",
    "        print(\">>> run:\", {k: getattr(cfg,k) for k in keys})\n",
    "        res = run_experiment(cfg, verbose=False)\n",
    "        print({k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "        results.append(res)\n",
    "\n",
    "    os.makedirs(\"out\", exist_ok=True)\n",
    "    csv_path = os.path.join(\"out\",\"snn_energy_accuracy_grid.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
    "        writer.writeheader(); writer.writerows(results)\n",
    "    print(f\"Saved: {csv_path} | runs={len(results)} | elapsed={_ptime.time()-t0:.1f}s\")\n",
    "\n",
    "    # quick Pareto-ish\n",
    "    best = (sorted(results, key=lambda r: (r[\"energy_proxy_per_sample\"], r[\"winner_HHI\"], -r[\"winners_unique\"])))[:5]\n",
    "    print(\"\\nTop-5 Pareto-ish:\")\n",
    "    for r in best:\n",
    "        print({k: r[k] for k in [\"inhib_strength\",\"top_k\",\"time\",\"use_latency\",\n",
    "                                 \"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f8eb2b6-28b4-499d-9679-d66f8b0c23c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[]' is invalid for input of size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Cfg(\n\u001b[1;32m      2\u001b[0m     time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m      3\u001b[0m     n_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     nu_minus \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSUMMARY:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k: res[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspikes_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinners_unique\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinner_HHI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_proxy_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "Cell \u001b[0;32mIn[40], line 237\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(cfg, verbose)\u001b[0m\n\u001b[1;32m    235\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# –°–µ—Ç—å + –º–æ–Ω–∏—Ç–æ—Ä—ã\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m net, input_layer, lif_layer, connection, recurrent_inh, W_inh \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    239\u001b[0m     recurrent_inh\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 150\u001b[0m, in \u001b[0;36mbuild_net\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    148\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m784\u001b[39m, traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    149\u001b[0m lif_layer   \u001b[38;5;241m=\u001b[39m LIFNodes(n\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_hidden, traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 150\u001b[0m \u001b[43mtune_lif_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlif_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvt_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvt_jitter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefrac_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m net\u001b[38;5;241m.\u001b[39madd_layer(input_layer, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    153\u001b[0m net\u001b[38;5;241m.\u001b[39madd_layer(lif_layer,   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIF\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 41\u001b[0m, in \u001b[0;36mtune_lif_params\u001b[0;34m(lif_layer, n_hidden, vt_mean, vt_jitter, tau_val, refrac_val)\u001b[0m\n\u001b[1;32m     39\u001b[0m vt \u001b[38;5;241m=\u001b[39m (vt_mean \u001b[38;5;241m+\u001b[39m vt_jitter \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(n_hidden))\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _set_param(lif_layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_thresh\u001b[39m\u001b[38;5;124m\"\u001b[39m, vt):\n\u001b[0;32m---> 41\u001b[0m     \u001b[43m_set_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlif_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthresh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# thresh –∑–¥–µ—Å—å –∏–º–µ–Ω–Ω–æ Tensor, –Ω–µ float!\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# –ú–µ–º–±—Ä–∞–Ω–Ω–∞—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (–∏–º—è –≤–∞—Ä—å–∏—Ä—É–µ—Ç—Å—è –ø–æ –≤–µ—Ä—Å–∏—è–º)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _set_param(lif_layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtau_m\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mfull((n_hidden,), tau_val)):\n",
      "Cell \u001b[0;32mIn[39], line 25\u001b[0m, in \u001b[0;36m_set_param\u001b[0;34m(module, name, value, prefer_scalar)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m cur\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m---> 25\u001b[0m             value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m         cur\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(value\u001b[38;5;241m.\u001b[39mto(cur\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mcur\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[]' is invalid for input of size 100"
     ]
    }
   ],
   "source": [
    "cfg = Cfg(\n",
    "    time=300,\n",
    "    n_hidden=100,\n",
    "    encoder=\"latency\",                 # —Å–Ω–∞—á–∞–ª–∞ Poisson\n",
    "    top_k=0,                           # WTA –≤—ã–∫–ª. –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "    enable_inhibition_at_start=False,  # –∏–Ω–≥–∏–±–∏—Ü–∏—é –≤–∫–ª—é—á–∏–º –ø–æ–∑–∂–µ\n",
    "    nu_plus = 0.002,\n",
    "    nu_minus = -0.001\n",
    ")\n",
    "res = run_experiment(cfg, verbose=True)\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67314ca5-f60c-435e-945a-7594a098bfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
