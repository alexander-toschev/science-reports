{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f620028-87ed-4c99-a115-950ce07e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class LatencyEncoder:\n",
    "    def __init__(self, time: int = 100):\n",
    "        self.time = time  # –û–±—â–µ–µ —á–∏—Å–ª–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤\n",
    "\n",
    "    def __call__(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        image: Tensor [1, 28, 28] –∏–ª–∏ [28, 28], –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1 –∏–ª–∏ –¥–æ 255\n",
    "        return: spike_tensor [time, 1, 784]\n",
    "        \"\"\"\n",
    "        if image.ndim == 3:\n",
    "            image = image.squeeze()\n",
    "\n",
    "        if image.max() > 1:\n",
    "            image = image / 255.0\n",
    "\n",
    "        spike_tensor = torch.zeros((self.time, 1, 784))\n",
    "\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                pixel = image[i, j].item()\n",
    "                if pixel > 0:\n",
    "                    spike_time = int((1.0 - pixel) * (self.time - 1))\n",
    "                    spike_tensor[spike_time, 0, i * 28 + j] = 1.0\n",
    "\n",
    "        return spike_tensor.view(self.time, 1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297294ce-41ea-4446-bfed-081c022d6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stdp_nu(conn, nu_plus, nu_minus):\n",
    "    dev = conn.w.device\n",
    "    conn.update_rule.nu = (torch.tensor(nu_plus, device=dev),\n",
    "                           torch.tensor(nu_minus, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04cd6b1-9541-4bf7-bfec-daba59b3f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–¥ run_experiment\n",
    "class ThreshEMA:\n",
    "    def __init__(self): self.rate_ema = None\n",
    "    def step(self, layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "        with torch.no_grad():\n",
    "            rate = spike_counts / max(1, T)\n",
    "            if self.rate_ema is None:\n",
    "                self.rate_ema = rate.clone()\n",
    "            self.rate_ema = alpha * self.rate_ema + (1 - alpha) * rate\n",
    "            vt = layer.v_thresh if hasattr(layer,'v_thresh') else layer.thresh\n",
    "            vt += k * (self.rate_ema - target)\n",
    "            vt.clamp_(0.15, 1.2)\n",
    "            if hasattr(layer,'v_thresh'): layer.v_thresh = vt\n",
    "            else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd656371-a693-4252-9532-7e8105b90ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rate_ema = None\n",
    "def adapt_thresholds_ema(layer, spike_counts, T, target=1.5, alpha=0.9, k=0.02):\n",
    "    global _rate_ema\n",
    "    with torch.no_grad():\n",
    "        rate = spike_counts / max(1, T)\n",
    "        if _rate_ema is None: _rate_ema = rate.clone()\n",
    "        _rate_ema = alpha * _rate_ema + (1 - alpha) * rate\n",
    "        vt = layer.v_thresh if hasattr(layer,\"v_thresh\") else layer.thresh\n",
    "        vt += k * (_rate_ema - target)\n",
    "        vt.clamp_(vt_min, vt_max)  \n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6059930-22e3-4bdf-af94-50037eb25be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_param(module, name, value, prefer_scalar=False, fallback_scalar=None):\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ—Å—Ç–∞–≤–ª—è–µ—Ç module.<name>.\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor —Å–∫–∞–ª—è—Ä–Ω—ã–π (numel()==1) –∏ value –≤–µ–∫—Ç–æ—Ä -> –∫–ª–∞–¥—ë–º 0-D —Ç–µ–Ω–∑–æ—Ä (—Å—Ä. –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ fallback_scalar).\n",
    "    - –ï—Å–ª–∏ –±—É—Ñ–µ—Ä Tensor –≤–µ–∫—Ç–æ—Ä–Ω—ã–π -> –∫–æ–ø–∏—Ä—É–µ–º –ø–æ —Ñ–æ—Ä–º–µ.\n",
    "    - prefer_scalar=True –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –¥–µ–ª–∞–µ—Ç 0-D (–¥–ª—è refrac/reset).\n",
    "    \"\"\"\n",
    "    if not hasattr(module, name):\n",
    "        return False\n",
    "\n",
    "    cur = getattr(module, name)\n",
    "\n",
    "    # –µ—Å–ª–∏ —ç—Ç–æ Tensor-–±—É—Ñ–µ—Ä\n",
    "    if isinstance(cur, torch.Tensor):\n",
    "        dev, dt = cur.device, cur.dtype\n",
    "\n",
    "        if prefer_scalar:\n",
    "            # –≤—Å–µ–≥–¥–∞ 0-D —Ç–µ–Ω–∑–æ—Ä\n",
    "            val = float(value.mean().item() if torch.is_tensor(value) else value)\n",
    "            setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            return True\n",
    "\n",
    "        if torch.is_tensor(value):\n",
    "            if cur.numel() == 1 and value.numel() > 1:\n",
    "                # –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π, value –≤–µ–∫—Ç–æ—Ä -> –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ/—Ñ–æ–ª–±—ç–∫\n",
    "                val = float(value.mean().item())\n",
    "                if fallback_scalar is not None:\n",
    "                    val = float(fallback_scalar)\n",
    "                setattr(module, name, torch.tensor(val, device=dev, dtype=dt))\n",
    "            else:\n",
    "                if value.shape != cur.shape:\n",
    "                    value = value.view_as(cur)\n",
    "                cur.data.copy_(value.to(dev, dtype=dt))\n",
    "        else:\n",
    "            # value —Å–∫–∞–ª—è—Ä Python -> –ø—Ä–æ—Å—Ç–æ –∑–∞–ª–∏–≤–∞–µ–º\n",
    "            if cur.numel() == 1:\n",
    "                setattr(module, name, torch.tensor(float(value), device=dev, dtype=dt))\n",
    "            else:\n",
    "                cur.data.fill_(float(value))\n",
    "        return True\n",
    "\n",
    "    # –Ω–µ Tensor-–±—É—Ñ–µ—Ä ‚Äì –æ–±—ã—á–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç\n",
    "    setattr(module, name, float(value) if prefer_scalar else value)\n",
    "    return True\n",
    "\n",
    "\n",
    "def tune_lif_params(lif_layer, n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0):\n",
    "    with torch.no_grad():\n",
    "        # –ø–æ—Ä–æ–≥: –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ—Å—Ç–∞–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä; –µ—Å–ª–∏ –±—É—Ñ–µ—Ä —Å–∫–∞–ª—è—Ä–Ω—ã–π ‚Äî –∞–≤—Ç–æ-–¥–∞—É–Ω–º–∏–∫—Å –≤ —Å–∫–∞–ª—è—Ä\n",
    "        vt_vec = (vt_mean + vt_jitter * torch.randn(n_hidden)).clamp(0.05, 2.0)\n",
    "        if not _set_param(lif_layer, \"v_thresh\", vt_vec, fallback_scalar=vt_mean):\n",
    "            _set_param(lif_layer, \"thresh\", vt_vec, fallback_scalar=vt_mean)\n",
    "\n",
    "        # tau: –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å v–µ–∫—Ç–æ—Ä/—Å–∫–∞–ª—è—Ä –≤ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö)\n",
    "        if not _set_param(lif_layer, \"tau_m\", torch.full((n_hidden,), tau_val), fallback_scalar=tau_val):\n",
    "            _set_param(lif_layer, \"tau\",   torch.full((n_hidden,), tau_val),   fallback_scalar=tau_val)\n",
    "\n",
    "        # refrac ‚Äî —Å—Ç—Ä–æ–≥–æ —Å–∫–∞–ª—è—Ä (0-D)\n",
    "        _set_param(lif_layer, \"refrac\", refrac_val, prefer_scalar=True)\n",
    "\n",
    "        # reset ‚Äî —Å–∫–∞–ª—è—Ä\n",
    "        if not _set_param(lif_layer, \"v_reset\", 0.0, prefer_scalar=True):\n",
    "            _set_param(lif_layer, \"reset\",  0.0, prefer_scalar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1080659-6ab0-4b4c-9dc8-1a070c04babe",
   "metadata": {},
   "source": [
    "# üß† Spiking Neural Network (SNN) –Ω–∞ –±–∞–∑–µ BindsNET —Å –æ–±—É—á–µ–Ω–∏–µ–º —á–µ—Ä–µ–∑ STDP\n",
    "\n",
    "–í —ç—Ç–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –±–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–∞—è —Å–ø–∞–π–∫–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å (SNN) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST.\n",
    "\n",
    "## üìå –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏:\n",
    "- **–í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`Input`, 784 –Ω–µ–π—Ä–æ–Ω–∞)** ‚Äî –ø–æ –æ–¥–Ω–æ–º—É –Ω–µ–π—Ä–æ–Ω—É –Ω–∞ –∫–∞–∂–¥—ã–π –ø–∏–∫—Å–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 28√ó28.\n",
    "- **Poisson-–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫** ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —è—Ä–∫–æ—Å—Ç—å –ø–∏–∫—Å–µ–ª–µ–π –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- **–ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π (`Connection`)** ‚Äî —Å–æ–µ–¥–∏–Ω—è–µ—Ç –≤—Ö–æ–¥ —Å –≤—ã—Ö–æ–¥–æ–º (–º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ 784 √ó 100).\n",
    "- **–í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (`LIF`, 100 –Ω–µ–π—Ä–æ–Ω–æ–≤)** ‚Äî Leaky Integrate-and-Fire –Ω–µ–π—Ä–æ–Ω—ã —Å —É—Ç–µ—á–∫–æ–π –∏ –ø–æ—Ä–æ–≥–æ–º.\n",
    "- **STDP (Spike-Timing Dependent Plasticity)** ‚Äî –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤; –≤–µ—Å–∞ —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è, –µ—Å–ª–∏ –≤—Ö–æ–¥ –∞–∫—Ç–∏–≤–µ–Ω –¥–æ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∞–π–∫–∞.\n",
    "\n",
    "## üî¨ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è:\n",
    "1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ MNIST.\n",
    "2. –ö–æ–¥–∏—Ä—É–µ—Ç—Å—è –≤ Poisson-—Å–ø–∞–π–∫–æ–≤—ã–π –ø–æ—Ç–æ–∫.\n",
    "3. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ —Å–µ—Ç—å:\n",
    "   - `Input` –ø–æ–ª—É—á–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏,\n",
    "   - `LIF` –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–∏—Ä—É—é—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Å–æ–≤.\n",
    "4. –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:\n",
    "   - –°–ø–∞–π–∫–æ–≤–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å `LIF`-–Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ –ø–æ–¥–∞—á–∏ –≤—Ö–æ–¥–∞.\n",
    "   - –°—É–º–º–∞ —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ (`Input`) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–∏–µ –ø–∏–∫—Å–µ–ª–∏ –∞–∫—Ç–∏–≤–Ω—ã.\n",
    "   - –í–µ—Å–∞ –æ–¥–Ω–æ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ `LIF`-–Ω–µ–π—Ä–æ–Ω–∞ ‚Äî –¥–æ –∏ –ø–æ—Å–ª–µ STDP.\n",
    "\n",
    "## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:\n",
    "- –ì—Ä–∞—Ñ–∏–∫: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ø–∞–π–∫–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ–π—Ä–æ–Ω–æ–≤ –¥–æ/–ø–æ—Å–ª–µ + –≤—Ö–æ–¥–Ω—ã–µ —Å–ø–∞–π–∫–∏.\n",
    "- –ì—Ä–∞—Ñ–∏–∫: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤, –≤–µ–¥—É—â–∏—Ö –∫ –Ω–µ–π—Ä–æ–Ω—É `LIF[42]` ‚Äî –≤–∏–¥–Ω–æ, –∫–∞–∫ STDP —É—Å–∏–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–∏–º—ã–µ —Å–≤—è–∑–∏.\n",
    "\n",
    "## üéØ –¶–µ–ª—å:\n",
    "–ü–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ SNN:\n",
    "- –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ø–æ—Ç–æ–∫ —Å–ø–∞–π–∫–æ–≤,\n",
    "- –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω—ã,\n",
    "- –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ (STDP), –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62625648-17a4-47af-9950-dfa00b772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SETUP (Colab/Local) ======\n",
    "# !pip -q install bindsnet==0.2.8 torchvision==0.18.1 torch==2.3.1 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import os, itertools, random, csv, time as _ptime\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====== Utils ======\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "def to_2d(s):  # [T,N] or [T,1,N] -> [T,N]\n",
    "    return s[:,0,:] if (s.dim()==3 and s.size(1)==1) else s\n",
    "\n",
    "# ====== Config ======\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    # core\n",
    "    time:   int = 200\n",
    "    n_hidden: int = 100\n",
    "    nu_plus:  float = 0.02\n",
    "    nu_minus: float = -0.02\n",
    "\n",
    "    # inhibition / WTA\n",
    "    inhib_strength: float = 0.3\n",
    "    inh_decay: float = 0.9\n",
    "    top_k: int = 0                    # 0 = WTA off for diagnostics\n",
    "    enable_inhibition_at_start: bool = False\n",
    "\n",
    "    # encoder\n",
    "    encoder: str = \"latency\"         # start with Poisson to \"ignite\" spikes\n",
    "\n",
    "    # homeostasis\n",
    "    target_spikes: float = 2.0\n",
    "    eta_up: float = 1.0\n",
    "    eta_down: float = 0.5\n",
    "    thresh_min: float = 0.2\n",
    "    thresh_max: float = 2.0\n",
    "    thresh_init: float = 0.5          # v_thresh initial (BindsNET positive scale)\n",
    "\n",
    "    # weights\n",
    "    w_clip_min: float = 0.0\n",
    "    w_clip_max: float = 1.5\n",
    "    w_col_target_norm: float = 20.0\n",
    "    w_init_lo: float = 0.8\n",
    "    w_init_hi: float = 1.2\n",
    "    wmin:float = 0.0\n",
    "    wmax:float = 2.0\n",
    "    warmup_N: int = 50\n",
    "    # loop\n",
    "    N: int = 200\n",
    "    log_every: int = 50\n",
    "    seed: int = 42\n",
    "    poisson_rate_scale: float = 0.7 \n",
    "\n",
    "# ====== Helpers: WTA, norm, thresholds, plots, metrics ======\n",
    "def apply_wta(s, top_k=1):\n",
    "    s2 = to_2d(s)\n",
    "    sb = s2.sum(0).float().squeeze()\n",
    "    if sb.sum() == 0:\n",
    "        return False, None\n",
    "    vals, idxs = torch.topk(sb, k=min(top_k, sb.numel()))\n",
    "    s.zero_()\n",
    "    for j in idxs.tolist():\n",
    "        if s.dim()==3:\n",
    "            s[:,0,j] = True\n",
    "        else:\n",
    "            s[:,j] = True\n",
    "    return True, idxs.tolist()\n",
    "\n",
    "def weight_soft_bound_and_colnorm(conn_w, w_clip_min, w_clip_max, target_norm):\n",
    "    with torch.no_grad():\n",
    "        w = conn_w.data\n",
    "        w.clamp_(w_clip_min, w_clip_max)\n",
    "        col_norm = w.norm(p=1, dim=0, keepdim=True) + 1e-6\n",
    "        w.mul_(target_norm / col_norm)\n",
    "\n",
    "def adapt_thresholds(layer, spike_counts, cfg: Cfg):\n",
    "    with torch.no_grad():\n",
    "        vt = layer.v_thresh if hasattr(layer, \"v_thresh\") else layer.thresh\n",
    "        vt -= 0.05 * (spike_counts < 1.0).float()        # if silent -> lower threshold\n",
    "        vt += 0.02 * (spike_counts > 3.0).float()        # if too active -> raise\n",
    "        vt.clamp_(cfg.thresh_min, cfg.thresh_max)\n",
    "        if hasattr(layer, \"v_thresh\"): layer.v_thresh = vt\n",
    "        else: layer.thresh = vt\n",
    "\n",
    "def spiking_metrics_window(lif_s, winners=None):\n",
    "    s = to_2d(lif_s).to(torch.bool)\n",
    "    T, N = s.shape\n",
    "    per_n = s.sum(0)\n",
    "    tot = int(per_n.sum())\n",
    "    active = int((per_n > 0).sum())\n",
    "    if tot > 0:\n",
    "        p = (per_n / tot).float().cpu().numpy()\n",
    "        HHI = float((p**2).sum())\n",
    "        ps = np.sort(p)\n",
    "        Gini = float((np.cumsum(ps).sum()/ps.sum() - (len(ps)+1)/2)/len(ps))\n",
    "    else:\n",
    "        HHI, Gini = 1.0, 1.0\n",
    "    uniq_winners = len(set(winners)) if winners else 0\n",
    "    return dict(T=T, N=N, total_spikes=tot, active=active, HHI=HHI, Gini=Gini, uniq_winners=uniq_winners)\n",
    "\n",
    "class SNNMeter:\n",
    "    def __init__(self): self.reset()\n",
    "    def reset(self):\n",
    "        self.samples=0; self.S_out=0; self.S_in=0; self.SynOps=0; self.V_updates=0\n",
    "        self.usage_counts = {}\n",
    "    def log_sample(self, lif_s, in_s, n_hidden, T, winners=None):\n",
    "        lif2 = to_2d(lif_s);  in2 = to_2d(in_s)\n",
    "        s_out = int(lif2.sum().item())\n",
    "        s_in  = int(in2.sum().item())\n",
    "        self.S_out += s_out; self.S_in += s_in\n",
    "        self.SynOps += s_in * n_hidden\n",
    "        self.V_updates += n_hidden * T\n",
    "        self.samples += 1\n",
    "        if winners:\n",
    "            for j in winners:\n",
    "                self.usage_counts[j] = self.usage_counts.get(j,0)+1\n",
    "    def report(self, a=1.0, b=0.05, c=0.005):\n",
    "        s = max(1, self.samples)\n",
    "        HHI_win = 0.0\n",
    "        if self.usage_counts:\n",
    "            tot = sum(self.usage_counts.values())\n",
    "            ps = np.array([v/tot for v in self.usage_counts.values()], dtype=float)\n",
    "            HHI_win = float((ps**2).sum())\n",
    "        return {\n",
    "            \"spikes_per_sample\": self.S_out/s,\n",
    "            \"synops_per_sample\": self.SynOps/s,\n",
    "            \"v_updates_per_sample\": self.V_updates/s,\n",
    "            \"energy_proxy_per_sample\": (a*self.S_out + b*self.SynOps + c*self.V_updates)/s,\n",
    "            \"winners_unique\": len(self.usage_counts),\n",
    "            \"winner_HHI\": HHI_win,\n",
    "        }\n",
    "\n",
    "# ====== Build Net & Encoder ======\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "def build_net(cfg: Cfg):\n",
    "    net = Network()\n",
    "\n",
    "    input_layer = Input(n=784, traces=True)\n",
    "    lif_layer   = LIFNodes(n=cfg.n_hidden, traces=True)\n",
    "    tune_lif_params(lif_layer, cfg.n_hidden, vt_mean=0.35, vt_jitter=0.02, tau_val=50.0, refrac_val=2.0)\n",
    "            \n",
    "    net.add_layer(input_layer, name='Input')\n",
    "    net.add_layer(lif_layer,   name='LIF')\n",
    "    \n",
    "\n",
    "    connection = Connection(source=input_layer, target=lif_layer)\n",
    "    connection.update_rule = PostPre(connection=connection,\n",
    "                                 nu=(torch.tensor(cfg.nu_plus),\n",
    "                                     torch.tensor(cfg.nu_minus)))\n",
    "    net.add_connection(connection, source='Input', target='LIF')\n",
    "\n",
    "    # Lateral inhibition (created, but optionally disabled at start)\n",
    "    W_inh = torch.full((cfg.n_hidden, cfg.n_hidden), -cfg.inhib_strength)\n",
    "    W_inh.fill_diagonal_(0.0)\n",
    "    recurrent_inh = Connection(source=lif_layer, target=lif_layer, w=W_inh.clone())\n",
    "    net.add_connection(recurrent_inh, source='LIF', target='LIF')\n",
    "\n",
    "    # Weights init (stronger to ignite)\n",
    "    with torch.no_grad():\n",
    "        connection.w.data.uniform_(cfg.w_init_lo, cfg.w_init_hi)\n",
    "\n",
    "    # Thresholds: use v_thresh if available\n",
    "    th0 = torch.full((cfg.n_hidden,), cfg.thresh_init)\n",
    "    if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh = th0.clone()\n",
    "    else: lif_layer.thresh = th0.clone()\n",
    "\n",
    "    # Optionally disable inhibition at start (for diagnostics)\n",
    "    if not cfg.enable_inhibition_at_start:\n",
    "        with torch.no_grad():\n",
    "            recurrent_inh.w.zero_()\n",
    "\n",
    "    return net, input_layer, lif_layer, connection, recurrent_inh, W_inh\n",
    "\n",
    "# –ü—Ä–µ-–ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL / np / tensor)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28), antialias=True),\n",
    "    transforms.ToTensor(),                 # -> [1,28,28] float in [0,1]\n",
    "    # –ù–∏–∫–∞–∫–∏—Ö Normalize(mean,std) –∑–¥–µ—Å—å ‚Äî –Ω–∞–º –Ω—É–∂–Ω—ã ¬´—Å—ã—Ä—ã–µ¬ª 0..1!\n",
    "])\n",
    "\n",
    "def make_encoder(encoder_type: str, T: int, rate_floor: float = 0.0,poisson_rate_scale: float = 0.7 ):  # floor –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0\n",
    "    encoder_type = encoder_type.lower()\n",
    "    assert encoder_type in (\"poisson\", \"latency\")\n",
    "\n",
    "    def encode_poisson(img_tensor):\n",
    "        x = img_tensor.view(-1).clamp(0, 1)\n",
    "        rates = x * poisson_rate_scale\n",
    "        rand = torch.rand((T, rates.numel()), device=rates.device if x.is_cuda else None)\n",
    "        spikes = (rand < rates).float()\n",
    "        return spikes.view(T, 1, 784)\n",
    "\n",
    "    def encode_latency(img_tensor):\n",
    "        x = img_tensor.squeeze(0).clamp(0, 1)\n",
    "        spikes = torch.zeros((T, 1, 784), dtype=torch.float32)\n",
    "        nz = (x > 0).nonzero(as_tuple=False)\n",
    "        if nz.numel() == 0:\n",
    "            return spikes\n",
    "        for idx in nz:\n",
    "            i, j = int(idx[0]), int(idx[1])\n",
    "            p = float(x[i, j])\n",
    "            t = int(round((1.0 - p) * (T - 1)))\n",
    "            # –º–∞–ª–µ–Ω—å–∫–∏–π –¥–∂–∏—Ç—Ç–µ—Ä ¬±1 —Ç–∏–∫ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–∫–Ω–∞)\n",
    "            if T >= 3:\n",
    "                t += int(torch.randint(-1, 2, (1,)).item())\n",
    "                t = max(0, min(T-1, t))\n",
    "            spikes[t, 0, i*28 + j] = 1.0\n",
    "        return spikes\n",
    "\n",
    "    return (encode_poisson if encoder_type == \"poisson\" else encode_latency), preprocess\n",
    "        \n",
    "def _to_2d(s):  # [T, B, N] -> [T, N]\n",
    "    return s[:, 0, :] if s.dim()==3 else s\n",
    "    \n",
    "# ====== One Experiment ======\n",
    "def run_experiment(cfg: Cfg, verbose=True):\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # –î–∞—Ç–∞—Å–µ—Ç (MNIST —É–∂–µ –≤ [0,1] –∏ [1,28,28])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # –°–µ—Ç—å + –º–æ–Ω–∏—Ç–æ—Ä—ã\n",
    "    net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "    # ‚Üì –°–†–ê–ó–£ –ü–û–°–õ–ï build_net(cfg)\n",
    "    with torch.no_grad():\n",
    "        # —É —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π BindsNET –ø–æ—Ä–æ–≥ –ª–µ–∂–∏—Ç –≤ v_thresh –ò–õ–ò –≤ thresh\n",
    "        if hasattr(lif_layer, \"v_thresh\"):\n",
    "            vt = lif_layer.v_thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.v_thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)  # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.v_thresh.fill_(0.12)\n",
    "        else:\n",
    "            vt = lif_layer.thresh\n",
    "            if isinstance(vt, torch.Tensor) and vt.numel() == 1:\n",
    "                lif_layer.thresh = torch.tensor(0.12, device=vt.device, dtype=vt.dtype)   # 0-D —Ç–µ–Ω–∑–æ—Ä!\n",
    "            else:\n",
    "                lif_layer.thresh.fill_(0.12)\n",
    "        if hasattr(lif_layer, \"refrac\"):\n",
    "            lif_layer.refrac = torch.tensor(2.0, device=vt.device)  # 2 —Ç–∏–∫–∞\n",
    "            #print(f\"set refrac {lif_layer.refrac}\")\n",
    "            \n",
    "    \n",
    "    # –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ ‚Äî –æ—Å—Ç–∞–≤—å print –æ–¥–∏–Ω —Ä–∞–∑\n",
    "    vt_chk = (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\">>> THRESH SET TO:\", float(vt_chk.mean().item()))\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    rf = lif_layer.refrac\n",
    "    #print(\"v_thresh mean¬±std refrac:\", float(vt.mean()), float(vt.std()),rf)\n",
    "    \n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    inp_mon = Monitor(input_layer, state_vars=(\"s\",), time=cfg.time)\n",
    "    net.add_monitor(lif_mon, name=\"lif_mon\")\n",
    "    net.add_monitor(inp_mon, name=\"inp_mon\")\n",
    "\n",
    "    # –≠–Ω–∫–æ–¥–µ—Ä\n",
    "    ENCODER_TYPE = cfg.encoder\n",
    "    T = cfg.time\n",
    "    encoder, _ = make_encoder(ENCODER_TYPE, T, poisson_rate_scale=cfg.poisson_rate_scale)\n",
    "    \n",
    "    # --------- WARMUP (–±–µ–∑ STDP) ---------\n",
    "    WARMUP = getattr(cfg, \"warmup_N\", 50)\n",
    "    if WARMUP > 0:\n",
    "        # –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤ STDP –≤—ã–∫–ª.\n",
    "        set_stdp_nu(connection, 0.0, 0.0)\n",
    "        for wi in range(min(WARMUP, len(dataset))):\n",
    "            image = dataset[wi][\"image\"]\n",
    "            spike_input = encoder(image)\n",
    "            net.run(inputs={\"Input\": spike_input}, time=cfg.time)\n",
    "\n",
    "            # –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ –ø—Ä–æ–≥—Ä–µ–≤–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é ‚Äî –ø–æ–ª–µ–∑–Ω–æ)\n",
    "            lif_s_full = lif_mon.get(\"s\")\n",
    "            spike_counts = to_2d(lif_s_full).sum(0).float().squeeze()\n",
    "            # adapt_thresholds_ema(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "            \n",
    "\n",
    "            # –æ—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏–π –º–µ–∂–¥—É –ø—Ä–∏–º–µ—Ä–∞–º–∏\n",
    "            net.reset_state_variables()\n",
    "            lif_mon.reset_state_variables()\n",
    "            inp_mon.reset_state_variables()\n",
    "\n",
    "    vt =  (lif_layer.v_thresh if hasattr(lif_layer,\"v_thresh\") else lif_layer.thresh)\n",
    "    #print(\"v_thresh mean¬±std:\", float(vt.mean()), float(vt.std()))\n",
    "    # --------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ---------\n",
    "    with torch.no_grad():\n",
    "        I = torch.eye(cfg.n_hidden, device=recurrent_inh.w.device, dtype=recurrent_inh.w.dtype)\n",
    "        recurrent_inh.w.copy_(-0.55 * (1 - I)) \n",
    "    ema = ThreshEMA()\n",
    "    meter = SNNMeter()\n",
    "    # –º—è–≥–∫–∏–π STDP –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ–≤–∞\n",
    "    set_stdp_nu(connection, cfg.nu_plus, cfg.nu_minus) # –±—ã–ª–æ 1e-3 / -5e-4\n",
    "    \n",
    "\n",
    "    for i in range(cfg.N):\n",
    "        sample = dataset[i]\n",
    "        image  = sample[\"image\"]\n",
    "        spike_input = encoder(image)\n",
    "        inputs = {\"Input\": spike_input}\n",
    "\n",
    "        net.run(inputs=inputs, time=cfg.time)\n",
    "\n",
    "        # –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\n",
    "        lif_s_full = lif_mon.get(\"s\")   # [T,B,N]\n",
    "        in_s_full  = inp_mon.get(\"s\")   # [T,B,784]\n",
    "        lif2 = _to_2d(lif_s_full); in2 = _to_2d(in_s_full)\n",
    "\n",
    "        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º\n",
    "        if verbose and (i+1) in (1, 50, 150):\n",
    "            print(\"INPUT window sum:\", int(in2.sum()))\n",
    "            print(\"LIF   window sum:\", int(lif2.sum()))\n",
    "            vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "            print(\"v_thresh mean¬±std refrac:\", float(vt.mean()), float(vt.std()), lif_layer.refrac)\n",
    "            print(\"w[min,max]:\", float(connection.w.min()), float(connection.w.max()))\n",
    "\n",
    "        # WTA (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)\n",
    "        winners = []\n",
    "        if cfg.top_k and cfg.top_k > 0:\n",
    "            ok, idxs = apply_wta(lif_layer.s, top_k=cfg.top_k)\n",
    "            winners = idxs if ok and idxs is not None else []\n",
    "\n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–∫–Ω–∞\n",
    "        m = spiking_metrics_window(lif_s_full, winners)\n",
    "        if verbose and ((i+1) % cfg.log_every == 0 or i == 0):\n",
    "            print(f\"[{i+1}] total={m['total_spikes']} active={m['active']}/{m['N']} HHI={m['HHI']:.3f}\")\n",
    "\n",
    "        # Homeostasis –ø–æ ¬´—Å—ã—Ä—ã–º¬ª —Å–ø–∞–π–∫–∞–º (–¥–æ WTA)\n",
    "        spike_counts = to_2d(lif_s_full).sum(0).float()\n",
    "        ema.step(lif_layer, spike_counts, cfg.time, target=1.5)\n",
    "\n",
    "        # –ö–ª–∞–º–ø –≤–µ—Å–æ–≤ (–±–µ–∑ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –∫–æ–ª–æ–Ω–æ—á–Ω–æ–π –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ –∫–∞–∂–¥—ã–π —à–∞–≥)\n",
    "        with torch.no_grad():\n",
    "            connection.w.clamp_(0.0, 1.0)\n",
    "\n",
    "        # –≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ / —É—á—ë—Ç\n",
    "        meter.log_sample(lif_s_full, in_s_full, cfg.n_hidden, cfg.time, winners=winners)\n",
    "\n",
    "        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –º–æ–Ω–∏—Ç–æ—Ä–æ–≤\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "        inp_mon.reset_state_variables()\n",
    "\n",
    "   \n",
    "    rpt = meter.report()\n",
    "    if getattr(meter, \"samples\", 0) == 0:\n",
    "        print(\"!! meter: no samples logged ‚Äî –ø—Ä–æ–≤–µ—Ä—å –ø–æ—Ä—è–¥–æ–∫ log_sample()/reset() –∏ continue –≤ —Ü–∏–∫–ª–µ\")\n",
    "    out = {**asdict(cfg), **rpt}\n",
    "    return out, connection, lif_layer\n",
    "\n",
    "# ====== Grid Runner (compact) ======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8eb2b6-28b4-499d-9679-d66f8b0c23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set refrac 2.0\n",
      ">>> THRESH SET TO: 0.11999998986721039\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "INPUT window sum: 117\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.1999914646148682\n",
      "[1] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.7999433279037476 1.0\n",
      "[50] total=0 active=0/100 HHI=1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Cfg(\n\u001b[1;32m      2\u001b[0m     time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      3\u001b[0m     n_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     poisson_rate_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.006\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSUMMARY:\u001b[39m\u001b[38;5;124m\"\u001b[39m, {k: res[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspikes_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinners_unique\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwinner_HHI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_proxy_per_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "Cell \u001b[0;32mIn[27], line 312\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(cfg, verbose)\u001b[0m\n\u001b[1;32m    309\u001b[0m spike_input \u001b[38;5;241m=\u001b[39m encoder(image)\n\u001b[1;32m    310\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m\"\u001b[39m: spike_input}\n\u001b[0;32m--> 312\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\u001b[39;00m\n\u001b[1;32m    315\u001b[0m lif_s_full \u001b[38;5;241m=\u001b[39m lif_mon\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# [T,B,N]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/bindsnet/network/network.py:407\u001b[0m, in \u001b[0;36mNetwork.run\u001b[0;34m(self, inputs, time, one_step, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inject_v[t]\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m current_inputs:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    410\u001b[0m         x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    412\u001b[0m         )\n\u001b[1;32m    413\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/bindsnet/network/nodes.py:511\u001b[0m, in \u001b[0;36mLIFNodes.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Integrate inputs.\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefrac_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Decrement refractory counters.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefrac_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg = Cfg(\n",
    "    time=200,\n",
    "    n_hidden=100,\n",
    "    encoder=\"poisson\",                 # —Å–Ω–∞—á–∞–ª–∞ Poisson\n",
    "    top_k=3,                           # WTA –≤—ã–∫–ª. –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏\n",
    "    enable_inhibition_at_start=False,  # –∏–Ω–≥–∏–±–∏—Ü–∏—é –≤–∫–ª—é—á–∏–º –ø–æ–∑–∂–µ\n",
    "   \n",
    "    poisson_rate_scale = 0.006\n",
    ")\n",
    "res = run_experiment(cfg, verbose=True)\n",
    "print(\"\\nSUMMARY:\", {k: res[k] for k in [\"spikes_per_sample\",\"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67314ca5-f60c-435e-945a-7594a098bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan poisson_rate_scale ‚Üí [spikes/sample, winners_unique, HHI, energy_proxy]\n",
      "\n",
      "set refrac 2.0\n",
      ">>> THRESH SET TO: 0.11999998986721039\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "INPUT window sum: 41\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.1999914646148682\n",
      "INPUT window sum: 58\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.0\n",
      "INPUT window sum: 53\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.0\n",
      " 0.002: 0.00, 0, 0.000, 296.1\n",
      "set refrac 2.0\n",
      ">>> THRESH SET TO: 0.11999998986721039\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "v_thresh mean¬±std: 0.11999998986721039 7.488115016940355e-09\n",
      "INPUT window sum: 83\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.1999914646148682\n",
      "INPUT window sum: 99\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.0\n",
      "INPUT window sum: 112\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m scales:\n\u001b[1;32m      9\u001b[0m     cfg_s \u001b[38;5;241m=\u001b[39m Cfg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39masdict(cfg), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoisson_rate_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m: s})\n\u001b[0;32m---> 10\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>6\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspikes_per_sample\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinners_unique\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinner_HHI\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_proxy_per_sample\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 312\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(cfg, verbose)\u001b[0m\n\u001b[1;32m    309\u001b[0m spike_input \u001b[38;5;241m=\u001b[39m encoder(image)\n\u001b[1;32m    310\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m\"\u001b[39m: spike_input}\n\u001b[0;32m--> 312\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# –ü–æ–ª–Ω—ã–π —Ä–∞—Å—Ç—Ä –∑–∞ –æ–∫–Ω–æ\u001b[39;00m\n\u001b[1;32m    315\u001b[0m lif_s_full \u001b[38;5;241m=\u001b[39m lif_mon\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# [T,B,N]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/bindsnet/network/network.py:407\u001b[0m, in \u001b[0;36mNetwork.run\u001b[0;34m(self, inputs, time, one_step, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m inject_v[t]\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m current_inputs:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    410\u001b[0m         x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[l]\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    412\u001b[0m         )\n\u001b[1;32m    413\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/bindsnet/network/nodes.py:508\u001b[0m, in \u001b[0;36mLIFNodes.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03mRuns a single simulation step.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m:param x: Inputs to the layer.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# Decay voltages.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Integrate inputs.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m x\u001b[38;5;241m.\u001b[39mmasked_fill_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefrac_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/torch/nn/modules/module.py:2027\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2025\u001b[0m sign \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer)\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersistent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sign\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m-> 2027\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersistent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2029\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m persistent:\n",
      "File \u001b[0;32m~/anaconda3/envs/bindsnet/lib/python3.10/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule.register_buffer\u001b[0;34m(self, name, tensor, persistent)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers[name] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m persistent:\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_persistent_buffers_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set\u001b[38;5;241m.\u001b[39madd(name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "# –°–µ—Ç–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "scales = [0.002, 0.004, 0.006, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "results = []\n",
    "print(\"scan poisson_rate_scale ‚Üí [spikes/sample, winners_unique, HHI, energy_proxy]\\n\")\n",
    "for s in scales:\n",
    "    cfg_s = Cfg(**{**asdict(cfg), \"poisson_rate_scale\": s})\n",
    "    res = run_experiment(cfg_s, verbose=False)\n",
    "    results.append(res)\n",
    "    print(f\"{s:>6}: {res['spikes_per_sample']:.2f}, \"\n",
    "          f\"{res['winners_unique']}, \"\n",
    "          f\"{res['winner_HHI']:.3f}, \"\n",
    "          f\"{res['energy_proxy_per_sample']:.1f}\")\n",
    "\n",
    "# –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –æ—Ç–±–æ—Ä ¬´—Ä–∞–∑—É–º–Ω—ã—Ö¬ª –Ω–∞—Å—Ç—Ä–æ–µ–∫:\n",
    "#   - —Ö–æ—Ç–∏–º winners_unique > 0 (–µ—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)\n",
    "#   - —Ö–æ—Ç–∏–º —É–º–µ—Ä–µ–Ω–Ω—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–Ω–µ –ª–∞–≤–∏–Ω–∞): spikes_per_sample –≤ [20, 400] (–ø–æ–¥–ø—Ä–∞–≤—å –ø–æ–¥ —Å–≤–æ—é —Ü–µ–ª—å)\n",
    "#   - –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º energy_proxy_per_sample\n",
    "candidates = [\n",
    "    r for r in results\n",
    "    if r[\"winners_unique\"] > 0 and 20 <= r[\"spikes_per_sample\"] <= 400\n",
    "]\n",
    "if candidates:\n",
    "    best = min(candidates, key=lambda r: r[\"energy_proxy_per_sample\"])\n",
    "    print(\"\\nBEST (by lowest energy among reasonable activity):\")\n",
    "    print({k: best[k] for k in [\"poisson_rate_scale\",\"spikes_per_sample\",\n",
    "                                \"winners_unique\",\"winner_HHI\",\"energy_proxy_per_sample\"]})\n",
    "else:\n",
    "    print(\"\\nNo reasonable candidates found ‚Äî relax constraints or widen scales.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f981614-7982-4266-86e8-e76f58315789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools, csv, math, traceback\n",
    "\n",
    "# ---- –Ω–∞—Å—Ç—Ä–æ–∏ÃÜ —Å–µ—Ç–∫—É –∑–¥–µ—Å—å ----\n",
    "param_grid = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008, 0.009, 0.01],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [0, 1, 3, 4, 5],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "\n",
    "def grid_search(param_grid, out_csv=\"grid_results.csv\", seed=42, verbose_every=0):\n",
    "    keys = list(param_grid.keys())\n",
    "    vals = [param_grid[k] for k in keys]\n",
    "    total = 1\n",
    "    for v in vals: total *= len(v)\n",
    "    print(f\"–ö–æ–º–±–∏–Ω–∞—Ü–∏–π: {total}\")\n",
    "\n",
    "    # CSV\n",
    "    header = keys + [\n",
    "        \"spikes_per_sample\",\n",
    "        \"winners_unique\",\n",
    "        \"winner_HHI\",\n",
    "        \"energy_proxy_per_sample\",\n",
    "    ]\n",
    "    f = open(out_csv, \"w\", newline=\"\")\n",
    "    writer = csv.writer(f); writer.writerow(header)\n",
    "\n",
    "    best = []  # –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–ø-5\n",
    "    def score(res):\n",
    "        # —Ü–µ–ª—å: –±–æ–ª—å—à–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏, –º–µ–Ω—å—à–µ —ç–Ω–µ—Ä–≥–∏–∏ –∏ –ª–∏—à–Ω–∏—Ö —Å–ø–∞–π–∫–æ–≤\n",
    "        # –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á: (-winners_unique, winner_HHI –≤–æ–∑–º., energy, spikes)\n",
    "        # –Ω–æ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –≤–æ–∑—å–º—ë–º tuple (—ç–Ω–µ—Ä–≥–∏—è, -winners_unique, winner_HHI)\n",
    "        return (res[\"energy_proxy_per_sample\"], -res[\"winners_unique\"], res[\"winner_HHI\"])\n",
    "\n",
    "    with tqdm(total=total, desc=\"Grid search\") as pbar:\n",
    "        for combo in itertools.product(*vals):\n",
    "            cfg_dict = dict(zip(keys, combo))\n",
    "            try:\n",
    "                cfg = Cfg(\n",
    "                    time=200,\n",
    "                    n_hidden=100,\n",
    "                    encoder=\"poisson\",\n",
    "                    top_k=int(cfg_dict[\"top_k\"]),\n",
    "                    enable_inhibition_at_start=False,\n",
    "                    nu_plus=float(cfg_dict[\"nu_plus\"]),\n",
    "                    nu_minus=float(cfg_dict[\"nu_minus\"]),           # –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –¥–æ–ø—É—Å—Ç–∏–º—ã\n",
    "                    poisson_rate_scale=float(cfg_dict[\"poisson_rate_scale\"]),\n",
    "                    seed=seed,\n",
    "                )\n",
    "\n",
    "                res = run_experiment(cfg, verbose=False)\n",
    "                row = [cfg_dict[k] for k in keys] + [\n",
    "                    res[\"spikes_per_sample\"],\n",
    "                    res[\"winners_unique\"],\n",
    "                    res[\"winner_HHI\"],\n",
    "                    res[\"energy_proxy_per_sample\"],\n",
    "                ]\n",
    "                writer.writerow(row); f.flush()\n",
    "\n",
    "                # –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–ø-5\n",
    "                best.append(res)\n",
    "                best.sort(key=score)\n",
    "                if len(best) > 5: best = best[:5]\n",
    "\n",
    "            except Exception as e:\n",
    "                # –ª–æ–≥–∏—Ä—É–µ–º ¬´–ø–ª–æ—Ö—É—é¬ª —Ç–æ—á–∫—É\n",
    "                row = [cfg_dict[k] for k in keys] + [\"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"]\n",
    "                writer.writerow(row); f.flush()\n",
    "                print(\"\\n[WARN] –û—à–∏–±–∫–∞ –Ω–∞ –∫–æ–º–±–µ:\", cfg_dict)\n",
    "                traceback.print_exc()\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    print(\"\\nTop-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\")\n",
    "    for i, r in enumerate(best, 1):\n",
    "        short = {\n",
    "            \"poisson_rate_scale\": r.get(\"poisson_rate_scale\", None) if isinstance(r.get(\"poisson_rate_scale\", None), (int,float)) else None,\n",
    "            \"nu_plus\": r.get(\"nu_plus\", None) if isinstance(r.get(\"nu_plus\", None), (int,float)) else None,\n",
    "            \"nu_minus\": r.get(\"nu_minus\", None) if isinstance(r.get(\"nu_minus\", None), (int,float)) else None,\n",
    "            \"top_k\": r.get(\"top_k\", None) if isinstance(r.get(\"top_k\", None), (int,float)) else None,\n",
    "            \"spikes_per_sample\": r[\"spikes_per_sample\"],\n",
    "            \"winners_unique\": r[\"winners_unique\"],\n",
    "            \"winner_HHI\": r[\"winner_HHI\"],\n",
    "            \"energy_proxy_per_sample\": r[\"energy_proxy_per_sample\"],\n",
    "        }\n",
    "        print(f\"{i}.\", short)\n",
    "\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df7b10dc-1cd8-4c72-8fd6-a449cb7a4505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–º–±–∏–Ω–∞—Ü–∏–π: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [04:54<00:00, 36.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\n",
      "1. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 8, 'spikes_per_sample': 18.885, 'winners_unique': 35, 'winner_HHI': 0.036458333333333336, 'energy_proxy_per_sample': 711.21}\n",
      "2. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 7, 'spikes_per_sample': 18.885, 'winners_unique': 32, 'winner_HHI': 0.03854875283446711, 'energy_proxy_per_sample': 711.21}\n",
      "3. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 6, 'spikes_per_sample': 18.885, 'winners_unique': 28, 'winner_HHI': 0.04166666666666667, 'energy_proxy_per_sample': 711.21}\n",
      "4. {'poisson_rate_scale': 0.006, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 5, 'spikes_per_sample': 18.885, 'winners_unique': 25, 'winner_HHI': 0.04666666666666667, 'energy_proxy_per_sample': 711.21}\n",
      "5. {'poisson_rate_scale': 0.065, 'nu_plus': 0.0001, 'nu_minus': -0.001, 'top_k': 8, 'spikes_per_sample': 1419.19, 'winners_unique': 94, 'winner_HHI': 0.017494960947341893, 'energy_proxy_per_sample': 7970.165}\n",
      "\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: grid_results_set3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- –Ω–∞—Å—Ç—Ä–æ–∏ÃÜ —Å–µ—Ç–∫—É –∑–¥–µ—Å—å ----\n",
    "param_grid_set2 = {\n",
    "    \"poisson_rate_scale\": [0.004, 0.006, 0.008],\n",
    "    \"nu_plus\": [0.001, 0.002, 0.003],\n",
    "    \"nu_minus\": [-0.0005, -0.001, -0.002],\n",
    "    \"top_k\": [0, 3, 5]\n",
    "}\n",
    "param_grid_set1 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.007, 0.008],\n",
    "    \"nu_plus\":            [1e-4, 3e-4, 1e-3, 3e-3],\n",
    "    \"nu_minus\":           [-5e-5, -1e-4, -3e-4, -1e-3],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [0,  3,  5,6],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "param_grid_set3 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.065,],\n",
    "    \"nu_plus\":            [0.0001],\n",
    "    \"nu_minus\":           [-0.001],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [ 5,6,7,8],\n",
    "    # –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å ‚Äî –¥–æ–±–∞–≤—å —Å—é–¥–∞ \"time\", \"n_hidden\", –Ω–æ —Ç–æ–≥–¥–∞ –º–µ–Ω—è–π —Å–±–æ—Ä–∫—É cfg –Ω–∏–∂–µ\n",
    "}\n",
    "\n",
    "grid_search(param_grid_set3, out_csv=\"grid_results_set3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ee5c9-dd5c-472f-ae14-e1691c18b023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5608d0cb-e714-4826-9ac0-0e7422dce145",
   "metadata": {},
   "source": [
    "Top-5 (–ø–æ —ç–Ω–µ—Ä–≥–æ-–º–µ—Ç—Ä–∏–∫–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏):\n",
    "1. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 0, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "2. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 3, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "3. {'poisson_rate_scale': 0.004, 'nu_plus': 0.003, 'nu_minus': -0.002, 'top_k': 5, 'spikes_per_sample': 0.195, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 492.995}\n",
    "4. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 0, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}\n",
    "5. {'poisson_rate_scale': 0.004, 'nu_plus': 0.001, 'nu_minus': -0.0005, 'top_k': 3, 'spikes_per_sample': 0.2, 'winners_unique': 0, 'winner_HHI': 0.0, 'energy_proxy_per_sample': 493.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6385223-e6d4-45d9-a080-e30a2b9c8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, torch\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.network.monitors import Monitor\n",
    "\n",
    "# ====== 1) SAVE / LOAD ======\n",
    "def save_snn(path, cfg, connection, lif_layer):\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "    vt = (lif_layer.v_thresh if hasattr(lif_layer,'v_thresh') else lif_layer.thresh)\n",
    "    ckpt = {\n",
    "        \"cfg\": asdict(cfg),\n",
    "        \"W\": connection.w.detach().cpu(),\n",
    "        \"v_thresh\": vt.detach().cpu(),\n",
    "    }\n",
    "    torch.save(ckpt, path)\n",
    "    print(f\"Saved to {path} | W {tuple(ckpt['W'].shape)}\")\n",
    "\n",
    "def load_weights_into(net, connection, lif_layer, ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        connection.w.copy_(ckpt[\"W\"])\n",
    "        vt = ckpt[\"v_thresh\"]\n",
    "        if hasattr(lif_layer, \"v_thresh\"): lif_layer.v_thresh.copy_(vt)\n",
    "        else: lif_layer.thresh.copy_(vt)\n",
    "    print(f\"Loaded from {ckpt_path}\")\n",
    "\n",
    "# ====== 2) –ö–ê–õ–ò–ë–†–û–í–ö–ê (–Ω–µ–π—Ä–æ–Ω -> –º–µ—Ç–∫–∞) ======\n",
    "@torch.no_grad()\n",
    "def build_label_map(net, input_layer, lif_layer, encoder, n_calib=2000, T=200, top_k=3, seed=123):\n",
    "    # –≤—ã–∫–ª—é—á–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_eval_tmp\")\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_train = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_calib, len(ds_train))))\n",
    "    usage = torch.zeros((lif_layer.n,), dtype=torch.long)          # —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –Ω–µ–π—Ä–æ–Ω –≤—ã–∏–≥—Ä—ã–≤–∞–ª\n",
    "    wins  = torch.zeros((lif_layer.n, 10), dtype=torch.long)       # –Ω–µ–π—Ä–æ–Ω x –∫–ª–∞—Å—Å\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)  # —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Å—Ç–æ—Ö–∞—Å—Ç–∏–∫—É Poisson per-sample\n",
    "        x = ds_train[i][\"image\"]\n",
    "        y = int(ds_train[i][\"label\"])\n",
    "        spikes_in = encoder(x)                       # [T,1,784]\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        # –≤—ã–±–∏—Ä–∞–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π –ø–æ —Å—É–º–º–µ —Å–ø–∞–π–∫–æ–≤ –∑–∞ –æ–∫–Ω–æ\n",
    "        s = lif_mon.get(\"s\")                         # [T,1,N]\n",
    "        s2 = s[:,0,:]                                # [T,N]\n",
    "        counts = s2.sum(0)                           # [N]\n",
    "        if counts.sum() > 0:\n",
    "            k = min(top_k, lif_layer.n)\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            for j in topi.tolist():\n",
    "                usage[j] += 1\n",
    "                wins[j, y] += 1\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    net.monitors.pop(\"lif_eval_tmp\", None)\n",
    "\n",
    "    # –Ω–µ–π—Ä–æ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ = argmax –ø–æ –∫–ª–∞—Å—Å–∞–º (–µ—Å–ª–∏ –Ω–µ–π—Ä–æ–Ω —Ö–æ—Ç—å —Ä–∞–∑ –≤—ã–∏–≥—Ä—ã–≤–∞–ª)\n",
    "    label_map = -torch.ones((lif_layer.n,), dtype=torch.long)\n",
    "    active = (usage > 0).nonzero().flatten().tolist()\n",
    "    for j in active:\n",
    "        label_map[j] = wins[j].argmax().item()\n",
    "\n",
    "    covered = int((label_map >= 0).sum())\n",
    "    print(f\"Label-map built: {covered}/{lif_layer.n} neurons assigned; active winners {int((usage>0).sum())}\")\n",
    "    return label_map\n",
    "\n",
    "# ====== 3) –û–¶–ï–ù–ö–ê –ù–ê TEST ======\n",
    "@torch.no_grad()\n",
    "def evaluate_on_mnist(net, input_layer, lif_layer, encoder, label_map, T=200, top_k=3, n_test=1000, seed=999):\n",
    "    # freeze learning\n",
    "    for c in net.connections.values():\n",
    "        if hasattr(c, \"update_rule\"): c.update_rule.nu = (torch.as_tensor(0.0), torch.as_tensor(0.0))\n",
    "\n",
    "    lif_mon = Monitor(lif_layer, state_vars=(\"s\",), time=T); net.add_monitor(lif_mon, name=\"lif_test_tmp\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    ds_test = MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "    idxs = list(range(min(n_test, len(ds_test))))\n",
    "\n",
    "    correct = 0\n",
    "    meter = SNNMeter()\n",
    "\n",
    "    for i in idxs:\n",
    "        torch.manual_seed(seed + i)\n",
    "        x = ds_test[i][\"image\"]; y = int(ds_test[i][\"label\"])\n",
    "        spikes_in = encoder(x)\n",
    "        net.run(inputs={\"Input\": spikes_in}, time=T)\n",
    "\n",
    "        s_full = lif_mon.get(\"s\")              # [T,1,N]\n",
    "        s2 = s_full[:,0,:]                     # [T,N]\n",
    "        counts = s2.sum(0)                     # [N]\n",
    "\n",
    "        # WTA –Ω–∞ –æ—Ü–µ–Ω–∫–µ ‚Äî –±–µ—Ä—ë–º top_k –Ω–µ–π—Ä–æ–Ω–æ–≤ –∏ –≥–æ–ª–æ—Å—É–µ–º –∏—Ö –º–µ—Ç–∫–∞–º–∏\n",
    "        k = min(top_k, lif_layer.n)\n",
    "        if counts.sum() == 0:\n",
    "            pred = -1\n",
    "        else:\n",
    "            topv, topi = torch.topk(counts, k=k)\n",
    "            votes = torch.zeros(10, dtype=torch.float32)\n",
    "            for j, v in zip(topi.tolist(), topv.tolist()):\n",
    "                lbl = int(label_map[j].item())\n",
    "                if lbl >= 0: votes[lbl] += float(v)\n",
    "            pred = int(votes.argmax().item()) if votes.sum() > 0 else -1\n",
    "\n",
    "        if pred == y: correct += 1\n",
    "\n",
    "        # —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞ (–¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è)\n",
    "        # —Å–æ–∑–¥–∞–¥–∏–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π ‚Äúinput monitor‚Äù –∏–∑ —Ç–µ—Ö –∂–µ —Å–ø–∞–π–∫–æ–≤\n",
    "        meter.log_sample(s_full, spikes_in, lif_layer.n, T, winners=topi.tolist() if counts.sum()>0 else None)\n",
    "\n",
    "        net.reset_state_variables()\n",
    "        lif_mon.reset_state_variables()\n",
    "\n",
    "    acc = correct / len(idxs)\n",
    "    rpt = meter.report()\n",
    "    net.monitors.pop(\"lif_test_tmp\", None)\n",
    "    print(f\"TEST accuracy: {acc:.3f}  | spikes/sample={rpt['spikes_per_sample']:.2f}  energy‚âà{rpt['energy_proxy_per_sample']:.1f}\")\n",
    "    return {\"accuracy\": acc, **rpt}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26c63233-0d2b-43c2-a3fa-8744a8a2523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT window sum: 117\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.11999998986721039 7.488115016940355e-09 tensor(2.)\n",
      "w[min,max]: 0.8000055551528931 1.1999914646148682\n",
      "[1] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 140\n",
      "LIF   window sum: 0\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.7964295744895935 1.0\n",
      "[50] total=0 active=0/100 HHI=1.000\n",
      "[100] total=0 active=0/100 HHI=1.000\n",
      "INPUT window sum: 165\n",
      "LIF   window sum: 102\n",
      "v_thresh mean¬±std refrac: 0.15000000596046448 0.0 tensor(2.)\n",
      "w[min,max]: 0.7924708724021912 1.0\n",
      "[150] total=102 active=33/100 HHI=0.040\n",
      "[200] total=0 active=0/100 HHI=1.000\n",
      "Saved to out/snn_mnist.pt | W (784, 100)\n",
      "Loaded from out/snn_mnist.pt\n",
      "Label-map built: 76/100 neurons assigned; active winners 76\n",
      "TEST accuracy: 0.097  | spikes/sample=6645.70  energy‚âà73860.5\n",
      "{'accuracy': 0.097, 'spikes_per_sample': 6645.697, 'synops_per_sample': 1342296.9, 'v_updates_per_sample': 20000.0, 'energy_proxy_per_sample': 73860.542, 'winners_unique': 53, 'winner_HHI': 0.15879344444444446}\n"
     ]
    }
   ],
   "source": [
    "# ====== –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø ======\n",
    "# 1) —Ç—Ä–µ–Ω–∏—Ä—É–µ–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ:\n",
    "param_grid_set3 = {\n",
    "    \"poisson_rate_scale\": [ 0.006, 0.065,],\n",
    "    \"nu_plus\":            [0.0001],\n",
    "    \"nu_minus\":           [-0.001],  # –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–ï\n",
    "    \"top_k\":              [ 5,6,7,8]\n",
    "}\n",
    "cfg = Cfg(time=200, n_hidden=100, encoder=\"poisson\", top_k=6,\n",
    "           enable_inhibition_at_start=False, nu_plus=0.0001, nu_minus=-0.001,\n",
    "           poisson_rate_scale=0.006)\n",
    "_, connection, lif_layer = run_experiment(cfg, verbose=True)   # —Ç—É—Ç —Ç—ã —É–∂–µ –æ–±—É—á–∞–ª\n",
    "\n",
    "# 2) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:\n",
    "save_snn(\"out/snn_mnist.pt\", cfg, connection, lif_layer)\n",
    "\n",
    "# 3) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ ‚Äî –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º —Å–µ—Ç—å (–∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é), –≥—Ä—É–∑–∏–º –≤–µ—Å–∞:\n",
    "net, input_layer, lif_layer, connection, recurrent_inh, W_inh = build_net(cfg)\n",
    "load_weights_into(net, connection, lif_layer, \"out/snn_mnist.pt\")\n",
    "\n",
    "# 4) —Ç–æ—Ç –∂–µ —ç–Ω–∫–æ–¥–µ—Ä, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏:\n",
    "encoder, _ = make_encoder(\"poisson\", T=cfg.time)\n",
    "\n",
    "# 5) –∫–∞–ª–∏–±—Ä—É–µ–º –Ω–µ–π—Ä–æ–Ω‚Üí–º–µ—Ç–∫–∞ –ø–æ train (–±–µ–∑ –æ–±—É—á–µ–Ω–∏—è!):\n",
    "label_map = build_label_map(net, input_layer, lif_layer, encoder,\n",
    "                             n_calib=2000, T=cfg.time, top_k=cfg.top_k)\n",
    "\n",
    "# 6) —Å—á–∏—Ç–∞–µ–º accuracy –Ω–∞ test:\n",
    "test_report = evaluate_on_mnist(net, input_layer, lif_layer, encoder,\n",
    "                                 label_map, T=cfg.time, top_k=cfg.top_k, n_test=1000)\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0968c3-e842-48ce-860b-9beff1f775a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
